{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovRLzgZl65LR"
      },
      "source": [
        "### polybert fingerprints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mlK-YsUs-z6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d705ee50-f46b-435f-fbbc-4d2d578446d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.11/dist-packages (2024.9.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_combined = pd.read_csv('sigma_data.csv')\n"
      ],
      "metadata": {
        "id": "HSM563rcpe1L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_Df = df_combined[df_combined['synthetic'] == False]\n",
        "s_Df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "OWAy_6aqB80O",
        "outputId": "27358d22-09e6-44f4-efd3-7a5978c0bb04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Plastic Type, Enzyme Name, protein_sequence, smiles, protein_length, synthetic, cluster, Cluster]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96d17308-7331-4aca-8b18-427448bbcc9e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plastic Type</th>\n",
              "      <th>Enzyme Name</th>\n",
              "      <th>protein_sequence</th>\n",
              "      <th>smiles</th>\n",
              "      <th>protein_length</th>\n",
              "      <th>synthetic</th>\n",
              "      <th>cluster</th>\n",
              "      <th>Cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96d17308-7331-4aca-8b18-427448bbcc9e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96d17308-7331-4aca-8b18-427448bbcc9e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96d17308-7331-4aca-8b18-427448bbcc9e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_ba4d1fab-d066-4c0c-a693-7b4f93a79eb7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('s_Df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ba4d1fab-d066-4c0c-a693-7b4f93a79eb7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('s_Df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "s_Df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "C_Y6CrilCGoH",
        "outputId": "ef4a1e65-d4ab-4409-f549-d7f213d34063"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Plastic Type                   Enzyme Name  \\\n",
              "0             PCL                      Cutinase   \n",
              "1             PCL                      Cutinase   \n",
              "2             PCL                      Cutinase   \n",
              "3             PCL                      Cutinase   \n",
              "4             PCL                      Cutinase   \n",
              "...           ...                           ...   \n",
              "9022           PE  Manganese_Peroxidase_Iz-MnP2   \n",
              "9023           PE  Manganese_Peroxidase_Iz-MnP2   \n",
              "9024           PE  Manganese_Peroxidase_Iz-MnP2   \n",
              "9025           PE  Manganese_Peroxidase_Iz-MnP2   \n",
              "9026           PE  Manganese_Peroxidase_Iz-MnP2   \n",
              "\n",
              "                                       protein_sequence            smiles  \\\n",
              "0     MKFFALTTLLAATASALPTSHPVQELEARQLGGGTTRNDLTNGNSA...  [*]OCCCCC(=O)[*]   \n",
              "1     MKFFALTTLLAATASALPTSAPVAELEARQLGAGTTRNDLTNGNSA...  [*]OCCCCC(=O)[*]   \n",
              "2     MKFFALTTLLAATASALPTSIPVQELEARQLGGGTTRNDLTNGNSA...  [*]OCCCCC(=O)[*]   \n",
              "3     MKFFAITTLLAATASALPTSHPVQELEARQLGGGTTRNDLTNGNSA...  [*]OCCCCC(=O)[*]   \n",
              "4     MKFFALTTLLAATAAALPTSAPVVELEARQLGGGTTRNDLTNGNSA...  [*]OCCCCC(=O)[*]   \n",
              "...                                                 ...               ...   \n",
              "9022  MRLIGSSLLSASLRLARQAPAAELAACPDGTRVSNSACCAFIPIAQ...          [*]CC[*]   \n",
              "9023  MALHLSSLLSASLRLLVAAPAAETAVCPDGTRTSNSACCAFLPLAQ...          [*]CC[*]   \n",
              "9024  MALLLSSLLSASPILSRAAPAARSAVCPDGQRVANPACCAFFPIAQ...          [*]CC[*]   \n",
              "9025  MALHLSLLLSALARLVRTLSAANTAVCPDGTRVSNSACCAFFPVAQ...          [*]CC[*]   \n",
              "9026  MALHLLLLLSASPLLTRAAAAAETAVCPDGTAVSNSACCAFIPVAQ...          [*]CC[*]   \n",
              "\n",
              "      protein_length synthetic  cluster  Cluster  \n",
              "0                231       NaN     13.0        7  \n",
              "1                231      True     13.0        7  \n",
              "2                231      True     13.0        7  \n",
              "3                231      True     13.0        7  \n",
              "4                231      True     13.0        7  \n",
              "...              ...       ...      ...      ...  \n",
              "9022             385      True     14.0       10  \n",
              "9023             385      True     14.0       10  \n",
              "9024             385      True     14.0       10  \n",
              "9025             385      True     14.0       10  \n",
              "9026             385      True     14.0       10  \n",
              "\n",
              "[9027 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7cccb752-632b-428c-acb0-249d03bfcc2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plastic Type</th>\n",
              "      <th>Enzyme Name</th>\n",
              "      <th>protein_sequence</th>\n",
              "      <th>smiles</th>\n",
              "      <th>protein_length</th>\n",
              "      <th>synthetic</th>\n",
              "      <th>cluster</th>\n",
              "      <th>Cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PCL</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MKFFALTTLLAATASALPTSHPVQELEARQLGGGTTRNDLTNGNSA...</td>\n",
              "      <td>[*]OCCCCC(=O)[*]</td>\n",
              "      <td>231</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PCL</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MKFFALTTLLAATASALPTSAPVAELEARQLGAGTTRNDLTNGNSA...</td>\n",
              "      <td>[*]OCCCCC(=O)[*]</td>\n",
              "      <td>231</td>\n",
              "      <td>True</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PCL</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MKFFALTTLLAATASALPTSIPVQELEARQLGGGTTRNDLTNGNSA...</td>\n",
              "      <td>[*]OCCCCC(=O)[*]</td>\n",
              "      <td>231</td>\n",
              "      <td>True</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PCL</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MKFFAITTLLAATASALPTSHPVQELEARQLGGGTTRNDLTNGNSA...</td>\n",
              "      <td>[*]OCCCCC(=O)[*]</td>\n",
              "      <td>231</td>\n",
              "      <td>True</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PCL</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MKFFALTTLLAATAAALPTSAPVVELEARQLGGGTTRNDLTNGNSA...</td>\n",
              "      <td>[*]OCCCCC(=O)[*]</td>\n",
              "      <td>231</td>\n",
              "      <td>True</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9022</th>\n",
              "      <td>PE</td>\n",
              "      <td>Manganese_Peroxidase_Iz-MnP2</td>\n",
              "      <td>MRLIGSSLLSASLRLARQAPAAELAACPDGTRVSNSACCAFIPIAQ...</td>\n",
              "      <td>[*]CC[*]</td>\n",
              "      <td>385</td>\n",
              "      <td>True</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9023</th>\n",
              "      <td>PE</td>\n",
              "      <td>Manganese_Peroxidase_Iz-MnP2</td>\n",
              "      <td>MALHLSSLLSASLRLLVAAPAAETAVCPDGTRTSNSACCAFLPLAQ...</td>\n",
              "      <td>[*]CC[*]</td>\n",
              "      <td>385</td>\n",
              "      <td>True</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9024</th>\n",
              "      <td>PE</td>\n",
              "      <td>Manganese_Peroxidase_Iz-MnP2</td>\n",
              "      <td>MALLLSSLLSASPILSRAAPAARSAVCPDGQRVANPACCAFFPIAQ...</td>\n",
              "      <td>[*]CC[*]</td>\n",
              "      <td>385</td>\n",
              "      <td>True</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9025</th>\n",
              "      <td>PE</td>\n",
              "      <td>Manganese_Peroxidase_Iz-MnP2</td>\n",
              "      <td>MALHLSLLLSALARLVRTLSAANTAVCPDGTRVSNSACCAFFPVAQ...</td>\n",
              "      <td>[*]CC[*]</td>\n",
              "      <td>385</td>\n",
              "      <td>True</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9026</th>\n",
              "      <td>PE</td>\n",
              "      <td>Manganese_Peroxidase_Iz-MnP2</td>\n",
              "      <td>MALHLLLLLSASPLLTRAAAAAETAVCPDGTAVSNSACCAFIPVAQ...</td>\n",
              "      <td>[*]CC[*]</td>\n",
              "      <td>385</td>\n",
              "      <td>True</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9027 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cccb752-632b-428c-acb0-249d03bfcc2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7cccb752-632b-428c-acb0-249d03bfcc2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7cccb752-632b-428c-acb0-249d03bfcc2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-19446a16-f837-4272-b17d-51821a3e9d48\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19446a16-f837-4272-b17d-51821a3e9d48')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-19446a16-f837-4272-b17d-51821a3e9d48 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_06914642-bdc1-4c4f-a705-f2708cccd90d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_combined')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_06914642-bdc1-4c4f-a705-f2708cccd90d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_combined');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_combined",
              "summary": "{\n  \"name\": \"df_combined\",\n  \"rows\": 9027,\n  \"fields\": [\n    {\n      \"column\": \"Plastic Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"PET\",\n          \"P3HV_PHBV_PHA\",\n          \"PEG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Enzyme Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 43,\n        \"samples\": [\n          \"PHA depolymerase\",\n          \"PBS_depolymerase\",\n          \"Lipase\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9027,\n        \"samples\": [\n          \"MAVQYFRASDGARLAYSDEGEGLPVLALPGLTRTGRDFDDLAPHLPGVRLIRPDYRGRGDSDWTGHPSYRVPVEARDVLALLDHLGVAKAAVLGTSRGGIIGMLLAATAPERLLGLILNDVGPVLQRSGLLRIADYVGRLPAAATLEDLAQALAAAMPGFGAVPASRWLEEAARHYRETPSGLSVNYDPALREPFLAAFDGPEVDLWPLFDALAGLPLALIRGANSDLLSPETAAEMQRRRPDMILAEARDRAHAPFLDEPESLAAIHALLAAMR\",\n          \"MFNQIGLIALLLLVAAGSLMFSATALAGGGGGSGGGNNGGGGGCTADCGYERGPDPSVSGLEASTGPFSVRTSNVSSSVRGFGGGTIYYPTNTSGTLPAIAVAPGFVSPESSIAWWGPRLASHGFVVMTIGTNSRSDQPASRAGQLNAALDYLIEQNDSSGSPINGMIDTDRLGVMGWSMGGGGTLRVATDGRVSAAIPLAPWNSSSSQFRSIDTPTLIFACENDSTAPVRSHADPFYDAIPDNTAKSFVELDGGGHFVASGSSGFGGEYNDVLSRYIVSWMKLHLDKDQRYNQFVCGPNWESDRRISEYRGTCGY\",\n          \"MFGKLPFARASLAVGALLLSAAAVAQTNPYQRGPDPTVSSLEATRGPFSTSSFTVSAPSGYGGGTVYYPTNAGGKFGAIAVVPGYTARQNSISWWGPRLASHGFVVITIDTNSTLDQPSSRSSQLSAALNRVVSLNGTSSSPIYNKVDTARLGVMGWSMGGGGSLIAAKNNPSLRAAAPVAPWAQSSFSSVTVPTLIISCENDSTAPNSSHSGPFYNQMTRNKKAYLVINGGSHSCAFSGSSDAGLIGKYGVAWMKRFLDQDTRYSQFLCGAESPADLSTRAVNAYKFNCPY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smiles\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"[*]OC(C)CC(=O)[*]\",\n          \"[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)CC(=O)O[*]\",\n          \"[*]OC(C)C(=O)[*].[*]OCCCCC(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCOC(=O)CC(=O)O[*].[*]OC(C)CC(=O)[*]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 127,\n        \"min\": 108,\n        \"max\": 914,\n        \"num_unique_values\": 118,\n        \"samples\": [\n          213,\n          257,\n          201\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synthetic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.983299575558288,\n        \"min\": 0.0,\n        \"max\": 19.0,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          13.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cluster\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 22,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_list = []\n",
        "unique_smiles = set(df_combined['smiles'].unique())\n",
        "\n",
        "for smiles in unique_smiles:\n",
        "    # Remove any existing '[*]' at the start and end, even if there are spaces\n",
        "    stripped_smiles = smiles.strip().lstrip(\"[*]\").rstrip(\"[*]\").strip()\n",
        "\n",
        "    # Wrap properly\n",
        "    formatted_smiles = f\"[*]{stripped_smiles}[*]\"\n",
        "    smiles_list.append(formatted_smiles)\n",
        "\n",
        "smiles_list\n"
      ],
      "metadata": {
        "id": "MMnOPvz9plr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8727abb-ce00-4e28-ccb9-c6e1b04c5438"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*]',\n",
              " '[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)CC(=O)O[*].[*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*]',\n",
              " '[*]NCCCCNCCCC(=O)O[*]',\n",
              " '[*]CCO[*]',\n",
              " '[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OC(C)C(=O)[*]',\n",
              " '[*]OCCO[*]',\n",
              " '[*]OCCCCC(=O)[*]',\n",
              " '[*]OCCOC(=O)CC(=O)O[*].[*]OC(C)CC(=O)[*].[*]OC(C)CC(=O)[*]',\n",
              " '[*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*].[*]OCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*]',\n",
              " '[*]OC(C)C(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)CC(=O)O[*].[*]OC(C)CC(=O)[*].[*]OC(C)CC(=O)[*]',\n",
              " '[*]OC(C)C(=O)[*].[*]OCCCCC(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCOC(=O)CC(=O)O[*].[*]OC(C)CC(=O)[*]',\n",
              " '[*]OCCCCOC(=O)CC(=O)O[*]',\n",
              " '[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*]',\n",
              " '[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)CC(=O)O[*].[*]OC(C)CC(=O)[*].[*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*]',\n",
              " '[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OC(C)CC(=O)[*].[*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*]',\n",
              " '[*]OC(C)CC(=O)[*]',\n",
              " '[*]OC(C)CC(=O)[*].[*]OC(C)CC(=O)[*]',\n",
              " '[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCCCC(=O)[*]',\n",
              " '[*]CC[*]',\n",
              " '[*]OCCCCC(=O)[*].[*]OC(C)CC(=O)[*]',\n",
              " '[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]',\n",
              " '[*]OC(C)C(=O)[*].[*]OCCCCC(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*]',\n",
              " '[*]OC(C)C(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*]',\n",
              " '[*]OC(C)C(=O)[*]',\n",
              " '[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)CC(=O)O[*]',\n",
              " '[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]',\n",
              " '[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*]',\n",
              " '[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OC(C)CC(=O)[*].[*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*]',\n",
              " '[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCOC(=O)c1ccoc1C(=O)O[*]',\n",
              " '[*]OCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class PolyBERTEncoder(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "        self.polybert = AutoModel.from_pretrained('kuelumbus/polyBERT')\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('kuelumbus/polyBERT')\n",
        "        self.output_dim = output_dim\n",
        "        self.projection = nn.Linear(self.polybert.config.hidden_size, output_dim)\n",
        "\n",
        "    def forward(self, smiles_strings):\n",
        "        # Tokenize\n",
        "        encoded_input = self.tokenizer(smiles_strings,\n",
        "                                       padding=True,\n",
        "                                       truncation=True,\n",
        "                                       return_tensors='pt').to(next(self.polybert.parameters()).device)\n",
        "\n",
        "        # Raw PolyBERT output\n",
        "        with torch.no_grad():\n",
        "            model_output = self.polybert(**encoded_input)\n",
        "        sequence_embeddings = model_output.last_hidden_state  # [batch, seq_len, hidden_size]\n",
        "        print(\"Raw Sequence Embeddings Shape:\", sequence_embeddings.shape)\n",
        "        print(\"Raw Sequence Embeddings Sample:\", sequence_embeddings[0, :5, :5])  # First 5 tokens, 5 dims\n",
        "\n",
        "        # Mean pooling over sequence length\n",
        "        raw_embeddings = sequence_embeddings.mean(dim=1)  # [batch, hidden_size]\n",
        "        print(\"Raw Pooled Embeddings Shape:\", raw_embeddings.shape)\n",
        "        print(\"Raw Pooled Cos Sim:\", cosine_similarity(raw_embeddings.cpu().numpy()).mean())\n",
        "        print(\"Raw Pooled Sample:\", raw_embeddings[:5, :5])\n",
        "\n",
        "        # Projection\n",
        "        projected_output = self.projection(sequence_embeddings)  # [batch, seq_len, output_dim]\n",
        "        print(\"Projected Embeddings Shape:\", projected_output.shape)\n",
        "        projected_pooled = projected_output.mean(dim=1)  # [batch, output_dim]\n",
        "        print(\"Projected Pooled Cos Sim:\", cosine_similarity(projected_pooled.cpu().detach().numpy()).mean())\n",
        "        print(\"Projected Pooled Sample:\", projected_pooled[:5, :5])\n",
        "\n",
        "        return projected_output  # Still returns [batch, seq_len, output_dim]\n",
        "\n",
        "# Test with your SMILES list\n",
        "smiles_list = list(df_combined['smiles'].unique())\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "polybert_encoder = PolyBERTEncoder(output_dim=256).to(device)\n",
        "raw_projected_embeddings = polybert_encoder(smiles_list)\n",
        "\n",
        "# Normalize and check\n",
        "normalized_embeddings = raw_projected_embeddings.mean(dim=1)  # Pool to [batch, 256]\n",
        "normalized_embeddings = normalized_embeddings / normalized_embeddings.norm(dim=-1, keepdim=True).clamp(min=1e-7)\n",
        "print(\"Normalized Embeddings Shape:\", normalized_embeddings.shape)\n",
        "print(\"Normalized Cos Sim:\", cosine_similarity(normalized_embeddings.cpu().detach().numpy()).mean())\n",
        "print(\"Normalized Sample:\", normalized_embeddings[:5, :5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7O9KjrrCP-z",
        "outputId": "d22ec93d-46c7-49ee-ec6a-1620a987fec4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Sequence Embeddings Shape: torch.Size([30, 126, 600])\n",
            "Raw Sequence Embeddings Sample: tensor([[-0.0092,  0.2755, -0.4806, -1.4089, -2.2509],\n",
            "        [-0.0430,  0.4276, -0.5884, -1.4104, -2.2687],\n",
            "        [ 0.0815,  0.0174,  0.4578, -0.9439, -1.9573],\n",
            "        [ 0.7367, -0.3353, -0.0622, -0.3803, -1.8088],\n",
            "        [ 0.5147,  0.4097,  0.1846, -2.0083, -1.0798]], device='cuda:0')\n",
            "Raw Pooled Embeddings Shape: torch.Size([30, 600])\n",
            "Raw Pooled Cos Sim: 0.8083693\n",
            "Raw Pooled Sample: tensor([[ 1.2551,  1.3380, -0.4130,  0.4943, -1.3191],\n",
            "        [ 1.1604,  1.5419, -0.5716,  0.1570, -0.9123],\n",
            "        [ 1.0575,  0.8955, -0.0894,  1.2649, -0.8457],\n",
            "        [ 1.3844,  1.4011, -0.4012,  0.4703, -1.4604],\n",
            "        [ 1.1788,  1.4684, -0.5570,  0.2999, -0.8306]], device='cuda:0')\n",
            "Projected Embeddings Shape: torch.Size([30, 126, 256])\n",
            "Projected Pooled Cos Sim: 0.79702175\n",
            "Projected Pooled Sample: tensor([[-0.1068,  0.4629, -1.1883, -0.3747, -0.4732],\n",
            "        [-0.3430,  0.4556, -1.1637, -0.3639, -0.6661],\n",
            "        [ 0.7593,  0.5521, -0.7295, -0.4166, -0.6397],\n",
            "        [-0.1151,  0.4803, -1.1393, -0.3835, -0.5172],\n",
            "        [-0.2902,  0.4933, -1.1035, -0.3357, -0.6607]], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Normalized Embeddings Shape: torch.Size([30, 256])\n",
            "Normalized Cos Sim: 0.79702175\n",
            "Normalized Sample: tensor([[-0.0125,  0.0541, -0.1389, -0.0438, -0.0553],\n",
            "        [-0.0387,  0.0514, -0.1313, -0.0410, -0.0751],\n",
            "        [ 0.1055,  0.0767, -0.1013, -0.0579, -0.0889],\n",
            "        [-0.0136,  0.0567, -0.1345, -0.0453, -0.0611],\n",
            "        [-0.0331,  0.0562, -0.1258, -0.0383, -0.0753]], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Pick diverse SMILES\n",
        "test_smiles = [\n",
        "    \"[*]CCO[*]\",\n",
        "    \"[*]NCCCCNCCCC(=O)O[*]\",\n",
        "    \"[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]\",\n",
        "    \"[*]OC(C)C(=O)[*]\"\n",
        "]\n",
        "polybert_encoder = PolyBERTEncoder(output_dim=256).to(device)\n",
        "raw_projected = polybert_encoder(test_smiles)\n",
        "pooled_embeddings = raw_projected.mean(dim=1)\n",
        "cos_sim_matrix = cosine_similarity(pooled_embeddings.cpu().detach().numpy())\n",
        "print(\"Pairwise Cos Sim Matrix:\\n\", cos_sim_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v-yuC1bGX-v",
        "outputId": "51619dc6-3f63-477f-d239-7a1926f5a1e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Sequence Embeddings Shape: torch.Size([4, 30, 600])\n",
            "Raw Sequence Embeddings Sample: tensor([[ 0.2641,  0.4064, -0.9320, -1.0198, -1.7431],\n",
            "        [ 0.2463,  0.4902, -0.9593, -1.0126, -1.6991],\n",
            "        [ 0.5188,  0.1787,  0.1840, -0.7893, -1.7386],\n",
            "        [ 0.9525,  0.4810,  0.6171, -0.9781, -1.4589],\n",
            "        [ 1.1858,  0.6167, -0.4118, -0.9430, -1.9459]], device='cuda:0')\n",
            "Raw Pooled Embeddings Shape: torch.Size([4, 600])\n",
            "Raw Pooled Cos Sim: 0.7310372\n",
            "Raw Pooled Sample: tensor([[ 1.2448,  1.3446, -0.5050,  0.2491, -1.6926],\n",
            "        [ 0.9182,  0.7017,  0.6000, -0.4046, -0.5265],\n",
            "        [ 0.8717,  0.0715,  0.9499,  0.4704, -1.1281],\n",
            "        [ 0.8698,  0.8205,  0.1322, -0.8960, -1.7721]], device='cuda:0')\n",
            "Projected Embeddings Shape: torch.Size([4, 30, 256])\n",
            "Projected Pooled Cos Sim: 0.6988541\n",
            "Projected Pooled Sample: tensor([[ 0.7583,  0.2264,  0.1378,  0.0696, -0.3924],\n",
            "        [ 0.4842,  0.4137, -0.0345,  0.6175, -0.4094],\n",
            "        [ 0.1576, -0.0158, -0.1312, -0.0887, -0.1899],\n",
            "        [ 0.7312,  0.5805, -0.2673, -0.1617, -0.6041]], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Pairwise Cos Sim Matrix:\n",
            " [[1.         0.6082244  0.5001226  0.7740312 ]\n",
            " [0.6082244  0.99999976 0.5012369  0.6790423 ]\n",
            " [0.5001226  0.5012369  0.99999976 0.5281758 ]\n",
            " [0.7740312  0.6790423  0.5281758  0.9999999 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "class PolyBERTEncoder(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "        self.polybert = AutoModel.from_pretrained('kuelumbus/polyBERT')\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('kuelumbus/polyBERT')\n",
        "        self.output_dim = output_dim\n",
        "        self.projection = nn.Linear(self.polybert.config.hidden_size, output_dim)\n",
        "\n",
        "    def forward(self, smiles_strings):\n",
        "        encoded_input = self.tokenizer(smiles_strings,\n",
        "                                       padding=True,\n",
        "                                       truncation=True,\n",
        "                                       return_tensors='pt').to(next(self.polybert.parameters()).device)\n",
        "        with torch.no_grad():\n",
        "            model_output = self.polybert(**encoded_input)\n",
        "        sequence_embeddings = model_output.last_hidden_state\n",
        "        projected_output = self.projection(sequence_embeddings)\n",
        "        return projected_output\n",
        "\n",
        "# SMILES list\n",
        "smiles_list = [\n",
        "    '[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)CC(=O)O[*]',\n",
        "    '[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]',\n",
        "    '[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*]',\n",
        "    '[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OC(C)CC(=O)[*].[*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*]',\n",
        "    '[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCOC(=O)c1ccoc1C(=O)O[*]',\n",
        "    '[*]OCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]',\n",
        "    '[*]CCO[*]',\n",
        "    '[*]NCCCCNCCCC(=O)O[*]',\n",
        "    '[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]',\n",
        "    '[*]OC(C)C(=O)[*]'\n",
        "]\n",
        "\n",
        "# Short labels for plotting\n",
        "labels = [\n",
        "    'Copolymer 1 (4 segments)',\n",
        "    'Copolymer 2 (2 segments)',\n",
        "    'Copolymer 3 (2 segments)',\n",
        "    'Copolymer 4 (5 segments)',\n",
        "    'Copolymer 5 (2 segments)',\n",
        "    'Copolymer 6 (3 segments)',\n",
        "    'CCO',\n",
        "    'NCCCCNCCCC(=O)O',\n",
        "    'OCCOC(=O)c1ccc(cc1)C(=O)O',\n",
        "    'OC(C)C(=O)'\n",
        "]\n",
        "\n",
        "# Compute embeddings\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "polybert_encoder = PolyBERTEncoder(output_dim=256).to(device)\n",
        "raw_projected = polybert_encoder(smiles_list)\n",
        "pooled_embeddings = raw_projected.mean(dim=1)  # [10, 256]\n",
        "cos_sim_matrix = cosine_similarity(pooled_embeddings.cpu().detach().numpy())\n",
        "\n",
        "# Print matrix\n",
        "print(\"Pairwise Cosine Similarity Matrix:\\n\", cos_sim_matrix)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cos_sim_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
        "            xticklabels=labels, yticklabels=labels, square=True)\n",
        "plt.title('Cosine Similarity of PolyBERT Embeddings for SMILES Strings', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k0fUy4klHxLG",
        "outputId": "dbecd5a6-5a78-4aac-8783-59cd0b9f861a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pairwise Cosine Similarity Matrix:\n",
            " [[0.9999999  0.7753461  0.8893608  0.8860746  0.8429448  0.94228286\n",
            "  0.35395128 0.46348843 0.45312524 0.3810813 ]\n",
            " [0.7753461  0.9999998  0.8816548  0.80848855 0.87644416 0.87584466\n",
            "  0.5422297  0.6171322  0.74383485 0.5617026 ]\n",
            " [0.8893608  0.8816548  1.0000001  0.8567298  0.82729024 0.87884575\n",
            "  0.5400808  0.6653832  0.6806501  0.5872549 ]\n",
            " [0.8860746  0.80848855 0.8567298  1.         0.76514184 0.83787435\n",
            "  0.5019182  0.5606267  0.5984615  0.5292397 ]\n",
            " [0.8429448  0.87644416 0.82729024 0.76514184 0.99999994 0.94439363\n",
            "  0.40272665 0.44330746 0.5133944  0.394264  ]\n",
            " [0.94228286 0.87584466 0.87884575 0.83787435 0.94439363 0.9999997\n",
            "  0.358656   0.44335613 0.48699635 0.364854  ]\n",
            " [0.35395128 0.5422297  0.5400808  0.5019182  0.40272665 0.358656\n",
            "  1.0000001  0.8691161  0.81571615 0.93919456]\n",
            " [0.46348843 0.6171322  0.6653832  0.5606267  0.44330746 0.44335613\n",
            "  0.8691161  1.         0.86274904 0.928212  ]\n",
            " [0.45312524 0.74383485 0.6806501  0.5984615  0.5133944  0.48699635\n",
            "  0.81571615 0.86274904 0.9999997  0.86597884]\n",
            " [0.3810813  0.5617026  0.5872549  0.5292397  0.394264   0.364854\n",
            "  0.93919456 0.928212   0.86597884 0.9999999 ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_df = df_combined.drop_duplicates(subset=['smiles'])\n",
        "unique_df = unique_df.reset_index(drop=True)\n",
        "unique_df\n"
      ],
      "metadata": {
        "id": "X28MrIcuqS2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "883a000c-3825-4165-8ade-95437f09efbd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Plastic Type                      Enzyme Name  \\\n",
              "0                                 PCL                         Cutinase   \n",
              "1                                 PVA                PVA_dehydrogenase   \n",
              "2           P3HP_P4HB_PEA_PES_PHB_PHA                 PHB_depolymerase   \n",
              "3                                 PLA                 PLA_depolymerase   \n",
              "4                                 PEG                PEG_dehydrogenase   \n",
              "5                   PCL_PHA_PHBV_PHPV             MCL_PHA_depolymerase   \n",
              "6                               Nylon  Nylon_Oligomer_Degrading_Enzyme   \n",
              "7   PBAT_PBS_PBSA_PCL_PET_PHB_PLA_PHA                         Cutinase   \n",
              "8                             PCL_PET                         Cutinase   \n",
              "9                        PBS_PBSA_PCL                         Esterase   \n",
              "10                        PES_PCL_PET                         Cutinase   \n",
              "11                            PET_PLA                         Cutinase   \n",
              "12                            PET_PCL                        Hydrolase   \n",
              "13                       PLA_PCL_PBSA                        Hydrolase   \n",
              "14                           PLA_PBSA                         Esterase   \n",
              "15              PBAT_PBS_PBSA_PCL_PES                        Hydrolase   \n",
              "16                  PBAT_PBSA_PES_PCL                        Hydrolase   \n",
              "17                                PBS                 PBS_depolymerase   \n",
              "18                PBS_PCL_PHB_PLA_PHA                         Cutinase   \n",
              "19       PLA_PBS_PBSA_PCL_PES_PHB_PHA                 PLA_depolymerase   \n",
              "20           PBS_PBSA_PCL_PES_PLA_PHA                 PLA_depolymerase   \n",
              "21       PBS_PBSA_PCL_PES_PHB_PLA_PHA                 PLA_depolymerase   \n",
              "22                            PET_PEF                           PETase   \n",
              "23          PLA_PHBV_PCL_PBSA_PES_PHA                        Hydrolase   \n",
              "24                           PBS_PBSA                         Cutinase   \n",
              "25                    PLA_PHA_PES_PCL                           Lipase   \n",
              "26                            PHB_PHA                 PHB_depolymerase   \n",
              "27                  P(3HB-co-3MP)_PHA                 PHA_depolymerase   \n",
              "28                                PET                         Cutinase   \n",
              "29                                 PE               Alkane_hydroxylase   \n",
              "\n",
              "                                     protein_sequence  \\\n",
              "0   MKFFALTTLLAATASALPTSHPVQELEARQLGGGTTRNDLTNGNSA...   \n",
              "1   MQQNIERNQVSMTTSRFVWGAVMALVALGSASAAELNLPDGAALYR...   \n",
              "2   MTKQSLPQGMADQRLCRFFTAALCSLLMLLLWPTTVTAGQTFSYTS...   \n",
              "3   MRKLKLLLMVCMSMVFIFTLPGMGQSLKASAATERTPIVFVHGLTG...   \n",
              "4   MCLVTLYRCTPIWVRNRGMHKFDFVVVGAGSAGCTVASRLSENGKY...   \n",
              "5   MLAPRSLLFCLLLFALPNAFADSRCSERAKTLLLPAKVSCSYKTTW...   \n",
              "6   MLRFDFPGVSIGAAHYEEGPTGATVIHIPAGARTAVDARGGAVGLS...   \n",
              "7   MRIRRQAGTGARASMARAIGVMTTALAVLVGAVGGVAGAEVSTAQD...   \n",
              "8   MLPAGQDAAALEARQLGGSITRNDLANGNSGSCPGVIFIYARGSTE...   \n",
              "9   MQFKSTFAALVLAAAGLVQAAPLQERAGCSSYVIINTRGTSEPQGP...   \n",
              "10  MVRVFGLTLLALLVPALAAPVPEDLEARQSGCADVMVVYARGTDQD...   \n",
              "11  MANPYERGPNPTDALLEASSGPFSVSEENVSRLSASGFGGGTIYYP...   \n",
              "12  MKRTLKRALSLLPAAALAASALVAASPAQAAANPYQRGPNPTEASI...   \n",
              "13  MSDLVWSRDGLDWPHREASRFIEAGGFRWHVQRMGSPAAPAILLIH...   \n",
              "14  MTAIIRQGRYQGLSSKGVTEYRGIPFAKAPLGEWRFKAPQPLPDSE...   \n",
              "15  MKRRLIAYSIAALAISATAVALPTGVASAAPCSDVDVSFARGTGEL...   \n",
              "16  MKVILFKKRSLQILVALALVIGSMAFIQPKEVKAAEHNPVVMVHGI...   \n",
              "17  MHLPRSRWDIPFKEETTMTHHFSVRALLAAGALLASAAVSAQTNPY...   \n",
              "18  MLVSALALAVLSAASLGRAAPTPESAEAHELEARATSSACPQYVLI...   \n",
              "19  MEMVKGVHLAIAALLFLCVLPGNADASEKQFDLVLVHGLTNKHRWS...   \n",
              "20  MHESVHAESLWLTMDDGAEVYVRVWEPAARAAADSSDDAPAPPAAA...   \n",
              "21  MLLKKRWLIFISFLLAFTLLIPTAASASEKHYKPNIALEPIENSEG...   \n",
              "22  MNFPRASRLMQAAVLGGLMAVSAAATAQTNPYARGPNPTAASLEAS...   \n",
              "23  MQSGTVASNGIELFYESRGPENGEPMVFVMGLSAQMVFWPDTLLDA...   \n",
              "24  MHLRNIVIALAATAVASPVDLQDRQLTGGDELRDGPCKPITFIFAR...   \n",
              "25  MTMTLLYRDMNQAQLDAAYNNTQAVPDFPGIYAALQARSASFYASA...   \n",
              "26  MKHPYGYRWHWLYALVVTLMTALATFSAHAAVTAGPGAWSSQQTWA...   \n",
              "27  MRSIRLKRLIAAVALGGAAAATQAASPLPRLNVDKTQISVSGLSAG...   \n",
              "28  MANPYERGPNPTDALLEARSGPFSVSEENVSRLSASGFGGGTIYYP...   \n",
              "29  EHIRGHHVHVSTPEDASSSRFGQSLYAFLPHAYKHNFLNAWRLEAE...   \n",
              "\n",
              "                                               smiles  protein_length  \\\n",
              "0                                    [*]OCCCCC(=O)[*]             231   \n",
              "1                                                 CCO             639   \n",
              "2   [*]OCCOC(=O)CC(=O)O[*].[*]OC(C)CC(=O)[*].[*]OC...             576   \n",
              "3                                    [*]OC(C)C(=O)[*]             201   \n",
              "4                                                OCCO             553   \n",
              "5                  [*]OCCCCC(=O)[*].[*]OC(C)CC(=O)[*]             277   \n",
              "6                                     NCCCCNCCCC(=O)O             306   \n",
              "7   [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             304   \n",
              "8    [*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             226   \n",
              "9   [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             224   \n",
              "10  [*]OCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCC...             203   \n",
              "11   [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OC(C)C(=O)[*]             262   \n",
              "12   [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCCCC(=O)[*]             292   \n",
              "13  [*]OC(C)C(=O)[*].[*]OCCCCC(=O)[*].[*]OCCCCOC(=...             295   \n",
              "14          [*]OC(C)C(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*]             505   \n",
              "15  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             216   \n",
              "16  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCOC(=O)CC(=O)O[*...             215   \n",
              "17                           [*]OCCCCOC(=O)CC(=O)O[*]             304   \n",
              "18  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]O...             238   \n",
              "19  [*]OC(C)C(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]O...             283   \n",
              "20  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             338   \n",
              "21  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             431   \n",
              "22  [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCOC(=O)c1...             290   \n",
              "23  [*]OC(C)C(=O)[*].[*]OCCCCC(=O)[*].[*]OCCCCOC(=...             305   \n",
              "24  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*]             213   \n",
              "25  [*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*].[*]OCCOC(=O...             275   \n",
              "26                [*]OC(C)CC(=O)[*].[*]OC(C)CC(=O)[*]             492   \n",
              "27                                  [*]OC(C)CC(=O)[*]             492   \n",
              "28                    [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             262   \n",
              "29                                           [*]CC[*]             108   \n",
              "\n",
              "   synthetic  cluster  Cluster  \n",
              "0        NaN     13.0        7  \n",
              "1        NaN      2.0        5  \n",
              "2        NaN      6.0       12  \n",
              "3        NaN      8.0        4  \n",
              "4        NaN     18.0       15  \n",
              "5        NaN     15.0       17  \n",
              "6        NaN      5.0        3  \n",
              "7        NaN     12.0       16  \n",
              "8        NaN      1.0        8  \n",
              "9        NaN      3.0       21  \n",
              "10       NaN     17.0       18  \n",
              "11       NaN     11.0       11  \n",
              "12       NaN      1.0        8  \n",
              "13       NaN     19.0        6  \n",
              "14       NaN      9.0       19  \n",
              "15       NaN      3.0       14  \n",
              "16       NaN      3.0       14  \n",
              "17       NaN     10.0        0  \n",
              "18       NaN      0.0       20  \n",
              "19       NaN      0.0        9  \n",
              "20       NaN      0.0        9  \n",
              "21       NaN      0.0        9  \n",
              "22       NaN      7.0       13  \n",
              "23       NaN      0.0        9  \n",
              "24       NaN     10.0        0  \n",
              "25       NaN      0.0       22  \n",
              "26       NaN      4.0        2  \n",
              "27       NaN      4.0        2  \n",
              "28       NaN     16.0        1  \n",
              "29       NaN     14.0       10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afd7dbdd-21d6-426d-9870-3f3c902dad23\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plastic Type</th>\n",
              "      <th>Enzyme Name</th>\n",
              "      <th>protein_sequence</th>\n",
              "      <th>smiles</th>\n",
              "      <th>protein_length</th>\n",
              "      <th>synthetic</th>\n",
              "      <th>cluster</th>\n",
              "      <th>Cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PCL</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MKFFALTTLLAATASALPTSHPVQELEARQLGGGTTRNDLTNGNSA...</td>\n",
              "      <td>[*]OCCCCC(=O)[*]</td>\n",
              "      <td>231</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PVA</td>\n",
              "      <td>PVA_dehydrogenase</td>\n",
              "      <td>MQQNIERNQVSMTTSRFVWGAVMALVALGSASAAELNLPDGAALYR...</td>\n",
              "      <td>CCO</td>\n",
              "      <td>639</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P3HP_P4HB_PEA_PES_PHB_PHA</td>\n",
              "      <td>PHB_depolymerase</td>\n",
              "      <td>MTKQSLPQGMADQRLCRFFTAALCSLLMLLLWPTTVTAGQTFSYTS...</td>\n",
              "      <td>[*]OCCOC(=O)CC(=O)O[*].[*]OC(C)CC(=O)[*].[*]OC...</td>\n",
              "      <td>576</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PLA</td>\n",
              "      <td>PLA_depolymerase</td>\n",
              "      <td>MRKLKLLLMVCMSMVFIFTLPGMGQSLKASAATERTPIVFVHGLTG...</td>\n",
              "      <td>[*]OC(C)C(=O)[*]</td>\n",
              "      <td>201</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PEG</td>\n",
              "      <td>PEG_dehydrogenase</td>\n",
              "      <td>MCLVTLYRCTPIWVRNRGMHKFDFVVVGAGSAGCTVASRLSENGKY...</td>\n",
              "      <td>OCCO</td>\n",
              "      <td>553</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PCL_PHA_PHBV_PHPV</td>\n",
              "      <td>MCL_PHA_depolymerase</td>\n",
              "      <td>MLAPRSLLFCLLLFALPNAFADSRCSERAKTLLLPAKVSCSYKTTW...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OC(C)CC(=O)[*]</td>\n",
              "      <td>277</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Nylon</td>\n",
              "      <td>Nylon_Oligomer_Degrading_Enzyme</td>\n",
              "      <td>MLRFDFPGVSIGAAHYEEGPTGATVIHIPAGARTAVDARGGAVGLS...</td>\n",
              "      <td>NCCCCNCCCC(=O)O</td>\n",
              "      <td>306</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PBAT_PBS_PBSA_PCL_PET_PHB_PLA_PHA</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MRIRRQAGTGARASMARAIGVMTTALAVLVGAVGGVAGAEVSTAQD...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>PCL_PET</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MLPAGQDAAALEARQLGGSITRNDLANGNSGSCPGVIFIYARGSTE...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>226</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PBS_PBSA_PCL</td>\n",
              "      <td>Esterase</td>\n",
              "      <td>MQFKSTFAALVLAAAGLVQAAPLQERAGCSSYVIINTRGTSEPQGP...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>PES_PCL_PET</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MVRVFGLTLLALLVPALAAPVPEDLEARQSGCADVMVVYARGTDQD...</td>\n",
              "      <td>[*]OCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCC...</td>\n",
              "      <td>203</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>PET_PLA</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MANPYERGPNPTDALLEASSGPFSVSEENVSRLSASGFGGGTIYYP...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OC(C)C(=O)[*]</td>\n",
              "      <td>262</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PET_PCL</td>\n",
              "      <td>Hydrolase</td>\n",
              "      <td>MKRTLKRALSLLPAAALAASALVAASPAQAAANPYQRGPNPTEASI...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCCCC(=O)[*]</td>\n",
              "      <td>292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PLA_PCL_PBSA</td>\n",
              "      <td>Hydrolase</td>\n",
              "      <td>MSDLVWSRDGLDWPHREASRFIEAGGFRWHVQRMGSPAAPAILLIH...</td>\n",
              "      <td>[*]OC(C)C(=O)[*].[*]OCCCCC(=O)[*].[*]OCCCCOC(=...</td>\n",
              "      <td>295</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>PLA_PBSA</td>\n",
              "      <td>Esterase</td>\n",
              "      <td>MTAIIRQGRYQGLSSKGVTEYRGIPFAKAPLGEWRFKAPQPLPDSE...</td>\n",
              "      <td>[*]OC(C)C(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*]</td>\n",
              "      <td>505</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>PBAT_PBS_PBSA_PCL_PES</td>\n",
              "      <td>Hydrolase</td>\n",
              "      <td>MKRRLIAYSIAALAISATAVALPTGVASAAPCSDVDVSFARGTGEL...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>216</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>PBAT_PBSA_PES_PCL</td>\n",
              "      <td>Hydrolase</td>\n",
              "      <td>MKVILFKKRSLQILVALALVIGSMAFIQPKEVKAAEHNPVVMVHGI...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCOC(=O)CC(=O)O[*...</td>\n",
              "      <td>215</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>PBS</td>\n",
              "      <td>PBS_depolymerase</td>\n",
              "      <td>MHLPRSRWDIPFKEETTMTHHFSVRALLAAGALLASAAVSAQTNPY...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*]</td>\n",
              "      <td>304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>PBS_PCL_PHB_PLA_PHA</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MLVSALALAVLSAASLGRAAPTPESAEAHELEARATSSACPQYVLI...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]O...</td>\n",
              "      <td>238</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>PLA_PBS_PBSA_PCL_PES_PHB_PHA</td>\n",
              "      <td>PLA_depolymerase</td>\n",
              "      <td>MEMVKGVHLAIAALLFLCVLPGNADASEKQFDLVLVHGLTNKHRWS...</td>\n",
              "      <td>[*]OC(C)C(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]O...</td>\n",
              "      <td>283</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>PBS_PBSA_PCL_PES_PLA_PHA</td>\n",
              "      <td>PLA_depolymerase</td>\n",
              "      <td>MHESVHAESLWLTMDDGAEVYVRVWEPAARAAADSSDDAPAPPAAA...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>338</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>PBS_PBSA_PCL_PES_PHB_PLA_PHA</td>\n",
              "      <td>PLA_depolymerase</td>\n",
              "      <td>MLLKKRWLIFISFLLAFTLLIPTAASASEKHYKPNIALEPIENSEG...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>431</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>PET_PEF</td>\n",
              "      <td>PETase</td>\n",
              "      <td>MNFPRASRLMQAAVLGGLMAVSAAATAQTNPYARGPNPTAASLEAS...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCOC(=O)c1...</td>\n",
              "      <td>290</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>PLA_PHBV_PCL_PBSA_PES_PHA</td>\n",
              "      <td>Hydrolase</td>\n",
              "      <td>MQSGTVASNGIELFYESRGPENGEPMVFVMGLSAQMVFWPDTLLDA...</td>\n",
              "      <td>[*]OC(C)C(=O)[*].[*]OCCCCC(=O)[*].[*]OCCCCOC(=...</td>\n",
              "      <td>305</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>PBS_PBSA</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MHLRNIVIALAATAVASPVDLQDRQLTGGDELRDGPCKPITFIFAR...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*]</td>\n",
              "      <td>213</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>PLA_PHA_PES_PCL</td>\n",
              "      <td>Lipase</td>\n",
              "      <td>MTMTLLYRDMNQAQLDAAYNNTQAVPDFPGIYAALQARSASFYASA...</td>\n",
              "      <td>[*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*].[*]OCCOC(=O...</td>\n",
              "      <td>275</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>PHB_PHA</td>\n",
              "      <td>PHB_depolymerase</td>\n",
              "      <td>MKHPYGYRWHWLYALVVTLMTALATFSAHAAVTAGPGAWSSQQTWA...</td>\n",
              "      <td>[*]OC(C)CC(=O)[*].[*]OC(C)CC(=O)[*]</td>\n",
              "      <td>492</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>P(3HB-co-3MP)_PHA</td>\n",
              "      <td>PHA_depolymerase</td>\n",
              "      <td>MRSIRLKRLIAAVALGGAAAATQAASPLPRLNVDKTQISVSGLSAG...</td>\n",
              "      <td>[*]OC(C)CC(=O)[*]</td>\n",
              "      <td>492</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>PET</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MANPYERGPNPTDALLEARSGPFSVSEENVSRLSASGFGGGTIYYP...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>262</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>PE</td>\n",
              "      <td>Alkane_hydroxylase</td>\n",
              "      <td>EHIRGHHVHVSTPEDASSSRFGQSLYAFLPHAYKHNFLNAWRLEAE...</td>\n",
              "      <td>[*]CC[*]</td>\n",
              "      <td>108</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afd7dbdd-21d6-426d-9870-3f3c902dad23')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-afd7dbdd-21d6-426d-9870-3f3c902dad23 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-afd7dbdd-21d6-426d-9870-3f3c902dad23');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d8d58454-9233-4d11-9f6e-a53ecdf62241\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8d58454-9233-4d11-9f6e-a53ecdf62241')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d8d58454-9233-4d11-9f6e-a53ecdf62241 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5cb596d0-f27f-4ec6-99b1-65a504cc5aac\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('unique_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5cb596d0-f27f-4ec6-99b1-65a504cc5aac button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('unique_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "unique_df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_df.to_csv('unique_df.csv')"
      ],
      "metadata": {
        "id": "8mI4X7dEq00g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "6E8LaJkIs7CV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-j9ixx3b9WW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348ccbfd-e33c-46fc-9b3d-71b40411f51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 4131 samples, 9 clusters\n",
            "Validation set: 383 samples, 3 clusters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-4704e4346094>:85: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return df.groupby('cluster', group_keys=False).apply(lambda x: x.sample(frac=subset_fraction, random_state=42))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "# Load dataset\n",
        "df_combined = pd.read_csv('sigma_data.csv')\n",
        "df_combined = df_combined.drop(columns=[col for col in ['cluster', 'Cluster'] if col in df_combined.columns], errors='ignore')\n",
        "\n",
        "# Ensure SMILES have [*] markers\n",
        "def format_smiles(smiles):\n",
        "    if not smiles.startswith('[*]'):\n",
        "        smiles = '[*]' + smiles\n",
        "    if not smiles.endswith('[*]'):\n",
        "        smiles = smiles + '[*]'\n",
        "    return smiles\n",
        "\n",
        "df_combined['smiles'] = df_combined['smiles'].apply(format_smiles)\n",
        "\n",
        "class PolyBERTEncoder(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "        self.polybert = AutoModel.from_pretrained('kuelumbus/polyBERT')\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('kuelumbus/polyBERT')\n",
        "        self.output_dim = output_dim\n",
        "        # Project each token embedding to required dimension\n",
        "        self.projection = nn.Linear(self.polybert.config.hidden_size, output_dim)\n",
        "\n",
        "    def forward(self, smiles_strings):\n",
        "        # Tokenize the SMILES strings\n",
        "        encoded_input = self.tokenizer(smiles_strings,\n",
        "                                     padding=True,\n",
        "                                     truncation=True,\n",
        "                                     return_tensors='pt').to(next(self.polybert.parameters()).device)\n",
        "\n",
        "        # Get PolyBERT embeddings\n",
        "        with torch.no_grad():\n",
        "            model_output = self.polybert(**encoded_input)\n",
        "\n",
        "        # Debug prints\n",
        "        # print(\"Model Output Keys:\", model_output.keys())\n",
        "        # print(\"Last Hidden State Shape:\", model_output.last_hidden_state.shape)  # [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        # Get sequence embeddings\n",
        "        sequence_embeddings = model_output.last_hidden_state\n",
        "\n",
        "        # Project each token embedding to required dimension\n",
        "        projected_output = self.projection(sequence_embeddings)  # [batch_size, seq_len, output_dim]\n",
        "        # print(\"Projected Output Shape:\", projected_output.shape)\n",
        "        # Take the mean over the sequence length dimension\n",
        "        pooled_output = projected_output.mean(dim=1)  # [batch_size, output_dim]\n",
        "\n",
        "        return pooled_output\n",
        "\n",
        "# Initialize PolyBERT Encoder\n",
        "encoder = PolyBERTEncoder(output_dim=256).eval().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Encode SMILES strings\n",
        "fingerprints = []\n",
        "valid_indices = []\n",
        "\n",
        "for i, smiles in enumerate(df_combined['smiles']):\n",
        "    try:\n",
        "        fp = encoder([smiles])  # [1, output_dim] after mean pooling\n",
        "        fingerprints.append(fp.detach().cpu().numpy().flatten())  # Ensure it's 1D\n",
        "        valid_indices.append(i)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing SMILES {smiles}: {e}\")\n",
        "\n",
        "X = np.vstack(fingerprints)\n",
        "n_clusters = 12\n",
        "\n",
        "# Apply KMeans Clustering\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=15)\n",
        "cluster_labels = kmeans.fit_predict(X)\n",
        "\n",
        "df_valid = df_combined.iloc[valid_indices].copy()\n",
        "df_valid['cluster'] = cluster_labels\n",
        "\n",
        "# Subset selection\n",
        "def subset_clusters(df, subset_fraction=0.5):\n",
        "    return df.groupby('cluster', group_keys=False).apply(lambda x: x.sample(frac=subset_fraction, random_state=42))\n",
        "\n",
        "df_subset = subset_clusters(df_valid, subset_fraction=0.5)\n",
        "cluster_centers = kmeans.cluster_centers_\n",
        "\n",
        "# Splitting by cluster dissimilarity\n",
        "def split_by_cluster_dissimilarity(df, cluster_centers, val_size=0.3):\n",
        "    unique_clusters = df['cluster'].unique()\n",
        "    n_clusters = len(unique_clusters)\n",
        "    n_val = int(n_clusters * val_size)\n",
        "    distances = euclidean_distances(cluster_centers)\n",
        "    np.random.seed(42)\n",
        "    current_cluster = np.random.choice(unique_clusters)\n",
        "    val_clusters = [current_cluster]\n",
        "    remaining_clusters = set(unique_clusters) - {current_cluster}\n",
        "\n",
        "    while len(val_clusters) < n_val:\n",
        "        avg_distances = [(cluster, np.mean([distances[cluster, val_cluster] for val_cluster in val_clusters])) for cluster in remaining_clusters]\n",
        "        next_cluster = max(avg_distances, key=lambda x: x[1])[0]\n",
        "        val_clusters.append(next_cluster)\n",
        "        remaining_clusters.remove(next_cluster)\n",
        "\n",
        "    train_clusters = list(set(unique_clusters) - set(val_clusters))\n",
        "    return df[df['cluster'].isin(train_clusters)], df[df['cluster'].isin(val_clusters)]\n",
        "\n",
        "train_df, val_df = split_by_cluster_dissimilarity(df_subset, cluster_centers)\n",
        "\n",
        "print(f\"Training set: {len(train_df)} samples, {train_df['cluster'].nunique()} clusters\")\n",
        "print(f\"Validation set: {len(val_df)} samples, {val_df['cluster'].nunique()} clusters\")\n",
        "\n",
        "train_df.to_csv('train_data.csv', index=False)\n",
        "val_df.to_csv('val_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move cluster 0 from val_df to train_df\n",
        "cluster_0_data = val_df[val_df['cluster'] == 0]\n",
        "val_df = val_df[val_df['cluster'] != 0]  # Remove from val_df\n",
        "\n",
        "# Move cluster 3 from train_df to val_df\n",
        "cluster_3_data = train_df[train_df['cluster'] == 3]\n",
        "train_df = train_df[train_df['cluster'] != 3]  # Remove from train_df\n",
        "\n",
        "# Swap the clusters\n",
        "train_df = pd.concat([train_df, cluster_0_data], ignore_index=True)\n",
        "val_df = pd.concat([val_df, cluster_3_data], ignore_index=True)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_df.to_csv('train_data.csv', index=False)\n",
        "val_df.to_csv('val_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "0D4laRpg8G9x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Updated Training set: {len(train_df)} samples, {train_df['cluster'].nunique()} clusters\")\n",
        "print(f\"Updated Validation set: {len(val_df)} samples, {val_df['cluster'].nunique()} clusters\")"
      ],
      "metadata": {
        "id": "FU8t6iC_8PJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ec4123-a3fb-4ca8-b172-33e887290056"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Training set: 3469 samples, 9 clusters\n",
            "Updated Validation set: 1045 samples, 3 clusters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6_TVOHpq_FVj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "outputId": "aa37b24b-f88c-4b1f-c3bb-339e063d6cad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Plastic Type         Enzyme Name  \\\n",
              "0                                 PET              Lipase   \n",
              "1                                 PLA            Protease   \n",
              "2                               Nylon           Hydrolase   \n",
              "3                                PBSA              Lipase   \n",
              "4        PBS_PBSA_PCL_PES_PHB_PLA_PHA    PLA_depolymerase   \n",
              "5           P3HP_P4HB_PEA_PES_PHB_PHA    PHB_depolymerase   \n",
              "6                            PLA_PBSA            Esterase   \n",
              "7                 PBS_PCL_PHB_PLA_PHA            Cutinase   \n",
              "8                            PBS_PBSA            Cutinase   \n",
              "9        PLA_PBS_PBSA_PCL_PES_PHB_PHA    PLA_depolymerase   \n",
              "10                       PBS_PBSA_PCL            Esterase   \n",
              "11                  PBAT_PBSA_PES_PCL           Hydrolase   \n",
              "12          PLA_PHBV_PCL_PBSA_PES_PHA           Hydrolase   \n",
              "13                       PLA_PCL_PBSA            Esterase   \n",
              "14                    PLA_PHA_PES_PCL              Lipase   \n",
              "15           PBS_PBSA_PCL_PES_PLA_PHA    PLA_depolymerase   \n",
              "16  PBAT_PBS_PBSA_PCL_PET_PHB_PLA_PHA            Cutinase   \n",
              "17              PBAT_PBS_PBSA_PCL_PES           Hydrolase   \n",
              "18                                 PE  Alkane_hydroxylase   \n",
              "19                                PHA    PHA_depolymerase   \n",
              "20                            PET_PLA            Cutinase   \n",
              "21                            PET_PCL           Hydrolase   \n",
              "22                                PCL           Chitinase   \n",
              "23                            PCL_PET              PETase   \n",
              "24                            PET_PEF              PETase   \n",
              "25                        PES_PCL_PET            Cutinase   \n",
              "\n",
              "                                     protein_sequence  \\\n",
              "0   MKLLSLTVVAGVLATLVAATPLVKRAPSGSDPAFSQPKSVLLAGLT...   \n",
              "1   MMRKKSFWLGMLTAFMLVFTMAFSDSASAAQPAKNVEKDYIVGFKS...   \n",
              "2   MNARSTPQHPAADPGAAAGEPTLDDWQRPPHNRWAFAHVGELLPTA...   \n",
              "3   MNLVGHSQGGLTSRYVAAVAPELVASVTTIGTPHRGSEGADFVQSV...   \n",
              "4   MLLKKLTLIFISFLLAIILLIPAAASASEKDYKPGIALEPIKNSEG...   \n",
              "5   MTKQSLPQSMAKQRLCRFFTAALLSLLMLLLWPTTAHAGQTFSYTS...   \n",
              "6   MTAIIRQGRVQGLSSDGVTEFRGIPFAAAPLGELRFRAPQPLPDSE...   \n",
              "7   MLQSALALAVLSAASLGLAAPTPESAEAHELEARATSSACPSYVLI...   \n",
              "8   MHLRNIVIALAATAVASPVDLQDRQLSTNNELRDGPCKPITFIFAR...   \n",
              "9   MKTKKAVLLAIAALLFLTDLPGNAGASEKQRDLVLVHGLTNKHRWS...   \n",
              "10  MQFSSTFAALVLAAAGLVQAAPMQERASCSSYQIISTRGTSEPQGP...   \n",
              "11  MKNILFKKRFLQILLALMLVIGSFAFIQPKEVKAANQNPVVFVHGY...   \n",
              "12  MASGTVAANGIELFYESRGPENGEPMVLVMGLSCQMVFWPDTLLDA...   \n",
              "13  MALNSMKFLLGLIGLLLLITLSLEAWLLRREPSQLQAADINGELEQ...   \n",
              "14  MTDTLLYRDMNRAQLDAAYNNTAAVPDFPGIYAGHQARSASFYASH...   \n",
              "15  MAESVHAESEWLTTDDGAEVYVRVWEPAAGEAADSSAAAPAPPAAA...   \n",
              "16  MRIRRRAGTGARASMARAAGVGSTALAVVVGAVGGVAGAEVVTAQD...   \n",
              "17  MKRRLIAGSLAALAISAAAVALPTGAASAAPCSDVEVSFARGTGEL...   \n",
              "18  EHNRGHHVHVSTPEDPSSSRFGQSLYAFLPHAIWENFLNAWRLEAQ...   \n",
              "19  MRQGYIFRSVELDNISIRVAVRPGKPHLTPLLVLNGIGANLELVQP...   \n",
              "20  MANPYSRGPNPTTASLGASSGQFSVRSENVSALSASGFGGGTIYYP...   \n",
              "21  MKRTLSRALRLLPAAALAASALVAASPAQAAANPYQRGPAPTVASI...   \n",
              "22  MTASTTRARPSARRLGLRHATVGVATAGLVAASFTAGSASAATGPV...   \n",
              "23  MNKSILKKLLIATAVLLVSMNALSTTPSPTPTPDPIPDPTPCTDDC...   \n",
              "24  MNFPNASRLGQAAVLGGLMAVSAAATAQTNPYARGPNPTAATLEAS...   \n",
              "25  MVRVFGLTLLALLAPALAAPVPEDLEARQSGCADVIVVFARGTSQA...   \n",
              "\n",
              "                                               smiles  protein_length  \\\n",
              "0                     [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             342   \n",
              "1                                    [*]OC(C)C(=O)[*]             379   \n",
              "2                               [*]NCCCCNCCCC(=O)O[*]             392   \n",
              "3                            [*]OCCCCOC(=O)CC(=O)O[*]             240   \n",
              "4   [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             431   \n",
              "5   [*]OCCOC(=O)CC(=O)O[*].[*]OC(C)CC(=O)[*].[*]OC...             576   \n",
              "6           [*]OC(C)C(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*]             505   \n",
              "7   [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]O...             238   \n",
              "8   [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*]             213   \n",
              "9   [*]OC(C)C(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]O...             283   \n",
              "10  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             224   \n",
              "11  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCOC(=O)CC(=O)O[*...             215   \n",
              "12  [*]OC(C)C(=O)[*].[*]OCCCCC(=O)[*].[*]OCCCCOC(=...             305   \n",
              "13  [*]OC(C)C(=O)[*].[*]OCCCCC(=O)[*].[*]OCCCCOC(=...             314   \n",
              "14  [*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*].[*]OCCOC(=O...             275   \n",
              "15  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             338   \n",
              "16  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             304   \n",
              "17  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             216   \n",
              "18                                           [*]CC[*]             108   \n",
              "19                                  [*]OC(C)CC(=O)[*]             283   \n",
              "20   [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OC(C)C(=O)[*]             262   \n",
              "21   [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCCCC(=O)[*]             292   \n",
              "22                                   [*]OCCCCC(=O)[*]             269   \n",
              "23   [*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             310   \n",
              "24  [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCOC(=O)c1...             290   \n",
              "25  [*]OCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCC...             203   \n",
              "\n",
              "   synthetic  cluster  \n",
              "0       True        1  \n",
              "1        NaN        2  \n",
              "2       True        4  \n",
              "3       True        4  \n",
              "4       True        5  \n",
              "5       True        5  \n",
              "6       True        5  \n",
              "7       True        5  \n",
              "8       True        5  \n",
              "9       True        5  \n",
              "10      True        5  \n",
              "11      True        5  \n",
              "12      True        5  \n",
              "13      True        5  \n",
              "14      True        5  \n",
              "15      True        5  \n",
              "16      True        5  \n",
              "17      True        5  \n",
              "18      True        7  \n",
              "19      True        8  \n",
              "20      True        9  \n",
              "21      True        9  \n",
              "22      True       10  \n",
              "23      True        0  \n",
              "24      True        0  \n",
              "25      True        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8a59123-1a82-4acb-b2a9-ef5ea7f3d4cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plastic Type</th>\n",
              "      <th>Enzyme Name</th>\n",
              "      <th>protein_sequence</th>\n",
              "      <th>smiles</th>\n",
              "      <th>protein_length</th>\n",
              "      <th>synthetic</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PET</td>\n",
              "      <td>Lipase</td>\n",
              "      <td>MKLLSLTVVAGVLATLVAATPLVKRAPSGSDPAFSQPKSVLLAGLT...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>342</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PLA</td>\n",
              "      <td>Protease</td>\n",
              "      <td>MMRKKSFWLGMLTAFMLVFTMAFSDSASAAQPAKNVEKDYIVGFKS...</td>\n",
              "      <td>[*]OC(C)C(=O)[*]</td>\n",
              "      <td>379</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nylon</td>\n",
              "      <td>Hydrolase</td>\n",
              "      <td>MNARSTPQHPAADPGAAAGEPTLDDWQRPPHNRWAFAHVGELLPTA...</td>\n",
              "      <td>[*]NCCCCNCCCC(=O)O[*]</td>\n",
              "      <td>392</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PBSA</td>\n",
              "      <td>Lipase</td>\n",
              "      <td>MNLVGHSQGGLTSRYVAAVAPELVASVTTIGTPHRGSEGADFVQSV...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*]</td>\n",
              "      <td>240</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PBS_PBSA_PCL_PES_PHB_PLA_PHA</td>\n",
              "      <td>PLA_depolymerase</td>\n",
              "      <td>MLLKKLTLIFISFLLAIILLIPAAASASEKDYKPGIALEPIKNSEG...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>431</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>P3HP_P4HB_PEA_PES_PHB_PHA</td>\n",
              "      <td>PHB_depolymerase</td>\n",
              "      <td>MTKQSLPQSMAKQRLCRFFTAALLSLLMLLLWPTTAHAGQTFSYTS...</td>\n",
              "      <td>[*]OCCOC(=O)CC(=O)O[*].[*]OC(C)CC(=O)[*].[*]OC...</td>\n",
              "      <td>576</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>PLA_PBSA</td>\n",
              "      <td>Esterase</td>\n",
              "      <td>MTAIIRQGRVQGLSSDGVTEFRGIPFAAAPLGELRFRAPQPLPDSE...</td>\n",
              "      <td>[*]OC(C)C(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*]</td>\n",
              "      <td>505</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PBS_PCL_PHB_PLA_PHA</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MLQSALALAVLSAASLGLAAPTPESAEAHELEARATSSACPSYVLI...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]O...</td>\n",
              "      <td>238</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>PBS_PBSA</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MHLRNIVIALAATAVASPVDLQDRQLSTNNELRDGPCKPITFIFAR...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*]</td>\n",
              "      <td>213</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PLA_PBS_PBSA_PCL_PES_PHB_PHA</td>\n",
              "      <td>PLA_depolymerase</td>\n",
              "      <td>MKTKKAVLLAIAALLFLTDLPGNAGASEKQRDLVLVHGLTNKHRWS...</td>\n",
              "      <td>[*]OC(C)C(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]O...</td>\n",
              "      <td>283</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>PBS_PBSA_PCL</td>\n",
              "      <td>Esterase</td>\n",
              "      <td>MQFSSTFAALVLAAAGLVQAAPMQERASCSSYQIISTRGTSEPQGP...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>224</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>PBAT_PBSA_PES_PCL</td>\n",
              "      <td>Hydrolase</td>\n",
              "      <td>MKNILFKKRFLQILLALMLVIGSFAFIQPKEVKAANQNPVVFVHGY...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCOC(=O)CC(=O)O[*...</td>\n",
              "      <td>215</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PLA_PHBV_PCL_PBSA_PES_PHA</td>\n",
              "      <td>Hydrolase</td>\n",
              "      <td>MASGTVAANGIELFYESRGPENGEPMVLVMGLSCQMVFWPDTLLDA...</td>\n",
              "      <td>[*]OC(C)C(=O)[*].[*]OCCCCC(=O)[*].[*]OCCCCOC(=...</td>\n",
              "      <td>305</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PLA_PCL_PBSA</td>\n",
              "      <td>Esterase</td>\n",
              "      <td>MALNSMKFLLGLIGLLLLITLSLEAWLLRREPSQLQAADINGELEQ...</td>\n",
              "      <td>[*]OC(C)C(=O)[*].[*]OCCCCC(=O)[*].[*]OCCCCOC(=...</td>\n",
              "      <td>314</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>PLA_PHA_PES_PCL</td>\n",
              "      <td>Lipase</td>\n",
              "      <td>MTDTLLYRDMNRAQLDAAYNNTAAVPDFPGIYAGHQARSASFYASH...</td>\n",
              "      <td>[*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*].[*]OCCOC(=O...</td>\n",
              "      <td>275</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>PBS_PBSA_PCL_PES_PLA_PHA</td>\n",
              "      <td>PLA_depolymerase</td>\n",
              "      <td>MAESVHAESEWLTTDDGAEVYVRVWEPAAGEAADSSAAAPAPPAAA...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>338</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>PBAT_PBS_PBSA_PCL_PET_PHB_PLA_PHA</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MRIRRRAGTGARASMARAAGVGSTALAVVVGAVGGVAGAEVVTAQD...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>304</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>PBAT_PBS_PBSA_PCL_PES</td>\n",
              "      <td>Hydrolase</td>\n",
              "      <td>MKRRLIAGSLAALAISAAAVALPTGAASAAPCSDVEVSFARGTGEL...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>216</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>PE</td>\n",
              "      <td>Alkane_hydroxylase</td>\n",
              "      <td>EHNRGHHVHVSTPEDPSSSRFGQSLYAFLPHAIWENFLNAWRLEAQ...</td>\n",
              "      <td>[*]CC[*]</td>\n",
              "      <td>108</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>PHA</td>\n",
              "      <td>PHA_depolymerase</td>\n",
              "      <td>MRQGYIFRSVELDNISIRVAVRPGKPHLTPLLVLNGIGANLELVQP...</td>\n",
              "      <td>[*]OC(C)CC(=O)[*]</td>\n",
              "      <td>283</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>PET_PLA</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MANPYSRGPNPTTASLGASSGQFSVRSENVSALSASGFGGGTIYYP...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OC(C)C(=O)[*]</td>\n",
              "      <td>262</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>PET_PCL</td>\n",
              "      <td>Hydrolase</td>\n",
              "      <td>MKRTLSRALRLLPAAALAASALVAASPAQAAANPYQRGPAPTVASI...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCCCC(=O)[*]</td>\n",
              "      <td>292</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>PCL</td>\n",
              "      <td>Chitinase</td>\n",
              "      <td>MTASTTRARPSARRLGLRHATVGVATAGLVAASFTAGSASAATGPV...</td>\n",
              "      <td>[*]OCCCCC(=O)[*]</td>\n",
              "      <td>269</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>PCL_PET</td>\n",
              "      <td>PETase</td>\n",
              "      <td>MNKSILKKLLIATAVLLVSMNALSTTPSPTPTPDPIPDPTPCTDDC...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>310</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>PET_PEF</td>\n",
              "      <td>PETase</td>\n",
              "      <td>MNFPNASRLGQAAVLGGLMAVSAAATAQTNPYARGPNPTAATLEAS...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCOC(=O)c1...</td>\n",
              "      <td>290</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>PES_PCL_PET</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MVRVFGLTLLALLAPALAAPVPEDLEARQSGCADVIVVFARGTSQA...</td>\n",
              "      <td>[*]OCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCC...</td>\n",
              "      <td>203</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8a59123-1a82-4acb-b2a9-ef5ea7f3d4cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b8a59123-1a82-4acb-b2a9-ef5ea7f3d4cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b8a59123-1a82-4acb-b2a9-ef5ea7f3d4cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a09dd108-5109-467d-9636-955de48ac66e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a09dd108-5109-467d-9636-955de48ac66e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a09dd108-5109-467d-9636-955de48ac66e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8d39957c-e120-4352-9d4d-5b95f2a35b91\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('unique_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8d39957c-e120-4352-9d4d-5b95f2a35b91 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('unique_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "unique_df",
              "summary": "{\n  \"name\": \"unique_df\",\n  \"rows\": 26,\n  \"fields\": [\n    {\n      \"column\": \"Plastic Type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"PBS_PBSA\",\n          \"PBAT_PBS_PBSA_PCL_PET_PHB_PLA_PHA\",\n          \"PET\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Enzyme Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Esterase\",\n          \"Lipase\",\n          \"Chitinase\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"MHLRNIVIALAATAVASPVDLQDRQLSTNNELRDGPCKPITFIFARASTEPGNLGITTGPAVCNRLKLARSGDVACQGVGPRYTADLPSNALPEGTSQAAIAEAQALFEQAVSKCPDTQIVAGGYSQGTAVMNGAIKTLSADVQDKIKGVVLFGYTRNAQDEGQIANFPKDKVKVYCAVGDLVCLGTLIVAPPHFSYLSDVGDASDFLLSQLG\",\n          \"MRIRRRAGTGARASMARAAGVGSTALAVVVGAVGGVAGAEVVTAQDNPYERGPDPTEDSIEAGQGPFSVATERVSSIASGFGGGTIYYPTETREGTFGAVAVVPGFTASQSSMSWYGERVASFGFVVFTIDTNTRLDQPGARGRQLLAALDYLTERSDARVRGRLDPNRLAVMGHSMGGGGSLEATVQRPSLKASIPLTPWNLDKTWGQVQVPTMIIGAEDDTIASVRTHAKPFYESLPSSLDKAYMELRGATHFAPNRPNSTIAKYAISWLKRFVDEDTRYSQFLCPKPTDRAIEEYRSTCPY\",\n          \"MKLLSLTVVAGVLATLVAATPLVKRAPSGSDPAFSQPKSVLLAGLTCPGASTLSASRPILLVPGTGTTGGQSFDSNWIPLMTQLGYTPCYISPPAFMLNDVQVNAEYMVNAITALYAASGNNKLPVLTWSQGGLVAQWGLTFFPSIRSKVDRYVAFAPDYKGTVLAQPLRALGVSAPSVVQQTTGSALITALRNNGGLTSIVPTTNLYSATDEIVQPQVSNSPLASSYLGGGKSVQVQAVCGPLFVIDHAKILTSNFSYVVGISALDSTTGNARSADYPITACNALPGNDLTPEQKVAAAALLAPAAAAIIAGGKTNCEPDLPPYAGPFAGGKRTCSGILTP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smiles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*]\",\n          \"[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OC(C)CC(=O)[*].[*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*]\",\n          \"[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 97,\n        \"min\": 108,\n        \"max\": 576,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          213,\n          304,\n          342\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synthetic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "unique_df = train_df.drop_duplicates(subset=['smiles'])\n",
        "unique_df = unique_df.reset_index(drop=True)\n",
        "unique_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qxj9iuhLBlJZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "c1292ee3-7ddb-4c4c-fa21-6ab23b2a2f4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Plastic Type    Enzyme Name  \\\n",
              "0             PET         Lipase   \n",
              "1             PET         PETase   \n",
              "2             PET        MHETase   \n",
              "3             PET           PET6   \n",
              "4             PET        MHETase   \n",
              "...           ...            ...   \n",
              "3464      PCL_PET       Cutinase   \n",
              "3465      PCL_PET  PET-hydrolase   \n",
              "3466      PCL_PET         PETase   \n",
              "3467      PET_PEF         PETase   \n",
              "3468      PCL_PET       Cutinase   \n",
              "\n",
              "                                       protein_sequence  \\\n",
              "0     MKLLSLTVVAGVLATLVAATPLVKRAPSGSDPAFSQPKSVLLAGLT...   \n",
              "1     MLERPVTFRNEGEKIIGILHIPDNIRPGEKVPGILMFHGFTGNKTE...   \n",
              "2     MRHTRRTMLLASVALAACGGGGGTPSPSPQQQPPQQEPPPPPPPLA...   \n",
              "3     MNVLTKCKISLGIIAIFFSLPSFAVTCSPCSNGFERGQGPTVDQLT...   \n",
              "4     MKTRLTTMLLASVALAACAGGGDTPLPLPQQPPPQQQPPPPPPPLA...   \n",
              "...                                                 ...   \n",
              "3464  MHGVLWRLRLAALRAALLALAAVALVVASPSVEAQSNPYQRGPAPT...   \n",
              "3465  MLNVLTFGKLALGIIAIFFALPSFAVPCSDCSNGFERGPDPTVSQL...   \n",
              "3466  MNKSILLALGFGISVLLVSMNALSVTPSPTPTPDPDPDPTPTQDNC...   \n",
              "3467  MNFARASRLMSAAVLGALAAVSAAATAQTNPYARGPDPTAASLEAS...   \n",
              "3468  MINRTLPNSLLSMLAAGALLLSTSVMATNPPVGEPTDPGYSYQRGP...   \n",
              "\n",
              "                                                 smiles  protein_length  \\\n",
              "0                       [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             342   \n",
              "1                       [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             272   \n",
              "2                       [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             603   \n",
              "3                       [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             297   \n",
              "4                       [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             603   \n",
              "...                                                 ...             ...   \n",
              "3464   [*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             293   \n",
              "3465   [*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             298   \n",
              "3466   [*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             310   \n",
              "3467  [*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCOC(=O)c1...             290   \n",
              "3468   [*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             302   \n",
              "\n",
              "     synthetic  cluster  \n",
              "0         True        1  \n",
              "1         True        1  \n",
              "2         True        1  \n",
              "3         True        1  \n",
              "4         True        1  \n",
              "...        ...      ...  \n",
              "3464      True        0  \n",
              "3465      True        0  \n",
              "3466      True        0  \n",
              "3467      True        0  \n",
              "3468      True        0  \n",
              "\n",
              "[3469 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c03015e4-cbde-47d2-9c20-608e3dc2186f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plastic Type</th>\n",
              "      <th>Enzyme Name</th>\n",
              "      <th>protein_sequence</th>\n",
              "      <th>smiles</th>\n",
              "      <th>protein_length</th>\n",
              "      <th>synthetic</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PET</td>\n",
              "      <td>Lipase</td>\n",
              "      <td>MKLLSLTVVAGVLATLVAATPLVKRAPSGSDPAFSQPKSVLLAGLT...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>342</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PET</td>\n",
              "      <td>PETase</td>\n",
              "      <td>MLERPVTFRNEGEKIIGILHIPDNIRPGEKVPGILMFHGFTGNKTE...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>272</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PET</td>\n",
              "      <td>MHETase</td>\n",
              "      <td>MRHTRRTMLLASVALAACGGGGGTPSPSPQQQPPQQEPPPPPPPLA...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>603</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PET</td>\n",
              "      <td>PET6</td>\n",
              "      <td>MNVLTKCKISLGIIAIFFSLPSFAVTCSPCSNGFERGQGPTVDQLT...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>297</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PET</td>\n",
              "      <td>MHETase</td>\n",
              "      <td>MKTRLTTMLLASVALAACAGGGDTPLPLPQQPPPQQQPPPPPPPLA...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>603</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3464</th>\n",
              "      <td>PCL_PET</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MHGVLWRLRLAALRAALLALAAVALVVASPSVEAQSNPYQRGPAPT...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>293</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3465</th>\n",
              "      <td>PCL_PET</td>\n",
              "      <td>PET-hydrolase</td>\n",
              "      <td>MLNVLTFGKLALGIIAIFFALPSFAVPCSDCSNGFERGPDPTVSQL...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>298</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3466</th>\n",
              "      <td>PCL_PET</td>\n",
              "      <td>PETase</td>\n",
              "      <td>MNKSILLALGFGISVLLVSMNALSVTPSPTPTPDPDPDPTPTQDNC...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>310</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3467</th>\n",
              "      <td>PET_PEF</td>\n",
              "      <td>PETase</td>\n",
              "      <td>MNFARASRLMSAAVLGALAAVSAAATAQTNPYARGPDPTAASLEAS...</td>\n",
              "      <td>[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OCCOC(=O)c1...</td>\n",
              "      <td>290</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3468</th>\n",
              "      <td>PCL_PET</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MINRTLPNSLLSMLAAGALLLSTSVMATNPPVGEPTDPGYSYQRGP...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>302</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3469 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c03015e4-cbde-47d2-9c20-608e3dc2186f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c03015e4-cbde-47d2-9c20-608e3dc2186f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c03015e4-cbde-47d2-9c20-608e3dc2186f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-600cfc43-fc4c-43f2-b876-a133d285782b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-600cfc43-fc4c-43f2-b876-a133d285782b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-600cfc43-fc4c-43f2-b876-a133d285782b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e3a60d5c-acff-4a13-8971-2b49eec92eda\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e3a60d5c-acff-4a13-8971-2b49eec92eda button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 3469,\n  \"fields\": [\n    {\n      \"column\": \"Plastic Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"PCL_PET\",\n          \"PLA_PCL_PBSA\",\n          \"P3HV_PHBV_PHA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Enzyme Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 35,\n        \"samples\": [\n          \"Manganese_Peroxidase_Iz-MnP1\",\n          \"Protease\",\n          \"PHB_depolymerase\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3469,\n        \"samples\": [\n          \"MKMIANKKRILQILVALALVIGSAAFIQPKEVKAANHNPVVFVHGIGGASSNFASIKSYLVGQGYDANQLYALDFIDTTGNNRVNAPRLSKFVQDVLVKTGAKKVDIVAHSMGGANTLYYIKNLDGSDKIENVVTIGSANGLVSSRSYPGTDPNRKIKYTSVYSSADWIVVPSSSHLIGAKNVEISGVGHIGLPTSSQVKGYIVEFLNGVQLNIN\",\n          \"MANGYERGPAPTTSSIEAPRGPFATASVTVSPVSDSGFGGGTIYYPTDTSPGTFGAVAIAPGFTADEGSMAWYGPRIASQGFVVFTIDTETRLDQPDSRGRQLLAALDYLTQSSSVRSRIDSSRLAVMGHSMGGGGSLEASVNRPSLKAAIPLTPWNLGKNWRDVRVPTLIVGAEGDSIASVSDHAEPFYRSIPSTTNKAYLELNRATHFAPNSSNTTIAKYSISWLKRFVDNDTRYEQFLCPLPRSDRDVTIYRSTCPF\",\n          \"MTTPTPTPEPGPEPEFGCGDCYQRGPDPTVSALEADRGPYSVRTINVSSGGSGFGGGTIHYPTGTQGTYGAIAIAPGYVSYENSIEWWGPRLASWGFVVITIDTNSIYDQPDSRAKQLSAALDYMIAQSNSSSSAIRGMVDPNRLGAIGWSMGGGGTLIASHDRRLKAAIPTAPWYSGFNPFDEITTPTLIIACQLDAVAPVAQHAIPFYNELPNSTAKAYLEIRGGDHFCANSGYPDEDELGKVGVAWMKRFLDDDRRYDQFLCGPNPNAEWGIEEYRDDCNYLNHHHHHH\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smiles\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*]\",\n          \"[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*].[*]OC(C)CC(=O)[*].[*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*]\",\n          \"[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 93,\n        \"min\": 108,\n        \"max\": 786,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          176,\n          201,\n          267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synthetic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_df = val_df.drop_duplicates(subset=['smiles'])\n",
        "unique_df = unique_df.reset_index(drop=True)\n",
        "unique_df\n"
      ],
      "metadata": {
        "id": "_RAHpvVC8hGs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "3067d64f-974b-4b31-82da-60239db85c52"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Plastic Type           Enzyme Name  \\\n",
              "0                PVA     PVA_dehydrogenase   \n",
              "1                PEG     PEG_dehydrogenase   \n",
              "2            PHA_PHB      PHA_depolymerase   \n",
              "3  PCL_PHA_PHBV_PHPV  MCL_PHA_depolymerase   \n",
              "\n",
              "                                    protein_sequence  \\\n",
              "0  MKANIERNAVSGTASRFVLGAVTALVALGTASAAEQNLPDGAALYR...   \n",
              "1  MCLVTLYFCTWINVRNRGMPDFDFIVVGAGSAGCVVASRLSETGKY...   \n",
              "2  MLYQLHEFNRSLLEPFEALAQATAKTFQNPLSPLSLVPGAKRLAAG...   \n",
              "3  MLAPRVLLFCLLLFALPNAFADSRCSERANTLLLPAKPSESAKTTI...   \n",
              "\n",
              "                                smiles  protein_length synthetic  cluster  \n",
              "0                            [*]CCO[*]             639      True        6  \n",
              "1                           [*]OCCO[*]             553      True       11  \n",
              "2  [*]OC(C)CC(=O)[*].[*]OC(C)CC(=O)[*]             419      True        3  \n",
              "3   [*]OCCCCC(=O)[*].[*]OC(C)CC(=O)[*]             277      True        3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51c95115-2e06-43ec-9ff3-345ffd9671c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plastic Type</th>\n",
              "      <th>Enzyme Name</th>\n",
              "      <th>protein_sequence</th>\n",
              "      <th>smiles</th>\n",
              "      <th>protein_length</th>\n",
              "      <th>synthetic</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PVA</td>\n",
              "      <td>PVA_dehydrogenase</td>\n",
              "      <td>MKANIERNAVSGTASRFVLGAVTALVALGTASAAEQNLPDGAALYR...</td>\n",
              "      <td>[*]CCO[*]</td>\n",
              "      <td>639</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PEG</td>\n",
              "      <td>PEG_dehydrogenase</td>\n",
              "      <td>MCLVTLYFCTWINVRNRGMPDFDFIVVGAGSAGCVVASRLSETGKY...</td>\n",
              "      <td>[*]OCCO[*]</td>\n",
              "      <td>553</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PHA_PHB</td>\n",
              "      <td>PHA_depolymerase</td>\n",
              "      <td>MLYQLHEFNRSLLEPFEALAQATAKTFQNPLSPLSLVPGAKRLAAG...</td>\n",
              "      <td>[*]OC(C)CC(=O)[*].[*]OC(C)CC(=O)[*]</td>\n",
              "      <td>419</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PCL_PHA_PHBV_PHPV</td>\n",
              "      <td>MCL_PHA_depolymerase</td>\n",
              "      <td>MLAPRVLLFCLLLFALPNAFADSRCSERANTLLLPAKPSESAKTTI...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OC(C)CC(=O)[*]</td>\n",
              "      <td>277</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51c95115-2e06-43ec-9ff3-345ffd9671c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51c95115-2e06-43ec-9ff3-345ffd9671c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51c95115-2e06-43ec-9ff3-345ffd9671c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86687e79-f9d7-4ba0-9af3-33c0419269c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86687e79-f9d7-4ba0-9af3-33c0419269c8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86687e79-f9d7-4ba0-9af3-33c0419269c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_536cdca8-3950-4e8f-bf9e-05bf32cc18ff\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('unique_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_536cdca8-3950-4e8f-bf9e-05bf32cc18ff button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('unique_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "unique_df",
              "summary": "{\n  \"name\": \"unique_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Plastic Type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"PEG\",\n          \"PCL_PHA_PHBV_PHPV\",\n          \"PVA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Enzyme Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"PEG_dehydrogenase\",\n          \"MCL_PHA_depolymerase\",\n          \"PVA_dehydrogenase\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"MCLVTLYFCTWINVRNRGMPDFDFIVVGAGSAGCVVASRLSETGKYQVALLEAGGSHNNPLISIPFGFAFTVFKGPHDWKFETVPQKGLNGRRMYQPRGKVLGGSSSINAMVYIRGAKRDYDHWASLGNEGWSYEEVLPFFKKSENNEKGANEYHGTGGPLTVSEPRSPLPLNDAFIKAGMQLGLPYNEDFNGELQEGVGGYELTQDRGKRWSAALAYLKPAENRKNLTIFTDALVEKLLVENGQATGVEVKLNGQLQIIKAEREVILSCGAIKSPQLLLLSGIGDKEHLSPLGIKVVHELPGVGENLRDHVDFCLTYQSDSEHTLDKNARSNFRVAWESLKYFAFRRGILTTNFGEAGAFFKTNPDTRSPDIQLHFAITEFDDHGRKRHGRNGFTCHVCVLRPKSRGNLTLADANPATPPLIDPAFLKDERDVATLLAGVKRAQQILQAPAFDEYRGKPVLPTQSLSDDELIEYIRNRADTIYHPVGTCKMGPDSDPMAVVDSKLRVRGIRNLRVIDASIMPSIVSGNTNAPTIMIGEKGAQMILDEAESYT\",\n          \"MLAPRVLLFCLLLFALPNAFADSRCSERANTLLLPAKPSESAKTTIDDSLLIGARQVIYQRPSGTPPAGGFPVVLVLQGSFFPLNDGTYDGNQPFGGYYTGKLVRALLDSGYAVIAPSAQADLFWQPNIPVLAQATELTTDYDFLGNVFDAIASGSFGPLNSQRLYATGISAGGYNTSRMAVSFPGQFKALAIQSGSYATCSGPLCVVPAQLPADHPPTYLLHGKLDLTVPYWVMDLYYDRLLQQGIETARYTEPLGGHEWPAADPGPVLAWFAAHP\",\n          \"MKANIERNAVSGTASRFVLGAVTALVALGTASAAEQNLPDGAALYRARCGTCHDNPMDRTPARDVIARRSPPRIMAAMSGPMAPMAAGLSEAEKQAIALALGGAPAGGSQEIVPLAIGGNPSASTPLDGPKCKGKIPPIDLSAPGQWNGWGAGITNARFQPNPGLTAADVPRLKVKWAFAYPGSKSGQATVVGDRLFVPSMSGFVYALNAKTGCIYWRHDAAAAVRTSVTVVQLPAGKPARHAIFFSDWTKAAYALDAQTGKQLWKTKIDDQPGVQMTGSPTYHKGRLFVPISSGEEAFANNEDYECCKFRGSLVALDARSGKVLWKTYTTQDEPAPFRKNKLGKQMWGPAGGSIWSAPTVDPKRGLVYVATSNSYSEPTHEGSDAVVAMEISTGKVRWIRQTTKDDAYNTGCRRAANCPEKQGPDFDLGTSPILTTLQDGRQALVVGQKSGAVYAMDPDKDGKLIWKRRVGRGSELGGVEWGMAADAENVYVGISDVIAPKGGKPGVYALRIRDGAPVWATPAPRTPCRRNNEFCHPAFSAAVTALPGVVFAGSMDGYLRAFSTSDGKVLWEFNTAAAPYKTVGGVQAIGGSMDGAGPTIAGGMVYVLSGYAGQNTFPGGGLRGREGNVLIAFSVDGK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smiles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"[*]OCCO[*]\",\n          \"[*]OCCCCC(=O)[*].[*]OC(C)CC(=O)[*]\",\n          \"[*]CCO[*]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 158,\n        \"min\": 277,\n        \"max\": 639,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          553,\n          277,\n          639\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synthetic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsZYuP9onEl1"
      },
      "source": [
        "### setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "CpeO8QHj-_z5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80724a06-6b32-49a0-b5f8-a1afc92fc3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.11/dist-packages (0.27.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from Levenshtein) (3.12.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Levenshtein\n",
        "# !pip install einops\n",
        "# !pip install einops_exts\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install tqdm\n",
        "!pip install sentencepiece\n",
        "# !pip install fair-esm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "CYInyPD_--Vo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e68a0e3-ab3b-49e9-e30f-396d91b84cc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from einops import rearrange, repeat\n",
        "# import esm\n",
        "\n",
        "# Set up GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# # Load ESM-2 model\n",
        "# esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "# batch_converter = alphabet.get_batch_converter()\n",
        "# esm_model = esm_model.to(device)  # Move to GPU if available\n",
        "# esm_model.eval()  # Set to evaluation mode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B--CLs46QMLR"
      },
      "source": [
        "### data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DyL8K36gQgPj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0UGP9rWlQgn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ddbce15-b577-4b8d-ec35-949f6b2e09a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aN6Of5EMJ2Ju"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t6vR0DNfQRUZ"
      },
      "outputs": [],
      "source": [
        "def preprocess_snp_data(file_path):\n",
        "    snp_df = pd.read_csv(file_path)\n",
        "\n",
        "    # Basic preprocessing and length calculations\n",
        "    snp_df['smiles_length'] = snp_df['smiles'].apply(len)\n",
        "    snp_df['protein_length'] = snp_df['protein_sequence'].apply(len)\n",
        "\n",
        "    return snp_df\n",
        "\n",
        "def filter_datasets(dataset):\n",
        "    return dataset[\n",
        "        (dataset['smiles'].notna()) &\n",
        "        (dataset['protein_sequence'].notna()) &\n",
        "        (dataset['smiles_length'] > 0) &\n",
        "        (dataset['protein_length'] > 0)\n",
        "    ]\n",
        "\n",
        "class ProteinGenerationDataset(Dataset):\n",
        "    def __init__(self, dataframe, max_length):\n",
        "        self.dataframe = dataframe\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        return row['smiles'], row['protein_sequence']\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Custom collate function to handle padding within batches.\n",
        "    Args:\n",
        "        batch: List of tuples (smiles, protein)\n",
        "    Returns:\n",
        "        Padded and batched tensors\n",
        "    \"\"\"\n",
        "    smiles, proteins = zip(*batch)\n",
        "\n",
        "    # SMILES strings don't need padding as PolyBERT handles that internally\n",
        "    smiles = list(smiles)\n",
        "\n",
        "    # Get max length in this batch for proteins (not exceeding dataset max_length)\n",
        "    max_protein_len = min(max(len(p) for p in proteins), max_length)\n",
        "\n",
        "    # Pad proteins to max length in batch\n",
        "    padded_proteins = []\n",
        "    protein_masks = []\n",
        "\n",
        "    for protein in proteins:\n",
        "        if len(protein) > max_protein_len:\n",
        "            padded = protein[:max_protein_len]\n",
        "            mask = [1] * max_protein_len\n",
        "        else:\n",
        "            padded = protein + ' ' * (max_protein_len - len(protein))\n",
        "            mask = [1] * len(protein) + [0] * (max_protein_len - len(protein))\n",
        "\n",
        "        padded_proteins.append(padded)\n",
        "        protein_masks.append(mask)\n",
        "\n",
        "    return {\n",
        "        'smiles': smiles,\n",
        "        'proteins': padded_proteins,\n",
        "        'protein_masks': torch.tensor(protein_masks, dtype=torch.bool)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y84XLPeXQIEv"
      },
      "source": [
        "### utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XEODw7FYQJEy"
      },
      "outputs": [],
      "source": [
        "# Model Components\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0)]\n",
        "\n",
        "class DoublePositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        # Use the full embedding dimension divided into two halves\n",
        "        self.d_model = d_model\n",
        "        half_dim = d_model // 2\n",
        "\n",
        "        # Create position encodings for both input and output positions\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, half_dim, 2) * (-math.log(10000.0) / half_dim))\n",
        "\n",
        "        # Input position encodings\n",
        "        pe_input = torch.zeros(max_len, half_dim)\n",
        "        pe_input[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe_input[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Output position encodings\n",
        "        pe_output = torch.zeros(max_len, half_dim)\n",
        "        pe_output[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe_output[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe_input', pe_input)\n",
        "        self.register_buffer('pe_output', pe_output)\n",
        "\n",
        "    def forward(self, x, input_positions, output_positions):\n",
        "        batch_size, seq_length, _ = x.shape\n",
        "\n",
        "        # Create a tensor of zeros with the same shape as the input\n",
        "        pos_encoding = torch.zeros_like(x)\n",
        "\n",
        "        # For each item in the batch\n",
        "        for b in range(batch_size):\n",
        "            for t in range(seq_length):\n",
        "                # Get the input and output positions for this token\n",
        "                input_pos = input_positions[b, t] if input_positions is not None else t\n",
        "                output_pos = output_positions[b, t] if output_positions is not None else t\n",
        "\n",
        "                if input_pos < self.pe_input.size(0) and output_pos < self.pe_output.size(0):\n",
        "                    # Fill the first half with input position encoding\n",
        "                    pos_encoding[b, t, :self.d_model//2] = self.pe_input[input_pos]\n",
        "                    # Fill the second half with output position encoding\n",
        "                    pos_encoding[b, t, self.d_model//2:] = self.pe_output[output_pos]\n",
        "\n",
        "        return x + pos_encoding\n",
        "\n",
        "class PerceiverAttention(nn.Module):\n",
        "    def __init__(self, dim, dim_head=64, heads=8):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        inner_dim = dim_head * heads\n",
        "\n",
        "        self.norm_media = nn.LayerNorm(dim)\n",
        "        self.norm_latents = nn.LayerNorm(dim)\n",
        "        self.to_q = nn.Linear(dim, inner_dim, bias=False)\n",
        "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias=False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim, bias=False)\n",
        "\n",
        "    def forward(self, x, latents):\n",
        "        \"\"\"\n",
        "        x: [batch_size, seq_len_x, dim]\n",
        "        latents: [batch_size, seq_len_l, dim]\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        x = self.norm_media(x)\n",
        "        latents = self.norm_latents(latents)\n",
        "\n",
        "        # Ensure latents has correct batch size\n",
        "        if latents.size(0) != batch_size:\n",
        "            latents = latents.expand(batch_size, -1, -1)\n",
        "\n",
        "        q = self.to_q(latents)\n",
        "        q = rearrange(q, 'b n (h d) -> b h n d', h=self.heads)\n",
        "        q = q * self.scale\n",
        "\n",
        "        # Ensure proper concatenation\n",
        "        kv_input = torch.cat((x, latents), dim=1)  # concatenate along sequence dimension\n",
        "        k, v = self.to_kv(kv_input).chunk(2, dim=-1)\n",
        "        k = rearrange(k, 'b n (h d) -> b h n d', h=self.heads)\n",
        "        v = rearrange(v, 'b n (h d) -> b h n d', h=self.heads)\n",
        "\n",
        "        sim = torch.einsum('b h i d, b h j d -> b h i j', q, k)\n",
        "        attn = sim.softmax(dim=-1)\n",
        "        out = torch.einsum('b h i j, b h j d -> b h i d', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "\n",
        "        return self.to_out(out)\n",
        "\n",
        "class GatedCrossAttentionBlock(nn.Module):\n",
        "    def __init__(self, dim, dim_head=64, heads=8, ff_mult=4):\n",
        "        super().__init__()\n",
        "        self.attn = PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads)\n",
        "        self.attn_gate = nn.Parameter(torch.tensor([0.]))\n",
        "        self.ff = FeedForward(dim, mult=ff_mult)\n",
        "        self.ff_gate = nn.Parameter(torch.tensor([0.]))\n",
        "\n",
        "    def forward(self, x, media):\n",
        "        \"\"\"\n",
        "        x: [batch_size, seq_len_x, dim]\n",
        "        media: [batch_size, seq_len_m, dim]\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "        target_batch_size = media.size(0)\n",
        "\n",
        "        # Handle batch size mismatch\n",
        "        if batch_size > target_batch_size:\n",
        "            media = media.expand(batch_size, -1, -1)\n",
        "        elif batch_size < target_batch_size:\n",
        "            x = x.expand(target_batch_size, -1, -1)\n",
        "\n",
        "        gate = self.attn_gate.tanh()\n",
        "        x = self.attn(media, x) * gate + x\n",
        "        x = self.ff(x) * self.ff_gate.tanh() + x\n",
        "        return x\n",
        "\n",
        "class PerceiverResampler(nn.Module):\n",
        "    def __init__(self, dim, depth, dim_head=64, heads=8, num_latents=64):\n",
        "        super().__init__()\n",
        "        # Initialize latents without batch dimension\n",
        "        self.latents = nn.Parameter(torch.randn(num_latents, dim))\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads),\n",
        "                FeedForward(dim=dim)\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        # Expand latents to batch size\n",
        "        latents = repeat(self.latents, 'n d -> b n d', b=batch_size)\n",
        "\n",
        "        for attn, ff in self.layers:\n",
        "            latents = attn(x, latents) + latents\n",
        "            latents = ff(latents) + latents\n",
        "\n",
        "        return latents\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, mult=4):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim * mult, bias=False),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim * mult, dim, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# class PerceiverResampler(nn.Module):\n",
        "#     def __init__(self, dim, depth, dim_head=64, heads=8, num_latents=64):\n",
        "#         super().__init__()\n",
        "#         self.latents = nn.Parameter(torch.randn(num_latents, dim))\n",
        "#         self.layers = nn.ModuleList([])\n",
        "\n",
        "#         for _ in range(depth):\n",
        "#             self.layers.append(nn.ModuleList([\n",
        "#                 PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads),\n",
        "#                 FeedForward(dim=dim)\n",
        "#             ]))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         latents = repeat(self.latents, 'n d -> b n d', b=x.shape[0])\n",
        "\n",
        "#         for attn, ff in self.layers:\n",
        "#             latents = attn(x, latents) + latents\n",
        "#             latents = ff(latents) + latents\n",
        "\n",
        "#         return latents\n",
        "\n",
        "# class GatedCrossAttentionBlock(nn.Module):\n",
        "#     def __init__(self, dim, dim_head=64, heads=8, ff_mult=4):\n",
        "#         super().__init__()\n",
        "#         self.attn = PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads)\n",
        "#         self.attn_gate = nn.Parameter(torch.tensor([0.]))\n",
        "#         self.ff = FeedForward(dim, mult=ff_mult)\n",
        "#         self.ff_gate = nn.Parameter(torch.tensor([0.]))\n",
        "\n",
        "#     def forward(self, x, media):\n",
        "#         gate = self.attn_gate.tanh()\n",
        "#         x = self.attn(media, x) * gate + x\n",
        "#         x = self.ff(x) * self.ff_gate.tanh() + x\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daZm9aPyRUAM"
      },
      "source": [
        "### PolyBert Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "00Y8KtCzni07"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rj3wpaKHRVmv"
      },
      "outputs": [],
      "source": [
        "# class PolyBERTEncoder(nn.Module):\n",
        "#     def __init__(self, output_dim):\n",
        "#         super().__init__()\n",
        "#         self.polybert = AutoModel.from_pretrained('kuelumbus/polyBERT')\n",
        "#         self.tokenizer = AutoTokenizer.from_pretrained('kuelumbus/polyBERT')\n",
        "#         self.output_dim = output_dim\n",
        "#         # Add a projection layer to match the required dimension\n",
        "#         self.projection = nn.Linear(self.polybert.config.hidden_size, output_dim)\n",
        "\n",
        "#     def mean_pooling(self, model_output, attention_mask):\n",
        "#         token_embeddings = model_output[0]\n",
        "#         input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "#         return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "#     def forward(self, smiles_strings):\n",
        "#         # Tokenize the SMILES strings\n",
        "#         encoded_input = self.tokenizer(smiles_strings,\n",
        "#                                      padding=True,\n",
        "#                                      truncation=True,\n",
        "#                                      return_tensors='pt').to(next(self.polybert.parameters()).device)\n",
        "\n",
        "#         # Get PolyBERT embeddings\n",
        "#         with torch.no_grad():\n",
        "#             model_output = self.polybert(**encoded_input)\n",
        "\n",
        "#         # Debug prints\n",
        "#         print(\"Model Output Keys:\", model_output.keys())  # Check available keys\n",
        "#         # print(\"Last Hidden State:\", model_output.last_hidden_state)\n",
        "#         print(\"Last Hidden State Shape:\", model_output.last_hidden_state.shape)\n",
        "\n",
        "#         # Pool the embeddings\n",
        "#         pooled_output = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "#         # print(\"Pooled Output:\", pooled_output)\n",
        "#         print(\"Pooled Output Shape:\", pooled_output.shape)\n",
        "\n",
        "#         # Project to required dimension\n",
        "#         projected_output = self.projection(pooled_output)\n",
        "\n",
        "#         return projected_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-2VWy9ecrDNX"
      },
      "outputs": [],
      "source": [
        "class PolyBERTEncoder(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "        self.polybert = AutoModel.from_pretrained('kuelumbus/polyBERT')\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('kuelumbus/polyBERT')\n",
        "        self.output_dim = output_dim\n",
        "        # Project each token embedding to required dimension\n",
        "        self.projection = nn.Linear(self.polybert.config.hidden_size, output_dim)\n",
        "\n",
        "    def forward(self, smiles_strings):\n",
        "        # Tokenize the SMILES strings\n",
        "        encoded_input = self.tokenizer(smiles_strings,\n",
        "                                     padding=True,\n",
        "                                     truncation=True,\n",
        "                                     return_tensors='pt').to(next(self.polybert.parameters()).device)\n",
        "\n",
        "        # Get PolyBERT embeddings\n",
        "        with torch.no_grad():\n",
        "            model_output = self.polybert(**encoded_input)\n",
        "\n",
        "        # Debug prints\n",
        "        # print(\"Model Output Keys:\", model_output.keys())\n",
        "        # print(\"Last Hidden State Shape:\", model_output.last_hidden_state.shape)  # [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        # Get sequence embeddings\n",
        "        sequence_embeddings = model_output.last_hidden_state\n",
        "\n",
        "        # Project each token embedding to required dimension\n",
        "        projected_output = self.projection(sequence_embeddings)  # [batch_size, seq_len, output_dim]\n",
        "        # print(\"Projected Output Shape:\", projected_output.shape)\n",
        "\n",
        "        return projected_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FLAMINGO"
      ],
      "metadata": {
        "id": "BRJt_Mhb-6FZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pe8VJFxQSS7"
      },
      "source": [
        "### ProtFlamingo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3FCpZZidXy3"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1CcCRv-9vxW"
      },
      "outputs": [],
      "source": [
        "class SigmaProtFlamingo(nn.Module):\n",
        "    def __init__(self, model_path, max_len, cross_attn_every=3, dim_head=64, heads=8, perceiver_depth=2, perceiver_num_latents=64):\n",
        "        super().__init__()\n",
        "\n",
        "        self.protGPT2_model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "        self.protGPT2_tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "        self.max_len = max_len\n",
        "\n",
        "        if self.protGPT2_tokenizer.pad_token is None:\n",
        "            self.protGPT2_tokenizer.pad_token = self.protGPT2_tokenizer.eos_token\n",
        "            self.protGPT2_model.config.pad_token_id = self.protGPT2_model.config.eos_token_id\n",
        "\n",
        "        self.cross_attn_every = cross_attn_every\n",
        "\n",
        "        # PolyBERT encoder for SMILES strings\n",
        "        self.polybert_encoder = PolyBERTEncoder(self.protGPT2_model.config.n_embd)\n",
        "\n",
        "        # Replace single positional encoding with double positional encoding\n",
        "        self.positional_encoding = DoublePositionalEncoding(self.protGPT2_model.config.n_embd, max_len=max_len)\n",
        "\n",
        "        # Single perceiver resampler for SMILES embeddings\n",
        "        self.smiles_perceiver = PerceiverResampler(\n",
        "            dim=self.protGPT2_model.config.n_embd,\n",
        "            depth=perceiver_depth,\n",
        "            dim_head=dim_head,\n",
        "            heads=heads,\n",
        "            num_latents=perceiver_num_latents\n",
        "        )\n",
        "\n",
        "        # Cross attention layers\n",
        "        num_gpt_layers = len(self.protGPT2_model.transformer.h)\n",
        "        self.cross_attn = nn.ModuleList([\n",
        "            GatedCrossAttentionBlock(dim=self.protGPT2_model.config.n_embd, dim_head=dim_head, heads=heads)\n",
        "            for _ in range(num_gpt_layers)\n",
        "        ])\n",
        "\n",
        "        # Combine GPT layers with cross attention\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i, block in enumerate(self.protGPT2_model.transformer.h):\n",
        "            self.layers.append(block)\n",
        "            if i % cross_attn_every == 0 and i != 0:\n",
        "                self.layers.append(GatedCrossAttentionBlock(dim=self.protGPT2_model.config.n_embd, dim_head=dim_head, heads=heads))\n",
        "\n",
        "    def forward(self, smiles_strings, order=None, targets=None, optimize=False, kv_cache=None, burst=False):\n",
        "        device = next(self.parameters()).device\n",
        "\n",
        "        # Get SMILES embeddings through PolyBERT\n",
        "        smiles_embeddings = self.polybert_encoder(smiles_strings)\n",
        "        processed_smiles = self.smiles_perceiver(smiles_embeddings)\n",
        "\n",
        "        # Initialize with start token\n",
        "        gpt_input = self.protGPT2_tokenizer.encode_plus(\n",
        "            \"<|endoftext|>\",\n",
        "            return_tensors=\"pt\",\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            truncation=True\n",
        "        ).to(device)\n",
        "\n",
        "        input_ids = gpt_input.input_ids.long()\n",
        "        seq_length = input_ids.size(1)\n",
        "        batch_size = 1 if isinstance(smiles_strings, str) else len(smiles_strings)\n",
        "\n",
        "        hidden_states = self.protGPT2_model.transformer.wte(input_ids)\n",
        "\n",
        "        # If no order is provided, use left-to-right\n",
        "        if order is None:\n",
        "            order = torch.arange(seq_length, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "        # Make sure order is the right length\n",
        "        if order.size(1) > seq_length:\n",
        "            order = order[:, :seq_length]\n",
        "        elif order.size(1) < seq_length:\n",
        "            # Pad order if needed\n",
        "            padding = torch.arange(order.size(1), seq_length, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
        "            order = torch.cat([order, padding], dim=1)\n",
        "\n",
        "        # Map the input tokens according to the order\n",
        "        # When using random order, we need to reshuffle the input tokens\n",
        "        if not optimize and not burst:  # Only shuffle during training\n",
        "            reordered_input_ids = torch.zeros_like(input_ids)\n",
        "            for b in range(batch_size):\n",
        "                # Reorder the input tokens according to the order\n",
        "                reordered_input_ids[b] = input_ids[b, order[b]]\n",
        "\n",
        "            # Re-embed with reordered tokens\n",
        "            hidden_states = self.protGPT2_model.transformer.wte(reordered_input_ids)\n",
        "\n",
        "        # Get input and output positions from the order\n",
        "        # Input positions: the current position in the order\n",
        "        # Output positions: the next position in the order\n",
        "        input_positions = order\n",
        "        # Shift the order by 1 to get output positions (target positions)\n",
        "        output_positions = torch.roll(order, -1, dims=1)\n",
        "        # The last position wraps to the first position\n",
        "        output_positions[:, -1] = order[:, 0]\n",
        "\n",
        "        # Apply double positional encoding\n",
        "        hidden_states = self.positional_encoding(hidden_states, input_positions, output_positions)\n",
        "\n",
        "        # Create attention mask based on the order\n",
        "        attention_mask = gpt_input.attention_mask\n",
        "        num_heads = self.protGPT2_model.config.n_head\n",
        "\n",
        "        # Create 4D attention mask [batch_size, num_heads, seq_length, seq_length]\n",
        "        attention_mask = attention_mask.view(batch_size, 1, 1, seq_length)\n",
        "        attention_mask = attention_mask.expand(batch_size, num_heads, seq_length, seq_length)\n",
        "        attention_mask = attention_mask.to(dtype=hidden_states.dtype)\n",
        "\n",
        "        # Create causal mask based on the order\n",
        "        # A token at position i can attend to tokens at positions j where order[j] <= order[i]\n",
        "        # Vectorized causal mask creation\n",
        "        seq_indices = torch.arange(seq_length, device=device)\n",
        "        expanded_seq_indices_i = seq_indices.unsqueeze(1).expand(seq_length, seq_length)\n",
        "        expanded_seq_indices_j = seq_indices.unsqueeze(0).expand(seq_length, seq_length)\n",
        "\n",
        "        causal_mask = torch.zeros((batch_size, seq_length, seq_length), device=device)\n",
        "        for b in range(batch_size):\n",
        "            # Get order for this batch\n",
        "            order_b = order[b]\n",
        "            # Get order values at positions i and j\n",
        "            order_i = order_b[expanded_seq_indices_i]\n",
        "            order_j = order_b[expanded_seq_indices_j]\n",
        "            # Create mask where order_j <= order_i\n",
        "            causal_mask[b] = (order_j <= order_i).float()\n",
        "\n",
        "        # Reshape causal_mask to match attention_mask and combine them\n",
        "        causal_mask = causal_mask.unsqueeze(1)  # [batch_size, 1, seq_length, seq_length]\n",
        "        combined_mask = attention_mask * causal_mask\n",
        "\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            if isinstance(layer, GatedCrossAttentionBlock):\n",
        "                hidden_states = layer(hidden_states, processed_smiles)\n",
        "            else:\n",
        "                hidden_states = layer(hidden_states, attention_mask=combined_mask)[0]\n",
        "\n",
        "        # Get logits\n",
        "        logits = self.protGPT2_model.lm_head(hidden_states)\n",
        "\n",
        "        if targets is None:\n",
        "            if optimize:\n",
        "                # inference-time mini-optimization: only forward the lm_head on the very last position\n",
        "                return logits[:, [-1], :], None\n",
        "            return logits, None\n",
        "\n",
        "        # Compute loss against the targets\n",
        "        # If targets are provided in original order, we need to shuffle them to match our order\n",
        "        if targets is not None:\n",
        "            shuffled_targets = torch.zeros_like(targets)\n",
        "            for b in range(batch_size):\n",
        "                # Reorder the targets according to the order\n",
        "                shuffled_targets[b] = targets[b, order[b]]\n",
        "\n",
        "            loss = F.cross_entropy(\n",
        "                logits.view(-1, logits.size(-1)),\n",
        "                shuffled_targets.view(-1),\n",
        "                ignore_index=-1\n",
        "            )\n",
        "        else:\n",
        "            loss = None\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def custom_generate(self, smiles_string, max_length=200):\n",
        "        device = next(self.parameters()).device\n",
        "\n",
        "        # Get SMILES embeddings\n",
        "        smiles_embeddings = self.polybert_encoder(smiles_string)\n",
        "        processed_smiles = self.smiles_perceiver(smiles_embeddings)\n",
        "\n",
        "        # Initialize with start token\n",
        "        input_ids = torch.tensor([[self.protGPT2_tokenizer.bos_token_id]]).to(device)\n",
        "\n",
        "        # Autoregressive generation\n",
        "        for _ in range(max_length):\n",
        "            inputs_embeds = self.protGPT2_model.transformer.wte(input_ids)\n",
        "            inputs_embeds = self.positional_encoding(inputs_embeds)\n",
        "\n",
        "            hidden_states = inputs_embeds\n",
        "            cross_attn_idx = 0\n",
        "\n",
        "            for i, layer in enumerate(self.layers):\n",
        "                if isinstance(layer, GatedCrossAttentionBlock):\n",
        "                    hidden_states = layer(hidden_states, processed_smiles)\n",
        "                    cross_attn_idx += 1\n",
        "                else:\n",
        "                    hidden_states = layer(hidden_states, attention_mask=None)[0]\n",
        "\n",
        "            next_token_logits = self.protGPT2_model.lm_head(hidden_states[:, -1, :])\n",
        "            next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)\n",
        "\n",
        "            input_ids = torch.cat([input_ids, next_token], dim=-1)\n",
        "\n",
        "            if next_token.item() == self.protGPT2_tokenizer.eos_token_id:\n",
        "                break\n",
        "\n",
        "        return self.protGPT2_tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    def generate(self, smiles_string, max_length=50):\n",
        "        return self.custom_generate(smiles_string, max_length)\n",
        "\n",
        "    def state_dict(self):\n",
        "        state_dict = super().state_dict()\n",
        "        state_dict['smiles_perceiver'] = self.smiles_perceiver.state_dict()\n",
        "        state_dict['cross_attn'] = self.cross_attn.state_dict()\n",
        "        state_dict['polybert_encoder'] = self.polybert_encoder.state_dict()\n",
        "        return state_dict\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        smiles_perceiver_state = state_dict.pop('smiles_perceiver')\n",
        "        cross_attn_state = state_dict.pop('cross_attn')\n",
        "        polybert_encoder_state = state_dict.pop('polybert_encoder')\n",
        "\n",
        "        super().load_state_dict(state_dict)\n",
        "\n",
        "        self.smiles_perceiver.load_state_dict(smiles_perceiver_state)\n",
        "        self.cross_attn.load_state_dict(cross_attn_state)\n",
        "        self.polybert_encoder.load_state_dict(polybert_encoder_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wnL43mTZkIN"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o91I0EXQaF4"
      },
      "source": [
        "### training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWmS0warQa-n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6WRIYHEfN6y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import Levenshtein\n",
        "\n",
        "\n",
        "\n",
        "def print_model_structure(model):\n",
        "    print(\"\\n===== MODEL STRUCTURE ANALYSIS =====\")\n",
        "\n",
        "    # 1. Check which layers have cross-attention\n",
        "    cross_attn_locations = []\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        if isinstance(layer, GatedCrossAttentionBlock):\n",
        "            cross_attn_locations.append(i)\n",
        "\n",
        "    print(f\"\\n📌 CROSS-ATTENTION LAYERS:\")\n",
        "    print(f\"  Total cross-attention blocks: {len(cross_attn_locations)}\")\n",
        "    print(f\"  Located at positions: {cross_attn_locations}\")\n",
        "\n",
        "    # 2. Check parameter freezing by group\n",
        "    frozen_info = {}\n",
        "    trainable_info = {}\n",
        "    total_frozen = 0\n",
        "    total_trainable = 0\n",
        "\n",
        "    # Get lm_head status if it exists\n",
        "    lm_head_status = \"NOT FOUND\"\n",
        "    if hasattr(model.protGPT2_model, 'lm_head'):\n",
        "        if isinstance(model.protGPT2_model.lm_head, GatedCrossAttentionBlock):\n",
        "            lm_head_status = \"REPLACED with GatedCrossAttentionBlock\"\n",
        "        else:\n",
        "            lm_head_trainable = all(p.requires_grad for p in model.protGPT2_model.lm_head.parameters())\n",
        "            lm_head_status = \"TRAINABLE\" if lm_head_trainable else \"FROZEN\"\n",
        "\n",
        "            # Count parameters\n",
        "            lm_head_params = sum(p.numel() for p in model.protGPT2_model.lm_head.parameters())\n",
        "            if lm_head_trainable:\n",
        "                total_trainable += lm_head_params\n",
        "                trainable_info[\"lm_head\"] = lm_head_params\n",
        "            else:\n",
        "                total_frozen += lm_head_params\n",
        "                frozen_info[\"lm_head\"] = lm_head_params\n",
        "\n",
        "    # Check transformer layer status\n",
        "    for i in range(36):  # Assuming 36 transformer layers\n",
        "        layer_name = f\"transformer.h.{i}\"\n",
        "\n",
        "        # Find parameters for this layer\n",
        "        layer_params = []\n",
        "        for name, param in model.protGPT2_model.named_parameters():\n",
        "            if f\"transformer.h.{i}.\" in name:\n",
        "                layer_params.append(param)\n",
        "\n",
        "        if layer_params:\n",
        "            layer_trainable = all(p.requires_grad for p in layer_params)\n",
        "            layer_status = \"TRAINABLE\" if layer_trainable else \"FROZEN\"\n",
        "\n",
        "            # Count parameters\n",
        "            layer_param_count = sum(p.numel() for p in layer_params)\n",
        "            if layer_trainable:\n",
        "                total_trainable += layer_param_count\n",
        "                trainable_info[layer_name] = layer_param_count\n",
        "            else:\n",
        "                total_frozen += layer_param_count\n",
        "                frozen_info[layer_name] = layer_param_count\n",
        "\n",
        "    # Print layer freezing status\n",
        "    print(f\"\\n📌 LAYER FREEZING STATUS:\")\n",
        "    for i in range(36):\n",
        "        layer_name = f\"transformer.h.{i}\"\n",
        "        if layer_name in trainable_info:\n",
        "            print(f\"  Layer {i:2d}: ✅ TRAINABLE ({trainable_info[layer_name]:,} params)\")\n",
        "        elif layer_name in frozen_info:\n",
        "            print(f\"  Layer {i:2d}: ❄️ FROZEN ({frozen_info[layer_name]:,} params)\")\n",
        "        else:\n",
        "            print(f\"  Layer {i:2d}: ⚠️ NOT FOUND\")\n",
        "\n",
        "    print(f\"\\n  LM Head: {lm_head_status}\")\n",
        "\n",
        "    # Print overall stats\n",
        "    total_params = total_trainable + total_frozen\n",
        "    print(f\"\\n📌 PARAMETER SUMMARY:\")\n",
        "    print(f\"  Total parameters: {total_params:,}\")\n",
        "    print(f\"  Trainable parameters: {total_trainable:,} ({total_trainable/total_params:.2%})\")\n",
        "    print(f\"  Frozen parameters: {total_frozen:,} ({total_frozen/total_params:.2%})\")\n",
        "\n",
        "    # Cross-attention specific info\n",
        "    print(f\"\\n📌 CROSS-ATTENTION DETAILS:\")\n",
        "    cross_attn_count = 0\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        if isinstance(layer, GatedCrossAttentionBlock):\n",
        "            cross_attn_count += 1\n",
        "            cross_attn_params = sum(p.numel() for p in layer.parameters())\n",
        "            trainable = all(p.requires_grad for p in layer.parameters())\n",
        "            print(f\"  Cross-Attention #{cross_attn_count} (index {i}): {'✅ TRAINABLE' if trainable else '❄️ FROZEN'} ({cross_attn_params:,} params)\")\n",
        "\n",
        "    print(\"\\n===================================\\n\")\n",
        "\n",
        "# Add this function to model class to get outputs without computing loss internally\n",
        "def add_forward_without_loss_to_model(model):\n",
        "    \"\"\"\n",
        "    Adds a new method to the model to get outputs without computing loss.\n",
        "    Call this function before starting training.\n",
        "    \"\"\"\n",
        "    def forward_without_loss(self, smiles_strings, targets=None):\n",
        "        \"\"\"Get model outputs without computing loss internally for SigmaProtFlamingo\"\"\"\n",
        "        device = next(self.parameters()).device\n",
        "\n",
        "        # Get SMILES embeddings through PolyBERT\n",
        "        smiles_embeddings = self.polybert_encoder(smiles_strings)\n",
        "        processed_smiles = self.smiles_perceiver(smiles_embeddings)\n",
        "\n",
        "        # Initialize with start token\n",
        "        gpt_input = self.protGPT2_tokenizer(\n",
        "            \"<|endoftext|>\",\n",
        "            return_tensors=\"pt\",\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            truncation=True\n",
        "        ).to(device)\n",
        "\n",
        "        input_ids = gpt_input.input_ids.long()\n",
        "        seq_length = input_ids.size(1)\n",
        "        batch_size = 1 if isinstance(smiles_strings, str) else len(smiles_strings)\n",
        "\n",
        "        hidden_states = self.protGPT2_model.transformer.wte(input_ids)\n",
        "\n",
        "        # Use left-to-right order for training with AAR focus\n",
        "        order = torch.arange(seq_length, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "        # Apply double positional encoding\n",
        "        input_positions = order\n",
        "        output_positions = torch.roll(order, -1, dims=1)\n",
        "        output_positions[:, -1] = order[:, 0]\n",
        "\n",
        "        hidden_states = self.positional_encoding(hidden_states, input_positions, output_positions)\n",
        "\n",
        "        # Create attention mask\n",
        "        attention_mask = gpt_input.attention_mask\n",
        "        num_heads = self.protGPT2_model.config.n_head\n",
        "\n",
        "        # Create 4D attention mask [batch_size, num_heads, seq_length, seq_length]\n",
        "        attention_mask = attention_mask.view(batch_size, 1, 1, seq_length)\n",
        "        attention_mask = attention_mask.expand(batch_size, num_heads, seq_length, seq_length)\n",
        "        attention_mask = attention_mask.to(dtype=hidden_states.dtype)\n",
        "\n",
        "        # Create causal mask based on left-to-right order\n",
        "        seq_indices = torch.arange(seq_length, device=device)\n",
        "        expanded_seq_indices_i = seq_indices.unsqueeze(1).expand(seq_length, seq_length)\n",
        "        expanded_seq_indices_j = seq_indices.unsqueeze(0).expand(seq_length, seq_length)\n",
        "\n",
        "        causal_mask = torch.zeros((batch_size, seq_length, seq_length), device=device)\n",
        "        for b in range(batch_size):\n",
        "            order_b = order[b]\n",
        "            order_i = order_b[expanded_seq_indices_i]\n",
        "            order_j = order_b[expanded_seq_indices_j]\n",
        "            causal_mask[b] = (order_j <= order_i).float()\n",
        "\n",
        "        # Reshape causal_mask to match attention_mask and combine them\n",
        "        causal_mask = causal_mask.unsqueeze(1)  # [batch_size, 1, seq_length, seq_length]\n",
        "        combined_mask = attention_mask * causal_mask\n",
        "\n",
        "        # Process through all layers\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            if isinstance(layer, GatedCrossAttentionBlock):\n",
        "                hidden_states = layer(hidden_states, processed_smiles)\n",
        "            else:\n",
        "                hidden_states = layer(hidden_states, attention_mask=combined_mask)[0]\n",
        "\n",
        "        # Get logits without computing loss\n",
        "        logits = self.protGPT2_model.lm_head(hidden_states)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    # Add the method to the model\n",
        "    model.forward_without_loss = forward_without_loss.__get__(model, type(model))\n",
        "    return model\n",
        "\n",
        "def repetition_penalty_loss(predicted_token_ids, target_token_ids, pad_token_id):\n",
        "    \"\"\"\n",
        "    Penalizes repeated amino acid tokens in a sequence.\n",
        "    Returns a penalty value for consecutive repeated tokens.\n",
        "    \"\"\"\n",
        "    # Ignore padding tokens\n",
        "    mask = target_token_ids != pad_token_id\n",
        "\n",
        "    # Shift the sequence by one token to compare\n",
        "    prev_tokens = predicted_token_ids[:, :-1]\n",
        "    curr_tokens = predicted_token_ids[:, 1:]\n",
        "\n",
        "    # Compute a repetition mask (1 if consecutive tokens are the same, 0 otherwise)\n",
        "    repetition_mask = (prev_tokens == curr_tokens).float()\n",
        "\n",
        "    # Apply the mask to only count valid (non-pad) regions\n",
        "    valid_mask = mask[:, 1:].float()\n",
        "    repetition_penalty = (repetition_mask * valid_mask).sum() / (valid_mask.sum() + 1e-8)\n",
        "\n",
        "    return repetition_penalty\n",
        "\n",
        "def sequence_diversity_loss(predicted_logits, pad_token_id, vocab_size):\n",
        "    \"\"\"\n",
        "    Encourages diversity in token distribution across the sequence.\n",
        "    Penalizes sequences that use a limited set of amino acids.\n",
        "    \"\"\"\n",
        "    # Get predicted token ids\n",
        "    predicted_token_ids = torch.argmax(predicted_logits, dim=-1)\n",
        "\n",
        "    # Create mask to ignore padding\n",
        "    mask = predicted_token_ids != pad_token_id\n",
        "\n",
        "    # Count frequency of each token\n",
        "    batch_size = predicted_token_ids.size(0)\n",
        "    token_counts = torch.zeros(batch_size, vocab_size, device=predicted_logits.device)\n",
        "\n",
        "    # For each sequence in the batch\n",
        "    diversity_loss = 0.0\n",
        "    for b in range(batch_size):\n",
        "        # Count tokens in this sequence (excluding padding)\n",
        "        seq_tokens = predicted_token_ids[b][mask[b]]\n",
        "        if len(seq_tokens) == 0:\n",
        "            continue\n",
        "\n",
        "        # Count each token\n",
        "        for t in range(vocab_size):\n",
        "            token_counts[b, t] = (seq_tokens == t).sum()\n",
        "\n",
        "        # Normalize to get probability distribution\n",
        "        token_probs = token_counts[b] / (len(seq_tokens) + 1e-8)\n",
        "\n",
        "        # Calculate entropy (higher is more diverse)\n",
        "        # We negate entropy to make it a loss (lower is better)\n",
        "        non_zero_probs = token_probs[token_probs > 0]\n",
        "        entropy = -torch.sum(non_zero_probs * torch.log(non_zero_probs + 1e-8))\n",
        "\n",
        "        # Add to batch loss with negation (we want to maximize entropy = diversity)\n",
        "        diversity_loss += -entropy\n",
        "\n",
        "    # Average over batch\n",
        "    return diversity_loss / batch_size\n",
        "\n",
        "def sequence_similarity_loss(predicted_tokens, target_tokens, tokenizer):\n",
        "    \"\"\"\n",
        "    Calculate a loss based on sequence-level similarity.\n",
        "    Uses normalized Levenshtein distance.\n",
        "    \"\"\"\n",
        "    batch_size = predicted_tokens.shape[0]\n",
        "    total_distance = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # Convert token IDs to strings, skipping padding and special tokens\n",
        "        pred_seq = tokenizer.decode(predicted_tokens[i], skip_special_tokens=True)\n",
        "        target_seq = tokenizer.decode(target_tokens[i], skip_special_tokens=True)\n",
        "\n",
        "        # Calculate normalized Levenshtein distance\n",
        "        if len(target_seq) > 0:\n",
        "            distance = Levenshtein.distance(pred_seq, target_seq) / max(len(target_seq), 1)\n",
        "            total_distance += distance\n",
        "\n",
        "    return total_distance / batch_size\n",
        "\n",
        "\n",
        "def apply_token_masking(input_ids, tokenizer, mask_prob=0.15):\n",
        "    masked_input_ids = input_ids.clone()\n",
        "    labels = input_ids.clone()\n",
        "\n",
        "    # Create mask for tokens that can be masked (exclude padding)\n",
        "    padding_mask = input_ids != tokenizer.pad_token_id\n",
        "\n",
        "    # Generate random mask with specified probability\n",
        "    random_mask = torch.rand(input_ids.shape, device=input_ids.device) < mask_prob\n",
        "\n",
        "    # Only apply masking to non-padding tokens\n",
        "    mask_indices = padding_mask & random_mask\n",
        "\n",
        "    # Replace masked tokens with mask token\n",
        "    if tokenizer.mask_token_id is not None:\n",
        "        mask_token_id = tokenizer.mask_token_id\n",
        "    else:\n",
        "        # If model doesn't have a mask token, use a special token or UNK token\n",
        "        mask_token_id = tokenizer.unk_token_id\n",
        "\n",
        "    masked_input_ids[mask_indices] = mask_token_id\n",
        "\n",
        "    # For the loss computation, we only want to predict the masked tokens\n",
        "    # Set labels to -100 for non-masked tokens (CrossEntropyLoss will ignore these)\n",
        "    labels[~mask_indices] = -100\n",
        "\n",
        "    return masked_input_ids, labels\n",
        "\n",
        "\n",
        "def train_with_improved_aar_objective(model, train_loader, val_loader, num_epochs, device,\n",
        "                           curriculum_steps=0, l2_reg=1e-5, sample_smiles=None):\n",
        "    # Add the forward_without_loss method to the model\n",
        "    model = add_forward_without_loss_to_model(model)\n",
        "\n",
        "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5, weight_decay=l2_reg)\n",
        "\n",
        "    # Use label smoothing to prevent overconfident predictions\n",
        "    criterion = nn.CrossEntropyLoss(\n",
        "        ignore_index=-100,  # Changed from pad_token_id to -100 for MLM\n",
        "        reduction='none',\n",
        "        label_smoothing=0.1\n",
        "    )\n",
        "\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "    # Hyperparameters for different loss components\n",
        "    lambda_rep = 0.2       # Weight for repetition penalty\n",
        "    # lambda_div = 0.1       # Weight for diversity loss\n",
        "    lambda_seq = 0.15      # Weight for sequence-level similarity loss\n",
        "\n",
        "    # MLM parameters\n",
        "    use_mlm = True\n",
        "    mlm_prob = 0.15\n",
        "\n",
        "    loss_log = []\n",
        "    new_checkpoint_dir = \"/content/drive/MyDrive/classes+projects/plastic_enzyme_project/2024/codes/sigma_ckpt_full_dataset_enhanced_metrics\"\n",
        "    os.makedirs(new_checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    best_val_aar = 0.0  # Track best validation AAR instead of loss\n",
        "\n",
        "    vocab_size = model.protGPT2_model.config.vocab_size\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_correct = 0\n",
        "        total_tokens = 0\n",
        "\n",
        "        # Calculate curriculum ratio (if using curriculum learning)\n",
        "        curriculum_ratio = min(1.0, epoch / (num_epochs / 2)) if curriculum_steps > 0 else 1.0\n",
        "        print(f\"Curriculum ratio: {curriculum_ratio:.2f}\")\n",
        "\n",
        "        for batch_idx, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
        "            smiles_strings = batch['smiles']\n",
        "            proteins = batch['proteins']\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            target_encoding = model.protGPT2_tokenizer(\n",
        "                proteins,\n",
        "                return_tensors=\"pt\",\n",
        "                padding='max_length',\n",
        "                max_length=model.max_len,\n",
        "                truncation=True\n",
        "            ).to(device)\n",
        "\n",
        "            # Alternate between MLM and autoregressive training\n",
        "            use_masking_this_batch = use_mlm and (epoch % 2 == 0 or batch_idx % 2 == 0)\n",
        "            if use_masking_this_batch:\n",
        "                masked_input_ids, mlm_labels = apply_token_masking(\n",
        "                    target_encoding.input_ids,\n",
        "                    model.protGPT2_tokenizer,\n",
        "                    mask_prob=mlm_prob\n",
        "                )\n",
        "\n",
        "                # Get model outputs with masked input\n",
        "                outputs = model.forward_without_loss(smiles_strings, masked_input_ids)\n",
        "\n",
        "                # Calculate loss only on masked positions\n",
        "                token_loss = criterion(outputs.view(-1, outputs.size(-1)), mlm_labels.view(-1))\n",
        "                token_loss = token_loss.view(outputs.size(0), -1)\n",
        "\n",
        "                # Create mask for valid tokens (not -100)\n",
        "                valid_mask = mlm_labels != -100\n",
        "            else:\n",
        "                # Original approach without masking\n",
        "                outputs = model.forward_without_loss(smiles_strings, target_encoding.input_ids)\n",
        "                token_loss = criterion(outputs.view(-1, outputs.size(-1)), target_encoding.input_ids.view(-1))\n",
        "                token_loss = token_loss.view(outputs.size(0), -1)\n",
        "                valid_mask = target_encoding.input_ids != model.protGPT2_tokenizer.pad_token_id\n",
        "\n",
        "            # Calculate token-level accuracy\n",
        "            predicted_token_ids = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            # Ensure predicted_token_ids has the same shape\n",
        "            if predicted_token_ids.shape[1] < model.max_len:\n",
        "                predicted_token_ids = torch.nn.functional.pad(\n",
        "                    predicted_token_ids,\n",
        "                    (0, model.max_len - predicted_token_ids.shape[1]),\n",
        "                    value=model.protGPT2_tokenizer.pad_token_id\n",
        "                )\n",
        "\n",
        "            # For MLM, we only check accuracy on masked positions\n",
        "            if use_mlm:\n",
        "                original_ids = target_encoding.input_ids.clone()\n",
        "                mask_positions = mlm_labels != -100\n",
        "\n",
        "                # Compute accuracy only on masked positions\n",
        "                token_correct = (predicted_token_ids == original_ids) & mask_positions\n",
        "                pad_mask = mask_positions\n",
        "            else:\n",
        "                # Original accuracy calculation\n",
        "                pad_mask = target_encoding.input_ids != model.protGPT2_tokenizer.pad_token_id\n",
        "                token_correct = (predicted_token_ids == target_encoding.input_ids) & pad_mask\n",
        "\n",
        "            # Create a weighting mask that balances correct and incorrect predictions\n",
        "            incorrect_weight = 1.5 + curriculum_ratio * 0.5  # Weight increases from 1.5 to 2.0 over training\n",
        "            weight_mask = (~token_correct).float() * incorrect_weight + 1.0\n",
        "            weight_mask = weight_mask * valid_mask.float()  # Zero out padding or non-masked tokens\n",
        "\n",
        "            # Apply the weighting mask to the token losses\n",
        "            weighted_loss = (token_loss * weight_mask).sum() / (weight_mask.sum() + 1e-8)\n",
        "\n",
        "            # Calculate repetition penalty\n",
        "            rep_penalty = repetition_penalty_loss(\n",
        "                predicted_token_ids,\n",
        "                target_encoding.input_ids,\n",
        "                model.protGPT2_tokenizer.pad_token_id\n",
        "            )\n",
        "\n",
        "            # # Calculate diversity loss\n",
        "            # div_loss = sequence_diversity_loss(\n",
        "            #     outputs,\n",
        "            #     model.protGPT2_tokenizer.pad_token_id,\n",
        "            #     vocab_size\n",
        "            # )\n",
        "\n",
        "            # Calculate sequence-level similarity loss\n",
        "            seq_loss = sequence_similarity_loss(\n",
        "                predicted_token_ids,\n",
        "                target_encoding.input_ids,\n",
        "                model.protGPT2_tokenizer\n",
        "            )\n",
        "\n",
        "            # Combine all losses with appropriate weights\n",
        "            total_loss_val = (\n",
        "                weighted_loss +\n",
        "                lambda_rep * rep_penalty +\n",
        "                # lambda_div * div_loss +\n",
        "                lambda_seq * seq_loss\n",
        "            )\n",
        "\n",
        "            # Print all loss components every 50 batches for monitoring\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f\"  Loss components: CE={weighted_loss:.4f}, Rep={rep_penalty:.4f}, Seq={seq_loss:.4f}\")\n",
        "\n",
        "            # Use the combined loss for backpropagation\n",
        "            total_loss_val.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            # For logging purposes, calculate the standard loss\n",
        "            standard_loss = token_loss[valid_mask].mean().item() if valid_mask.sum() > 0 else 0\n",
        "            total_loss += standard_loss\n",
        "\n",
        "            # Calculate AAR metrics for logging\n",
        "            correct = token_correct.sum().item()\n",
        "            total = pad_mask.sum().item()\n",
        "            total_correct += correct\n",
        "            total_tokens += total\n",
        "\n",
        "            # Print batch statistics occasionally\n",
        "            if batch_idx % 10 == 0:\n",
        "                batch_aar = (correct / total * 100) if total > 0 else 0\n",
        "                print(f\"  Batch {batch_idx}: Loss={standard_loss:.4f}, AAR={batch_aar:.2f}%\")\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        amino_acid_recovery = total_correct / total_tokens * 100\n",
        "\n",
        "        # Prevent overflow when calculating perplexity\n",
        "        try:\n",
        "            perplexity = math.exp(avg_loss)\n",
        "        except OverflowError:\n",
        "            perplexity = float('inf')  # Return infinity if the loss is too high\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
        "        print(f\"Perplexity: {perplexity}\")\n",
        "        print(f\"Amino Acid Recovery: {amino_acid_recovery:.2f}%\")\n",
        "\n",
        "        val_loss, val_perplexity, val_aar, val_results = validate_with_enhanced_metrics(model, val_loader, nn.CrossEntropyLoss(ignore_index=model.protGPT2_tokenizer.pad_token_id), device)\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Perplexity: {val_perplexity:.4f}, Amino Acid Recovery: {val_aar:.2f}%\")\n",
        "\n",
        "        # Save validation results\n",
        "        import json\n",
        "        json.dump(val_results, open(\"validation_results.json\", \"w\"), indent=4)\n",
        "\n",
        "        loss_log.append({\n",
        "            'epoch': epoch+1,\n",
        "            'train_loss': avg_loss,\n",
        "            'train_perplexity': perplexity,\n",
        "            'train_accuracy': amino_acid_recovery,\n",
        "            'val_loss': val_loss,\n",
        "            'val_perplexity': val_perplexity,\n",
        "            'val_accuracy': val_aar\n",
        "        })\n",
        "\n",
        "        checkpoint_path = os.path.join(new_checkpoint_dir, f\"sigma_epoch_{epoch+1}.pth\")\n",
        "\n",
        "        # Save checkpoint based on better AAR, but also consider perplexity\n",
        "        if val_aar > best_val_aar:\n",
        "            best_val_aar = val_aar\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            print(f\"Checkpoint saved at {checkpoint_path} (Validation AAR improved to {best_val_aar:.2f}%)\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    loss_df = pd.DataFrame(loss_log)\n",
        "    loss_df.to_csv(\"/content/drive/MyDrive/classes+projects/plastic_enzyme_project/2024/codes/sigma_improved_aar_log.csv\", index=False)\n",
        "\n",
        "    # Plot training metrics\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # Filter out invalid values for plotting\n",
        "    loss_df['train_perplexity_plot'] = loss_df['train_perplexity'].apply(lambda x: x if x != -1 and x < 1000 else None)\n",
        "    loss_df['val_perplexity_plot'] = loss_df['val_perplexity'].apply(lambda x: x if x != -1 and x < 1000 else None)\n",
        "\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(loss_df['epoch'], loss_df['train_loss'], label='Train')\n",
        "    plt.plot(loss_df['epoch'], loss_df['val_loss'], label='Validation')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss vs. Epoch')\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(loss_df['epoch'], loss_df['train_perplexity'], label='Train')\n",
        "    plt.plot(loss_df['epoch'], loss_df['val_perplexity'], label='Validation')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Perplexity')\n",
        "    plt.legend()\n",
        "    plt.title('Perplexity vs. Epoch')\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(loss_df['epoch'], loss_df['train_accuracy'], label='Train')\n",
        "    plt.plot(loss_df['epoch'], loss_df['val_accuracy'], label='Validation')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Amino Acid Recovery (%)')\n",
        "    plt.legend()\n",
        "    plt.title('AAR vs. Epoch')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/content/drive/MyDrive/classes+projects/plastic_enzyme_project/2024/codes/sigma_improved_aar_training_metrics.png\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_kb2PQmkBng"
      },
      "outputs": [],
      "source": [
        "def validate_with_enhanced_metrics(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    # Track advanced metrics\n",
        "    total_levenshtein = 0\n",
        "    total_diversity = 0\n",
        "    total_repetition = 0\n",
        "    total_sequences = 0\n",
        "\n",
        "    saved_results = []  # Store ground truth vs predicted sequences and SMILES\n",
        "\n",
        "    with torch.no_grad():\n",
        "        sampled_batches = random.sample(range(len(val_loader)), min(50, len(val_loader)))\n",
        "\n",
        "        for i, batch in enumerate(val_loader):\n",
        "            smiles_strings = batch['smiles']\n",
        "            proteins = batch['proteins']\n",
        "            protein_masks = batch['protein_masks'].to(device)\n",
        "\n",
        "            target_encoding = model.protGPT2_tokenizer(\n",
        "                proteins,\n",
        "                return_tensors=\"pt\",\n",
        "                padding='max_length',\n",
        "                max_length=model.max_len,\n",
        "                truncation=True\n",
        "            ).to(device)\n",
        "\n",
        "            # For validation, we don't use MLM - we want to evaluate on full sequence prediction\n",
        "            outputs = model.forward_without_loss(smiles_strings, target_encoding.input_ids)\n",
        "\n",
        "            # Calculate loss on full sequence prediction\n",
        "            loss_fn = nn.CrossEntropyLoss(ignore_index=model.protGPT2_tokenizer.pad_token_id)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.size(-1)), target_encoding.input_ids.view(-1))\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Amino Acid Recovery Calculation (excluding padding tokens)\n",
        "            predicted_token_ids = torch.argmax(outputs, dim=-1)\n",
        "            predicted_token_ids = torch.nn.functional.pad(\n",
        "                predicted_token_ids, (0, model.max_len - predicted_token_ids.shape[1]),\n",
        "                value=model.protGPT2_tokenizer.pad_token_id\n",
        "            )\n",
        "\n",
        "            mask = target_encoding.input_ids != model.protGPT2_tokenizer.pad_token_id\n",
        "            correct = (predicted_token_ids[mask] == target_encoding.input_ids[mask]).sum().item()\n",
        "            total = mask.sum().item()\n",
        "            total_correct += correct\n",
        "            total_tokens += total\n",
        "\n",
        "            # Calculate diversity for each sequence\n",
        "            for b in range(len(predicted_token_ids)):\n",
        "                pred_seq_tokens = predicted_token_ids[b][mask[b]]\n",
        "                if len(pred_seq_tokens) == 0:\n",
        "                    continue\n",
        "\n",
        "                # Count unique tokens\n",
        "                unique_tokens = torch.unique(pred_seq_tokens).size(0)\n",
        "                seq_diversity = unique_tokens / len(pred_seq_tokens)\n",
        "\n",
        "                # Measure repetition - look for consecutive repeated tokens\n",
        "                consecutive_repeats = 0\n",
        "                for t in range(1, len(pred_seq_tokens)):\n",
        "                    if pred_seq_tokens[t] == pred_seq_tokens[t-1]:\n",
        "                        consecutive_repeats += 1\n",
        "\n",
        "                normalized_repeats = consecutive_repeats / max(1, len(pred_seq_tokens) - 1)\n",
        "\n",
        "                # Decode sequences for Levenshtein distance\n",
        "                pred_seq = model.protGPT2_tokenizer.decode(predicted_token_ids[b], skip_special_tokens=True)\n",
        "                true_seq = model.protGPT2_tokenizer.decode(target_encoding.input_ids[b], skip_special_tokens=True)\n",
        "\n",
        "                # Calculate normalized Levenshtein distance\n",
        "                if len(true_seq) > 0:\n",
        "                    levenshtein_dist = Levenshtein.distance(pred_seq, true_seq) / len(true_seq)\n",
        "                    total_levenshtein += levenshtein_dist\n",
        "\n",
        "                total_diversity += seq_diversity\n",
        "                total_repetition += normalized_repeats\n",
        "                total_sequences += 1\n",
        "\n",
        "            # Save randomly selected ground truth vs predicted sequences and SMILES\n",
        "            if i in sampled_batches:\n",
        "                ground_truth = model.protGPT2_tokenizer.decode(target_encoding.input_ids[0], skip_special_tokens=True)\n",
        "                predicted = model.protGPT2_tokenizer.decode(predicted_token_ids[0], skip_special_tokens=True)\n",
        "\n",
        "                # Calculate per-sequence AAR for this example\n",
        "                seq_mask = target_encoding.input_ids[0] != model.protGPT2_tokenizer.pad_token_id\n",
        "                seq_correct = (predicted_token_ids[0][seq_mask] == target_encoding.input_ids[0][seq_mask]).sum().item()\n",
        "                seq_total = seq_mask.sum().item()\n",
        "                seq_aar = (seq_correct / seq_total * 100) if seq_total > 0 else 0\n",
        "\n",
        "                # Calculate additional metrics for this sample\n",
        "                # 1. Count longest repeated segment\n",
        "                pred_seq = model.protGPT2_tokenizer.decode(predicted_token_ids[0], skip_special_tokens=True)\n",
        "                longest_repeat = find_longest_repeat(pred_seq)\n",
        "\n",
        "                # 2. Calculate amino acid composition similarity\n",
        "                aa_comp_similarity = amino_acid_composition_similarity(ground_truth, predicted)\n",
        "\n",
        "                saved_results.append({\n",
        "                    'SMILES': smiles_strings[0],\n",
        "                    'Ground Truth': ground_truth,\n",
        "                    'Predicted': predicted,\n",
        "                    'Sequence AAR': f\"{seq_aar:.2f}%\",\n",
        "                    'Levenshtein Distance': f\"{Levenshtein.distance(predicted, ground_truth)}\",\n",
        "                    'Normalized Levenshtein': f\"{Levenshtein.distance(predicted, ground_truth) / max(1, len(ground_truth)):.4f}\",\n",
        "                    'Longest Repeat': longest_repeat,\n",
        "                    'AA Composition Similarity': f\"{aa_comp_similarity:.4f}\"\n",
        "                })\n",
        "\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    amino_acid_recovery = total_correct / total_tokens * 100\n",
        "\n",
        "    # Calculate average advanced metrics\n",
        "    avg_levenshtein = total_levenshtein / total_sequences if total_sequences > 0 else 0\n",
        "    avg_diversity = total_diversity / total_sequences if total_sequences > 0 else 0\n",
        "    avg_repetition = total_repetition / total_sequences if total_sequences > 0 else 0\n",
        "\n",
        "    # Prevent overflow when calculating perplexity\n",
        "    try:\n",
        "        perplexity = math.exp(avg_loss)\n",
        "    except OverflowError:\n",
        "        perplexity = float('inf')  # Return infinity if the loss is too high\n",
        "\n",
        "    # Add advanced metrics to the results\n",
        "    evaluation_metrics = {\n",
        "        'loss': avg_loss,\n",
        "        'perplexity': perplexity,\n",
        "        'aar': amino_acid_recovery,\n",
        "        'levenshtein': avg_levenshtein,\n",
        "        'diversity': avg_diversity,\n",
        "        'repetition': avg_repetition\n",
        "    }\n",
        "\n",
        "    return avg_loss, perplexity, amino_acid_recovery, saved_results\n",
        "\n",
        "def find_longest_repeat(sequence):\n",
        "    \"\"\"Find the longest repeated substring in the sequence.\"\"\"\n",
        "    if not sequence:\n",
        "        return 0\n",
        "\n",
        "    longest = 0\n",
        "    current = 1\n",
        "\n",
        "    for i in range(1, len(sequence)):\n",
        "        if sequence[i] == sequence[i-1]:\n",
        "            current += 1\n",
        "        else:\n",
        "            longest = max(longest, current)\n",
        "            current = 1\n",
        "\n",
        "    longest = max(longest, current)\n",
        "    return longest\n",
        "\n",
        "def amino_acid_composition_similarity(seq1, seq2):\n",
        "    \"\"\"\n",
        "    Calculate the similarity between the amino acid compositions of two sequences.\n",
        "    Returns a value between 0 and 1, where 1 means identical composition.\n",
        "    \"\"\"\n",
        "    if not seq1 or not seq2:\n",
        "        return 0\n",
        "\n",
        "    # Count amino acids in each sequence\n",
        "    aa_count1 = {}\n",
        "    aa_count2 = {}\n",
        "\n",
        "    for aa in seq1:\n",
        "        aa_count1[aa] = aa_count1.get(aa, 0) + 1\n",
        "\n",
        "    for aa in seq2:\n",
        "        aa_count2[aa] = aa_count2.get(aa, 0) + 1\n",
        "\n",
        "    # Get the union of all amino acids\n",
        "    all_aas = set(aa_count1.keys()) | set(aa_count2.keys())\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    dot_product = sum(aa_count1.get(aa, 0) * aa_count2.get(aa, 0) for aa in all_aas)\n",
        "\n",
        "    norm1 = math.sqrt(sum(count**2 for count in aa_count1.values()))\n",
        "    norm2 = math.sqrt(sum(count**2 for count in aa_count2.values()))\n",
        "\n",
        "    if norm1 == 0 or norm2 == 0:\n",
        "        return 0\n",
        "\n",
        "    return dot_product / (norm1 * norm2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfYBZUMhfOTB"
      },
      "source": [
        "### inference + training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWlqqd7_tO8_"
      },
      "source": [
        "#### all frozen _ 34+35 has cross_attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-67RvdafPdi"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load and preprocess data\n",
        "train_data = preprocess_snp_data('/content/train_data.csv')\n",
        "val_data = preprocess_snp_data('/content/val_data.csv')\n",
        "\n",
        "# train_data = train_data.sample(frac=0.01, random_state=42)\n",
        "# val_data = val_data.sample(frac=0.01, random_state=42)\n",
        "\n",
        "train_data = filter_datasets(train_data)\n",
        "val_data = filter_datasets(val_data)\n",
        "\n",
        "# Calculate max sequence length\n",
        "max_length = max(\n",
        "    train_data['protein_length'].max(),\n",
        "    val_data['protein_length'].max()\n",
        ")\n",
        "max_length = min(max_length, 1024)  # Cap at 1024 or your desired maximum\n",
        "print(f\"Max sequence length: {max_length}\")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ProteinGenerationDataset(train_data, max_length)\n",
        "val_dataset = ProteinGenerationDataset(val_data, max_length)\n",
        "\n",
        "# Create dataloaders with custom collate function\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=1,  # Adjust based on your GPU memory\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "# # Initialize model with sigma-gpt capabilities\n",
        "# model = SigmaProtFlamingo(\n",
        "#     model_path='nferruz/ProtGPT2',\n",
        "#     max_len=max_length,\n",
        "#     cross_attn_every=2,\n",
        "#     dim_head=64,\n",
        "#     heads=8,\n",
        "#     perceiver_depth=2,\n",
        "#     perceiver_num_latents=64\n",
        "# ).to(device)\n",
        "\n",
        "\n",
        "# Initialize model with sigma-gpt capabilities but without any cross-attention initially\n",
        "model = SigmaProtFlamingo(\n",
        "    model_path='nferruz/ProtGPT2',\n",
        "    max_len=max_length,\n",
        "    cross_attn_every=999,\n",
        "    dim_head=64,\n",
        "    heads=8,\n",
        "    perceiver_depth=2,\n",
        "    perceiver_num_latents=64\n",
        ")  # Don't move to device yet\n",
        "\n",
        "# The model structure shows that model.layers contains the transformer blocks\n",
        "# model.protGPT2_model.transformer.h contains the GPT2Blocks\n",
        "\n",
        "# Let's recreate the layers list with cross-attention only after the last two blocks\n",
        "new_layers = []\n",
        "\n",
        "# First, get all the original transformer blocks\n",
        "transformer_blocks = model.protGPT2_model.transformer.h\n",
        "\n",
        "# Total number of transformer blocks\n",
        "num_blocks = len(transformer_blocks)\n",
        "print(f\"Total transformer blocks: {num_blocks}\")\n",
        "\n",
        "# Add each transformer block, with cross-attention after the last two blocks\n",
        "for i, block in enumerate(transformer_blocks):\n",
        "    # Add the transformer block\n",
        "    new_layers.append(block)\n",
        "\n",
        "    # Add cross-attention after the last two blocks\n",
        "    if i == num_blocks - 2 or i == num_blocks - 1:\n",
        "        print(f\"Adding cross-attention after block {i}\")\n",
        "        new_layers.append(GatedCrossAttentionBlock(\n",
        "            dim=model.protGPT2_model.config.n_embd,\n",
        "            dim_head=64,\n",
        "            heads=8\n",
        "        ))\n",
        "\n",
        "# Replace the model's layers with our new sequence\n",
        "model.layers = nn.ModuleList(new_layers)\n",
        "\n",
        "\n",
        "# Now move the entire model to the device after modifying it\n",
        "model = model.to(device)\n",
        "\n",
        "# Count how many cross-attention blocks were added\n",
        "cross_attn_count = sum(1 for layer in model.layers if isinstance(layer, GatedCrossAttentionBlock))\n",
        "print(f\"Added {cross_attn_count} cross-attention blocks\")\n",
        "\n",
        "\n",
        "# Add this line after replacing model.layers with new_layers and moving to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Print more detailed layer structure first\n",
        "for name, _ in model.protGPT2_model.named_parameters():\n",
        "    if 'transformer.h' in name:\n",
        "        print(name)\n",
        "        break  # Just print one example to see the structure\n",
        "\n",
        "\n",
        "# Check the highest layer index in the model\n",
        "max_layer_idx = -1\n",
        "for name, _ in model.protGPT2_model.named_parameters():\n",
        "    if 'transformer.h.' in name:\n",
        "        # Extract the layer index which comes after 'transformer.h.'\n",
        "        parts = name.split('.')\n",
        "        if len(parts) > 2:\n",
        "            try:\n",
        "                layer_idx = int(parts[2])\n",
        "                max_layer_idx = max(max_layer_idx, layer_idx)\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "print(f\"Total number of transformer layers: {max_layer_idx + 1}\")\n",
        "\n",
        "# Then modify the freezing code to match the actual structure\n",
        "# This assumes the layer indexing is inside the parameter names\n",
        "for name, param in model.protGPT2_model.named_parameters():\n",
        "  param.requires_grad = False  # Freeze everything else\n",
        "\n",
        "\n",
        "print_model_structure(model)\n",
        "\n",
        "\n",
        "###___________________________________________________________________________________\n",
        "\n",
        "# # Directly check if 'lm_head' exists as an attribute\n",
        "# if hasattr(model.protGPT2_model, 'lm_head'):\n",
        "#     print(\"lm_head exists as an attribute!\")\n",
        "#     print(model.protGPT2_model.lm_head)\n",
        "\n",
        "#     # Check if it has parameters\n",
        "#     if hasattr(model.protGPT2_model.lm_head, 'parameters'):\n",
        "#         print(\"lm_head has parameters!\")\n",
        "\n",
        "#         # Check requires_grad for lm_head manually\n",
        "#         for param in model.protGPT2_model.lm_head.parameters():\n",
        "#             print(f\"lm_head requires_grad: {param.requires_grad}\")\n",
        "#     else:\n",
        "#         print(\"WARNING: lm_head has no registered parameters!\")\n",
        "# else:\n",
        "#     print(\"WARNING: lm_head does not exist as an attribute!\")\n",
        "\n",
        "# # Unfreeze lm_head manually\n",
        "# if hasattr(model.protGPT2_model, 'lm_head'):\n",
        "#     for param in model.protGPT2_model.lm_head.parameters():\n",
        "#         param.requires_grad = True\n",
        "#     print(\"lm_head manually unfrozen!\")\n",
        "\n",
        "# # Verify if lm_head is now trainable\n",
        "# for param in model.protGPT2_model.lm_head.parameters():\n",
        "#     print(f\"lm_head requires_grad: {param.requires_grad}\")\n",
        "\n",
        "# Verify which parameters are trainable\n",
        "total_params = 0\n",
        "trainable_params = 0\n",
        "for name, param in model.named_parameters():\n",
        "    total_params += param.numel()\n",
        "    if param.requires_grad:\n",
        "        trainable_params += param.numel()\n",
        "\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.2%})\")\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "# Training loop with curriculum learning\n",
        "# Start with 50% of sequences in left-to-right order and gradually increase to 100% random\n",
        "curriculum_steps = int(0.5 * num_epochs * len(train_loader))  # Curriculum over first half of training\n",
        "# print(\"Starting training with sigma-gpt capabilities...\")\n",
        "# train_with_improved_aar_objective(\n",
        "#     model,\n",
        "#     train_loader,\n",
        "#     val_loader,\n",
        "#     num_epochs,\n",
        "#     device,\n",
        "#     curriculum_steps=curriculum_steps\n",
        "# )\n",
        "\n",
        "###___________________________________________________________________________________\n",
        "\n",
        "# # Generate and evaluate\n",
        "# print(\"Generating proteins for test set...\")\n",
        "# test_results = generate_and_evaluate(model, test_loader, device)\n",
        "\n",
        "# # Save results\n",
        "# print(\"Saving results...\")\n",
        "# results_path = '/content/drive/MyDrive/classes+projects/plastic_enzyme_project/2024/codes/test_results.json'\n",
        "# with open(results_path, 'w') as f:\n",
        "#     json.dump(test_results, f, indent=2)\n",
        "\n",
        "# print(f\"Results saved to {results_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqmrJpgOtnBW"
      },
      "source": [
        "#### all but lm head is frozen _ cross attn 34+35+lmhead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hsqe5zYSJ5Bh"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load and preprocess data\n",
        "train_data = preprocess_snp_data('/content/train_data.csv')\n",
        "val_data = preprocess_snp_data('/content/val_data.csv')\n",
        "\n",
        "# train_data = train_data.sample(frac=0.01, random_state=42)\n",
        "# val_data = val_data.sample(frac=0.01, random_state=42)\n",
        "\n",
        "train_data = filter_datasets(train_data)\n",
        "val_data = filter_datasets(val_data)\n",
        "\n",
        "# Calculate max sequence length\n",
        "max_length = max(\n",
        "    train_data['protein_length'].max(),\n",
        "    val_data['protein_length'].max()\n",
        ")\n",
        "max_length = min(max_length, 1024)  # Cap at 1024 or your desired maximum\n",
        "print(f\"Max sequence length: {max_length}\")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ProteinGenerationDataset(train_data, max_length)\n",
        "val_dataset = ProteinGenerationDataset(val_data, max_length)\n",
        "\n",
        "# Create dataloaders with custom collate function\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=1,  # Adjust based on your GPU memory\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "# # Initialize model with sigma-gpt capabilities\n",
        "# model = SigmaProtFlamingo(\n",
        "#     model_path='nferruz/ProtGPT2',\n",
        "#     max_len=max_length,\n",
        "#     cross_attn_every=2,\n",
        "#     dim_head=64,\n",
        "#     heads=8,\n",
        "#     perceiver_depth=2,\n",
        "#     perceiver_num_latents=64\n",
        "# ).to(device)\n",
        "\n",
        "\n",
        "# Initialize model with sigma-gpt capabilities but without any cross-attention initially\n",
        "model = SigmaProtFlamingo(\n",
        "    model_path='nferruz/ProtGPT2',\n",
        "    max_len=max_length,\n",
        "    cross_attn_every=999,\n",
        "    dim_head=64,\n",
        "    heads=8,\n",
        "    perceiver_depth=2,\n",
        "    perceiver_num_latents=64\n",
        ")  # Don't move to device yet\n",
        "\n",
        "# The model structure shows that model.layers contains the transformer blocks\n",
        "# model.protGPT2_model.transformer.h contains the GPT2Blocks\n",
        "\n",
        "# Let's recreate the layers list with cross-attention only after the last two blocks\n",
        "new_layers = []\n",
        "\n",
        "# First, get all the original transformer blocks\n",
        "transformer_blocks = model.protGPT2_model.transformer.h\n",
        "\n",
        "# Total number of transformer blocks\n",
        "num_blocks = len(transformer_blocks)\n",
        "print(f\"Total transformer blocks: {num_blocks}\")\n",
        "\n",
        "# Add each transformer block, with cross-attention after the last two blocks\n",
        "for i, block in enumerate(transformer_blocks):\n",
        "    # Add the transformer block\n",
        "    new_layers.append(block)\n",
        "\n",
        "    # Add cross-attention after the last two blocks\n",
        "    if i == num_blocks - 2 or i == num_blocks - 1:\n",
        "        print(f\"Adding cross-attention after block {i}\")\n",
        "        new_layers.append(GatedCrossAttentionBlock(\n",
        "            dim=model.protGPT2_model.config.n_embd,\n",
        "            dim_head=64,\n",
        "            heads=8\n",
        "        ))\n",
        "\n",
        "# Replace the model's layers with our new sequence\n",
        "model.layers = nn.ModuleList(new_layers)\n",
        "\n",
        "# Now move the entire model to the device after modifying it\n",
        "model = model.to(device)\n",
        "\n",
        "# Count how many cross-attention blocks were added\n",
        "cross_attn_count = sum(1 for layer in model.layers if isinstance(layer, GatedCrossAttentionBlock))\n",
        "print(f\"Added {cross_attn_count} cross-attention blocks\")\n",
        "\n",
        "\n",
        "# Print more detailed layer structure first\n",
        "for name, _ in model.protGPT2_model.named_parameters():\n",
        "    if 'transformer.h' in name:\n",
        "        print(name)\n",
        "        break  # Just print one example to see the structure\n",
        "\n",
        "\n",
        "# Check the highest layer index in the model\n",
        "max_layer_idx = -1\n",
        "for name, _ in model.protGPT2_model.named_parameters():\n",
        "    if 'transformer.h.' in name:\n",
        "        # Extract the layer index which comes after 'transformer.h.'\n",
        "        parts = name.split('.')\n",
        "        if len(parts) > 2:\n",
        "            try:\n",
        "                layer_idx = int(parts[2])\n",
        "                max_layer_idx = max(max_layer_idx, layer_idx)\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "print(f\"Total number of transformer layers: {max_layer_idx + 1}\")\n",
        "\n",
        "# Then modify the freezing code to match the actual structure\n",
        "# This assumes the layer indexing is inside the parameter names\n",
        "for name, param in model.protGPT2_model.named_parameters():\n",
        "    param.requires_grad = False  # Freeze everything else\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###___________________________________________________________________________________\n",
        "\n",
        "# # Directly check if 'lm_head' exists as an attribute\n",
        "# if hasattr(model.protGPT2_model, 'lm_head'):\n",
        "#     print(\"lm_head exists as an attribute!\")\n",
        "#     print(model.protGPT2_model.lm_head)\n",
        "\n",
        "#     # Check if it has parameters\n",
        "#     if hasattr(model.protGPT2_model.lm_head, 'parameters'):\n",
        "#         print(\"lm_head has parameters!\")\n",
        "\n",
        "#         # Check requires_grad for lm_head manually\n",
        "#         for param in model.protGPT2_model.lm_head.parameters():\n",
        "#             print(f\"lm_head requires_grad: {param.requires_grad}\")\n",
        "#     else:\n",
        "#         print(\"WARNING: lm_head has no registered parameters!\")\n",
        "# else:\n",
        "#     print(\"WARNING: lm_head does not exist as an attribute!\")\n",
        "\n",
        "# Unfreeze lm_head manually\n",
        "if hasattr(model.protGPT2_model, 'lm_head'):\n",
        "    for param in model.protGPT2_model.lm_head.parameters():\n",
        "        param.requires_grad = True\n",
        "    print(\"lm_head manually unfrozen!\")\n",
        "\n",
        "# Verify if lm_head is now trainable\n",
        "for param in model.protGPT2_model.lm_head.parameters():\n",
        "    print(f\"lm_head requires_grad: {param.requires_grad}\")\n",
        "\n",
        "\n",
        "print_model_structure(model)\n",
        "\n",
        "# Verify which parameters are trainable\n",
        "total_params = 0\n",
        "trainable_params = 0\n",
        "for name, param in model.named_parameters():\n",
        "    total_params += param.numel()\n",
        "    if param.requires_grad:\n",
        "        trainable_params += param.numel()\n",
        "\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.2%})\")\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "# Training loop with curriculum learning\n",
        "# Start with 50% of sequences in left-to-right order and gradually increase to 100% random\n",
        "curriculum_steps = int(0.5 * num_epochs * len(train_loader))  # Curriculum over first half of training\n",
        "# print(\"Starting training with sigma-gpt capabilities...\")\n",
        "# train_with_improved_aar_objective(\n",
        "#     model,\n",
        "#     train_loader,\n",
        "#     val_loader,\n",
        "#     num_epochs,\n",
        "#     device,\n",
        "#     curriculum_steps=curriculum_steps\n",
        "# )\n",
        "\n",
        "###___________________________________________________________________________________\n",
        "\n",
        "# # Generate and evaluate\n",
        "# print(\"Generating proteins for test set...\")\n",
        "# test_results = generate_and_evaluate(model, test_loader, device)\n",
        "\n",
        "# # Save results\n",
        "# print(\"Saving results...\")\n",
        "# results_path = '/content/drive/MyDrive/classes+projects/plastic_enzyme_project/2024/codes/test_results.json'\n",
        "# with open(results_path, 'w') as f:\n",
        "#     json.dump(test_results, f, indent=2)\n",
        "\n",
        "# print(f\"Results saved to {results_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmqg3zrXtsP-"
      },
      "source": [
        "#### unfreeze 34+35 and do cross attn with 34+35"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dupiZgjctzja"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load and preprocess data\n",
        "train_data = preprocess_snp_data('/content/train_data.csv')\n",
        "val_data = preprocess_snp_data('/content/val_data.csv')\n",
        "\n",
        "# train_data = train_data.sample(frac=0.01, random_state=42)\n",
        "# val_data = val_data.sample(frac=0.01, random_state=42)\n",
        "\n",
        "train_data = filter_datasets(train_data)\n",
        "val_data = filter_datasets(val_data)\n",
        "\n",
        "# Calculate max sequence length\n",
        "max_length = max(\n",
        "    train_data['protein_length'].max(),\n",
        "    val_data['protein_length'].max()\n",
        ")\n",
        "max_length = min(max_length, 1024)  # Cap at 1024 or your desired maximum\n",
        "print(f\"Max sequence length: {max_length}\")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ProteinGenerationDataset(train_data, max_length)\n",
        "val_dataset = ProteinGenerationDataset(val_data, max_length)\n",
        "\n",
        "# Create dataloaders with custom collate function\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=1,  # Adjust based on your GPU memory\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "# # Initialize model with sigma-gpt capabilities\n",
        "# model = SigmaProtFlamingo(\n",
        "#     model_path='nferruz/ProtGPT2',\n",
        "#     max_len=max_length,\n",
        "#     cross_attn_every=2,\n",
        "#     dim_head=64,\n",
        "#     heads=8,\n",
        "#     perceiver_depth=2,\n",
        "#     perceiver_num_latents=64\n",
        "# ).to(device)\n",
        "\n",
        "\n",
        "# Initialize model with sigma-gpt capabilities but without any cross-attention initially\n",
        "model = SigmaProtFlamingo(\n",
        "    model_path='nferruz/ProtGPT2',\n",
        "    max_len=max_length,\n",
        "    cross_attn_every=999,\n",
        "    dim_head=64,\n",
        "    heads=8,\n",
        "    perceiver_depth=2,\n",
        "    perceiver_num_latents=64\n",
        ")  # Don't move to device yet\n",
        "\n",
        "# The model structure shows that model.layers contains the transformer blocks\n",
        "# model.protGPT2_model.transformer.h contains the GPT2Blocks\n",
        "\n",
        "# Let's recreate the layers list with cross-attention only after the last two blocks\n",
        "new_layers = []\n",
        "\n",
        "# First, get all the original transformer blocks\n",
        "transformer_blocks = model.protGPT2_model.transformer.h\n",
        "\n",
        "# Total number of transformer blocks\n",
        "num_blocks = len(transformer_blocks)\n",
        "print(f\"Total transformer blocks: {num_blocks}\")\n",
        "\n",
        "# Add each transformer block, with cross-attention after the last two blocks\n",
        "for i, block in enumerate(transformer_blocks):\n",
        "    # Add the transformer block\n",
        "    new_layers.append(block)\n",
        "\n",
        "    # Add cross-attention after the last two blocks\n",
        "    if i == num_blocks - 2 or i == num_blocks - 1:\n",
        "        print(f\"Adding cross-attention after block {i}\")\n",
        "        new_layers.append(GatedCrossAttentionBlock(\n",
        "            dim=model.protGPT2_model.config.n_embd,\n",
        "            dim_head=64,\n",
        "            heads=8\n",
        "        ))\n",
        "\n",
        "# Replace the model's layers with our new sequence\n",
        "model.layers = nn.ModuleList(new_layers)\n",
        "\n",
        "# Now move the entire model to the device after modifying it\n",
        "model = model.to(device)\n",
        "\n",
        "# Count how many cross-attention blocks were added\n",
        "cross_attn_count = sum(1 for layer in model.layers if isinstance(layer, GatedCrossAttentionBlock))\n",
        "print(f\"Added {cross_attn_count} cross-attention blocks\")\n",
        "\n",
        "# Print more detailed layer structure first\n",
        "for name, _ in model.protGPT2_model.named_parameters():\n",
        "    if 'transformer.h' in name:\n",
        "        print(name)\n",
        "        break  # Just print one example to see the structure\n",
        "\n",
        "\n",
        "# Check the highest layer index in the model\n",
        "max_layer_idx = -1\n",
        "for name, _ in model.protGPT2_model.named_parameters():\n",
        "    if 'transformer.h.' in name:\n",
        "        # Extract the layer index which comes after 'transformer.h.'\n",
        "        parts = name.split('.')\n",
        "        if len(parts) > 2:\n",
        "            try:\n",
        "                layer_idx = int(parts[2])\n",
        "                max_layer_idx = max(max_layer_idx, layer_idx)\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "print(f\"Total number of transformer layers: {max_layer_idx + 1}\")\n",
        "\n",
        "# Then modify the freezing code to match the actual structure\n",
        "# This assumes the layer indexing is inside the parameter names\n",
        "for name, param in model.protGPT2_model.named_parameters():\n",
        "    if 'lm_head' in name or 'transformer.h.34' in name or 'transformer.h.35' in name:\n",
        "        param.requires_grad = True  # Unfreeze\n",
        "    else:\n",
        "        param.requires_grad = False  # Freeze everything else\n",
        "\n",
        "\n",
        "\n",
        "print_model_structure(model)\n",
        "\n",
        "\n",
        "###___________________________________________________________________________________\n",
        "\n",
        "# # Directly check if 'lm_head' exists as an attribute\n",
        "# if hasattr(model.protGPT2_model, 'lm_head'):\n",
        "#     print(\"lm_head exists as an attribute!\")\n",
        "#     print(model.protGPT2_model.lm_head)\n",
        "\n",
        "#     # Check if it has parameters\n",
        "#     if hasattr(model.protGPT2_model.lm_head, 'parameters'):\n",
        "#         print(\"lm_head has parameters!\")\n",
        "\n",
        "#         # Check requires_grad for lm_head manually\n",
        "#         for param in model.protGPT2_model.lm_head.parameters():\n",
        "#             print(f\"lm_head requires_grad: {param.requires_grad}\")\n",
        "#     else:\n",
        "#         print(\"WARNING: lm_head has no registered parameters!\")\n",
        "# else:\n",
        "#     print(\"WARNING: lm_head does not exist as an attribute!\")\n",
        "\n",
        "# # Unfreeze lm_head manually\n",
        "# if hasattr(model.protGPT2_model, 'lm_head'):\n",
        "#     for param in model.protGPT2_model.lm_head.parameters():\n",
        "#         param.requires_grad = True\n",
        "#     print(\"lm_head manually unfrozen!\")\n",
        "\n",
        "# # Verify if lm_head is now trainable\n",
        "# for param in model.protGPT2_model.lm_head.parameters():\n",
        "#     print(f\"lm_head requires_grad: {param.requires_grad}\")\n",
        "\n",
        "# Verify which parameters are trainable\n",
        "total_params = 0\n",
        "trainable_params = 0\n",
        "for name, param in model.named_parameters():\n",
        "    total_params += param.numel()\n",
        "    if param.requires_grad:\n",
        "        trainable_params += param.numel()\n",
        "\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.2%})\")\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "# Training loop with curriculum learning\n",
        "# Start with 50% of sequences in left-to-right order and gradually increase to 100% random\n",
        "curriculum_steps = int(0.5 * num_epochs * len(train_loader))  # Curriculum over first half of training\n",
        "# print(\"Starting training with sigma-gpt capabilities...\")\n",
        "# train_with_improved_aar_objective(\n",
        "#     model,\n",
        "#     train_loader,\n",
        "#     val_loader,\n",
        "#     num_epochs,\n",
        "#     device,\n",
        "#     curriculum_steps=curriculum_steps\n",
        "# )\n",
        "\n",
        "###___________________________________________________________________________________\n",
        "\n",
        "# # Generate and evaluate\n",
        "# print(\"Generating proteins for test set...\")\n",
        "# test_results = generate_and_evaluate(model, test_loader, device)\n",
        "\n",
        "# # Save results\n",
        "# print(\"Saving results...\")\n",
        "# results_path = '/content/drive/MyDrive/classes+projects/plastic_enzyme_project/2024/codes/test_results.json'\n",
        "# with open(results_path, 'w') as f:\n",
        "#     json.dump(test_results, f, indent=2)\n",
        "\n",
        "# print(f\"Results saved to {results_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPoO9a6Xt3FL"
      },
      "source": [
        "#### unfreeze 34+35+lm head and add cross attn to those"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E7jy-MKlt6L5"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load and preprocess data\n",
        "train_data = preprocess_snp_data('/content/train_data.csv')\n",
        "val_data = preprocess_snp_data('/content/val_data.csv')\n",
        "\n",
        "# train_data = train_data.sample(frac=0.01, random_state=42)\n",
        "# val_data = val_data.sample(frac=0.01, random_state=42)\n",
        "\n",
        "train_data = filter_datasets(train_data)\n",
        "val_data = filter_datasets(val_data)\n",
        "\n",
        "# Calculate max sequence length\n",
        "max_length = max(\n",
        "    train_data['protein_length'].max(),\n",
        "    val_data['protein_length'].max()\n",
        ")\n",
        "max_length = min(max_length, 1024)  # Cap at 1024 or your desired maximum\n",
        "print(f\"Max sequence length: {max_length}\")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ProteinGenerationDataset(train_data, max_length)\n",
        "val_dataset = ProteinGenerationDataset(val_data, max_length)\n",
        "\n",
        "# Create dataloaders with custom collate function\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=1,  # Adjust based on your GPU memory\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "# # Initialize model with sigma-gpt capabilities\n",
        "# model = SigmaProtFlamingo(\n",
        "#     model_path='nferruz/ProtGPT2',\n",
        "#     max_len=max_length,\n",
        "#     cross_attn_every=2,\n",
        "#     dim_head=64,\n",
        "#     heads=8,\n",
        "#     perceiver_depth=2,\n",
        "#     perceiver_num_latents=64\n",
        "# ).to(device)\n",
        "\n",
        "\n",
        "# Initialize model with sigma-gpt capabilities but without any cross-attention initially\n",
        "model = SigmaProtFlamingo(\n",
        "    model_path='nferruz/ProtGPT2',\n",
        "    max_len=max_length,\n",
        "    cross_attn_every=999,\n",
        "    dim_head=64,\n",
        "    heads=8,\n",
        "    perceiver_depth=2,\n",
        "    perceiver_num_latents=64\n",
        ")  # Don't move to device yet\n",
        "\n",
        "# The model structure shows that model.layers contains the transformer blocks\n",
        "# model.protGPT2_model.transformer.h contains the GPT2Blocks\n",
        "\n",
        "# Let's recreate the layers list with cross-attention only after the last two blocks\n",
        "new_layers = []\n",
        "\n",
        "# First, get all the original transformer blocks\n",
        "transformer_blocks = model.protGPT2_model.transformer.h\n",
        "\n",
        "# Total number of transformer blocks\n",
        "num_blocks = len(transformer_blocks)\n",
        "print(f\"Total transformer blocks: {num_blocks}\")\n",
        "\n",
        "# Add each transformer block, with cross-attention after the last two blocks\n",
        "for i, block in enumerate(transformer_blocks):\n",
        "    # Add the transformer block\n",
        "    new_layers.append(block)\n",
        "\n",
        "    # Add cross-attention after the last two blocks\n",
        "    if i == num_blocks - 2 or i == num_blocks - 1:\n",
        "        print(f\"Adding cross-attention after block {i}\")\n",
        "        new_layers.append(GatedCrossAttentionBlock(\n",
        "            dim=model.protGPT2_model.config.n_embd,\n",
        "            dim_head=64,\n",
        "            heads=8\n",
        "        ))\n",
        "\n",
        "# Replace the model's layers with our new sequence\n",
        "model.layers = nn.ModuleList(new_layers)\n",
        "\n",
        "# Now move the entire model to the device after modifying it\n",
        "model = model.to(device)\n",
        "\n",
        "# Count how many cross-attention blocks were added\n",
        "cross_attn_count = sum(1 for layer in model.layers if isinstance(layer, GatedCrossAttentionBlock))\n",
        "print(f\"Added {cross_attn_count} cross-attention blocks\")\n",
        "\n",
        "# Print more detailed layer structure first\n",
        "for name, _ in model.protGPT2_model.named_parameters():\n",
        "    if 'transformer.h' in name:\n",
        "        print(name)\n",
        "        break  # Just print one example to see the structure\n",
        "\n",
        "\n",
        "# Check the highest layer index in the model\n",
        "max_layer_idx = -1\n",
        "for name, _ in model.protGPT2_model.named_parameters():\n",
        "    if 'transformer.h.' in name:\n",
        "        # Extract the layer index which comes after 'transformer.h.'\n",
        "        parts = name.split('.')\n",
        "        if len(parts) > 2:\n",
        "            try:\n",
        "                layer_idx = int(parts[2])\n",
        "                max_layer_idx = max(max_layer_idx, layer_idx)\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "print(f\"Total number of transformer layers: {max_layer_idx + 1}\")\n",
        "\n",
        "# Then modify the freezing code to match the actual structure\n",
        "# This assumes the layer indexing is inside the parameter names\n",
        "for name, param in model.protGPT2_model.named_parameters():\n",
        "    if 'lm_head' in name or 'transformer.h.34' in name or 'transformer.h.35' in name:\n",
        "        param.requires_grad = True  # Unfreeze\n",
        "    else:\n",
        "        param.requires_grad = False  # Freeze everything else\n",
        "\n",
        "##___________________________________________________________________________________\n",
        "\n",
        "# Directly check if 'lm_head' exists as an attribute\n",
        "if hasattr(model.protGPT2_model, 'lm_head'):\n",
        "    print(\"lm_head exists as an attribute!\")\n",
        "    print(model.protGPT2_model.lm_head)\n",
        "\n",
        "    # Check if it has parameters\n",
        "    if hasattr(model.protGPT2_model.lm_head, 'parameters'):\n",
        "        print(\"lm_head has parameters!\")\n",
        "\n",
        "        # Check requires_grad for lm_head manually\n",
        "        for param in model.protGPT2_model.lm_head.parameters():\n",
        "            print(f\"lm_head requires_grad: {param.requires_grad}\")\n",
        "    else:\n",
        "        print(\"WARNING: lm_head has no registered parameters!\")\n",
        "else:\n",
        "    print(\"WARNING: lm_head does not exist as an attribute!\")\n",
        "\n",
        "# Unfreeze lm_head manually\n",
        "if hasattr(model.protGPT2_model, 'lm_head'):\n",
        "    for param in model.protGPT2_model.lm_head.parameters():\n",
        "        param.requires_grad = True\n",
        "    print(\"lm_head manually unfrozen!\")\n",
        "\n",
        "# Verify if lm_head is now trainable\n",
        "for param in model.protGPT2_model.lm_head.parameters():\n",
        "    print(f\"lm_head requires_grad: {param.requires_grad}\")\n",
        "\n",
        "# Verify which parameters are trainable\n",
        "total_params = 0\n",
        "trainable_params = 0\n",
        "for name, param in model.named_parameters():\n",
        "    total_params += param.numel()\n",
        "    if param.requires_grad:\n",
        "        trainable_params += param.numel()\n",
        "\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.2%})\")\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "\n",
        "print_model_structure(model)\n",
        "\n",
        "\n",
        "# Training loop with curriculum learning\n",
        "# Start with 50% of sequences in left-to-right order and gradually increase to 100% random\n",
        "curriculum_steps = int(0.5 * num_epochs * len(train_loader))  # Curriculum over first half of training\n",
        "print(\"Starting training with sigma-gpt capabilities...\")\n",
        "train_with_improved_aar_objective(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs,\n",
        "    device,\n",
        "    curriculum_steps=curriculum_steps\n",
        ")\n",
        "\n",
        "###___________________________________________________________________________________\n",
        "\n",
        "# # Generate and evaluate\n",
        "# print(\"Generating proteins for test set...\")\n",
        "# test_results = generate_and_evaluate(model, test_loader, device)\n",
        "\n",
        "# # Save results\n",
        "# print(\"Saving results...\")\n",
        "# results_path = '/content/drive/MyDrive/classes+projects/plastic_enzyme_project/2024/codes/test_results.json'\n",
        "# with open(results_path, 'w') as f:\n",
        "#     json.dump(test_results, f, indent=2)\n",
        "\n",
        "# print(f\"Results saved to {results_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLZXFhNq9xvv"
      },
      "source": [
        "### generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXlyfekIsTlB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the trained model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Path to model checkpoint\n",
        "checkpoint_path = \"/content/drive/MyDrive/classes+projects/plastic_enzyme_project/2024/codes/sigma_checkpoint.pth\"\n",
        "\n",
        "# Load\n",
        "model = SigmaProtFlamingo(\n",
        "    model_path='nferruz/ProtGPT2',\n",
        "    max_len=914,  # Ensure this matches the training max_len\n",
        "    cross_attn_every=3,\n",
        "    dim_head=64,\n",
        "    heads=8,\n",
        "    perceiver_depth=2,\n",
        "    perceiver_num_latents=64\n",
        ").to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS0GAkWg-aV3"
      },
      "outputs": [],
      "source": [
        "ProteinGenerationDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHBmfbMT-FPX"
      },
      "outputs": [],
      "source": [
        "# Load trained weights\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# Load test data\n",
        "test_data = preprocess_snp_data('/content/augmented_test.csv')\n",
        "test_data = filter_datasets(test_data)\n",
        "\n",
        "# Create test dataset and dataloader\n",
        "test_dataset = ProteinGenerationDataset(test_data,max_length = 914 )\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sgmyq7fJ8kAb"
      },
      "outputs": [],
      "source": [
        "def generate_autoregressively(model, smiles_string, max_length=914, temperature=1.0, random_order=False):\n",
        "    \"\"\"Generate protein autoregressively, with option to use random order\"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Get SMILES embeddings\n",
        "    smiles_embeddings = model.polybert_encoder([smiles_string])\n",
        "    processed_smiles = model.smiles_perceiver(smiles_embeddings)\n",
        "\n",
        "    # Initialize with start token\n",
        "    input_ids = torch.tensor([[model.protGPT2_tokenizer.bos_token_id]], device=device)\n",
        "\n",
        "    # If using random order, generate a random permutation\n",
        "    if random_order:\n",
        "        order = torch.randperm(max_length, device=device).unsqueeze(0)\n",
        "    else:\n",
        "        order = torch.arange(max_length, device=device).unsqueeze(0)\n",
        "\n",
        "    # Track the current positions in the order\n",
        "    current_pos = 0\n",
        "\n",
        "    # Generated sequence in order's positions\n",
        "    generated_sequence = torch.full((1, max_length), model.protGPT2_tokenizer.pad_token_id, device=device)\n",
        "    generated_sequence[0, 0] = model.protGPT2_tokenizer.bos_token_id  # Start token\n",
        "\n",
        "    while current_pos < max_length - 1:\n",
        "        # Get the next position in the order\n",
        "        next_pos = current_pos + 1\n",
        "\n",
        "        # Forward pass to get next token prediction\n",
        "        with torch.no_grad():\n",
        "            # Use only the sequence up to the current position\n",
        "            current_order = order[:, :next_pos]\n",
        "            current_sequence = generated_sequence[:, current_order[0]]\n",
        "\n",
        "            # Get logits for the next token\n",
        "            logits, _ = model(\n",
        "                smiles_string,\n",
        "                order=current_order,\n",
        "                optimize=True\n",
        "            )\n",
        "\n",
        "            # Apply temperature and sample\n",
        "            logits = logits[0, -1, :] / temperature\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "            # Add the token to the generated sequence at the next position in the order\n",
        "            generated_sequence[0, order[0, next_pos]] = next_token\n",
        "\n",
        "            # Check for EOS token\n",
        "            if next_token == model.protGPT2_tokenizer.eos_token_id:\n",
        "                break\n",
        "\n",
        "            current_pos = next_pos\n",
        "\n",
        "    # Decode the generated sequence\n",
        "    generated_ids = generated_sequence[0].tolist()\n",
        "    print('generated_ids',generated_ids)\n",
        "    # Remove padding tokens\n",
        "    generated_ids = [id for id in generated_ids if id != model.protGPT2_tokenizer.pad_token_id]\n",
        "    seq = model.protGPT2_tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
        "    print('seq',seq)\n",
        "    print(\"autoregressive gen done...\")\n",
        "    return seq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Koy4bjRHu5hx"
      },
      "outputs": [],
      "source": [
        "def generate_with_rejection_sampling(model, smiles_string, max_length=914, num_orders=5, temperature=1.0):\n",
        "    \"\"\"Generate protein using token-based rejection sampling with proper MH acceptance ratio\"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Get SMILES embeddings\n",
        "    smiles_embeddings = model.polybert_encoder([smiles_string])\n",
        "    processed_smiles = model.smiles_perceiver(smiles_embeddings)\n",
        "\n",
        "    # Initialize with start token\n",
        "    prompt = torch.tensor([[model.protGPT2_tokenizer.bos_token_id]], device=device)\n",
        "\n",
        "    # Initialize full sequence with padding\n",
        "    full_seq = torch.full((1, max_length), model.protGPT2_tokenizer.pad_token_id, device=device)\n",
        "    full_seq[:, 0] = model.protGPT2_tokenizer.bos_token_id  # Start token\n",
        "\n",
        "    # Track positions that have been filled\n",
        "    filled_positions = {0}  # Start with position 0 filled\n",
        "\n",
        "    while len(filled_positions) < max_length:\n",
        "        remaining_positions = [i for i in range(max_length) if i not in filled_positions]\n",
        "        if not remaining_positions:\n",
        "            break\n",
        "\n",
        "        # Step 1: Sample tokens at all remaining positions from marginal distribution\n",
        "        # This is our proposal distribution p(x̃)\n",
        "        candidate_tokens = {}\n",
        "        proposal_probs = {}  # Store the probability of each proposal\n",
        "\n",
        "        for pos in remaining_positions:\n",
        "            # Create current filled sequence context\n",
        "            current_context = torch.ones((1, max_length), device=device) * model.protGPT2_tokenizer.pad_token_id\n",
        "            for filled_pos in filled_positions:\n",
        "                current_context[0, filled_pos] = full_seq[0, filled_pos]\n",
        "\n",
        "            # Get logits for this position given current context\n",
        "            with torch.no_grad():\n",
        "                # Order that puts this position last\n",
        "                context_order = torch.tensor([list(filled_positions) + [pos]], device=device)\n",
        "\n",
        "                logits = get_logits_for_position(model, current_context, context_order, smiles_string, pos)\n",
        "\n",
        "                # Sample a token and record its probability\n",
        "                logits = logits / temperature\n",
        "                probs = F.softmax(logits, dim=-1)\n",
        "                token_dist = torch.distributions.Categorical(probs)\n",
        "                token = token_dist.sample().item()\n",
        "\n",
        "                candidate_tokens[pos] = token\n",
        "                proposal_probs[pos] = probs[0, token].item()\n",
        "\n",
        "        # Step 2: Evaluate acceptance under different orders\n",
        "        best_order_acceptances = []\n",
        "\n",
        "        for _ in range(num_orders):\n",
        "            # Create a random permutation of remaining positions\n",
        "            eval_order = random.sample(remaining_positions, len(remaining_positions))\n",
        "\n",
        "            accepted_tokens = []\n",
        "            accepted_positions = []\n",
        "            acceptance_ratios = []\n",
        "\n",
        "            # Try to accept tokens in this order\n",
        "            for pos in eval_order:\n",
        "                # Create sequence with previously accepted tokens\n",
        "                temp_seq = full_seq.clone()\n",
        "                for acc_pos in accepted_positions:\n",
        "                    temp_seq[0, acc_pos] = candidate_tokens[acc_pos]\n",
        "\n",
        "                # Get conditional probability q(x̃|X,x̃σ<i)\n",
        "                filled_plus_accepted = list(filled_positions) + accepted_positions\n",
        "                context_order = torch.tensor([filled_plus_accepted + [pos]], device=device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    cond_logits = get_logits_for_position(\n",
        "                        model, temp_seq, context_order, processed_smiles, pos\n",
        "                    )\n",
        "\n",
        "                    cond_probs = F.softmax(cond_logits / temperature, dim=-1)\n",
        "                    cond_prob = cond_probs[0, candidate_tokens[pos]].item()\n",
        "\n",
        "                # Compute acceptance ratio r = q(x̃i|X,x̃σ<i) / p(x̃i|X)\n",
        "                # Where p(x̃i|X) is the proposal probability\n",
        "                acceptance_ratio = min(1.0, cond_prob / proposal_probs[pos])\n",
        "\n",
        "                # Decide whether to accept\n",
        "                if random.random() < acceptance_ratio:\n",
        "                    accepted_tokens.append(candidate_tokens[pos])\n",
        "                    accepted_positions.append(pos)\n",
        "                    acceptance_ratios.append(acceptance_ratio)\n",
        "                else:\n",
        "                    # Stop at first rejection\n",
        "                    break\n",
        "\n",
        "            best_order_acceptances.append((accepted_positions, accepted_tokens, acceptance_ratios))\n",
        "\n",
        "        # Step 3: Dynamic token acceptance\n",
        "        best_order_idx = -1\n",
        "        max_accepted = -1\n",
        "        min_sequence_idx = -1\n",
        "\n",
        "        for idx, (accepted_positions, _, acceptance_ratios) in enumerate(best_order_acceptances):\n",
        "            if len(accepted_positions) > max_accepted:\n",
        "                max_accepted = len(accepted_positions)\n",
        "                best_order_idx = idx\n",
        "                # Find the minimum position in the sequence where we see a rejection\n",
        "                if len(accepted_positions) < len(remaining_positions):\n",
        "                    min_sequence_idx = len(accepted_positions)\n",
        "                else:\n",
        "                    min_sequence_idx = len(remaining_positions)\n",
        "\n",
        "        # No need to calculate min across orders if all orders accept all tokens\n",
        "        if min_sequence_idx == -1:\n",
        "            min_sequence_idx = len(remaining_positions)\n",
        "\n",
        "        # Get the best order\n",
        "        best_order = best_order_acceptances[best_order_idx]\n",
        "        accepted_positions, accepted_tokens, _ = best_order\n",
        "\n",
        "        # Limit acceptance to positions before the minimum rejection\n",
        "        accepted_positions = accepted_positions[:min_sequence_idx]\n",
        "        accepted_tokens = accepted_tokens[:min_sequence_idx]\n",
        "\n",
        "        # Update the sequence with accepted tokens\n",
        "        for pos, token in zip(accepted_positions, accepted_tokens):\n",
        "            full_seq[0, pos] = token\n",
        "            filled_positions.add(pos)\n",
        "\n",
        "            # Check for EOS token\n",
        "            if token == model.protGPT2_tokenizer.eos_token_id:\n",
        "                break\n",
        "\n",
        "    # Decode the generated sequence\n",
        "    result = model.protGPT2_tokenizer.decode(\n",
        "        [t for t in full_seq[0].tolist() if t != model.protGPT2_tokenizer.pad_token_id],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "    return result\n",
        "\n",
        "def get_logits_for_position(model, sequence, order, smiles_string, target_position):\n",
        "    \"\"\"Helper function to get logits for a specific position\"\"\"\n",
        "    # Run model forward pass\n",
        "    logits, _ = model(\n",
        "        smiles_string,  # Pass the SMILES string\n",
        "        order=order,\n",
        "        optimize=True\n",
        "    )\n",
        "\n",
        "    # Return logits for target position (last position in the order)\n",
        "    return logits[:, -1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhpdI0vMXdUp"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2azHLfyMXUyR"
      },
      "outputs": [],
      "source": [
        "def evaluate_on_unique_smiles(model, test_loader, device, output_file=\"generated_proteins_comparison.json\"):\n",
        "    \"\"\"Generate proteins using both methods on unique SMILES from test set\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Collect unique SMILES from the test loader\n",
        "    unique_smiles = set()\n",
        "    for batch in test_loader:\n",
        "        unique_smiles.update(batch['smiles'])\n",
        "\n",
        "    unique_smiles = list(unique_smiles)  # Convert to list\n",
        "    print(f\"Found {len(unique_smiles)} unique SMILES in test set\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Generate proteins using both methods and time each generation\n",
        "    for i, smiles in enumerate(tqdm(unique_smiles, desc=\"Generating proteins\")):\n",
        "        # Track time for autoregressive generation\n",
        "        start_time = time.time()\n",
        "        print('autoregressive generations...')\n",
        "        print(f\"Generating protein for SMILES: {smiles}\")\n",
        "        ar_protein = generate_autoregressively(model, smiles, max_length=914, temperature=1.0, random_order=False)\n",
        "        print(ar_protein)\n",
        "        ar_time = time.time() - start_time\n",
        "\n",
        "        # Track time for rejection sampling\n",
        "        start_time = time.time()\n",
        "        print('rejection sampling generations...')\n",
        "        print(f\"Generating protein for SMILES: {smiles}\")\n",
        "        rs_protein = generate_with_rejection_sampling(model, smiles, max_length=914, num_orders=5, temperature=1.0)\n",
        "        print(rs_protein)\n",
        "        rs_time = time.time() - start_time\n",
        "\n",
        "        results.append({\n",
        "            'SMILES': smiles,\n",
        "            'Autoregressive': {\n",
        "                'protein': ar_protein,\n",
        "                'time_seconds': ar_time\n",
        "            },\n",
        "            'Rejection_Sampling': {\n",
        "                'protein': rs_protein,\n",
        "                'time_seconds': rs_time\n",
        "            }\n",
        "        })\n",
        "\n",
        "        # Print progress occasionally\n",
        "        if (i + 1) % 5 == 0:\n",
        "            print(f\"\\nCompleted {i+1}/{len(unique_smiles)}\")\n",
        "            print(f\"Example - SMILES: {smiles}\")\n",
        "            print(f\"Autoregressive: {ar_protein[:50]}... ({ar_time:.2f}s)\")\n",
        "            print(f\"Rejection Sampling: {rs_protein[:50]}... ({rs_time:.2f}s)\")\n",
        "\n",
        "    # Save results to JSON\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    # Calculate and print average times\n",
        "    ar_times = [r['Autoregressive']['time_seconds'] for r in results]\n",
        "    rs_times = [r['Rejection_Sampling']['time_seconds'] for r in results]\n",
        "\n",
        "    print(f\"\\nGeneration complete!\")\n",
        "    print(f\"Average autoregressive generation time: {np.mean(ar_times):.2f}s\")\n",
        "    print(f\"Average rejection sampling generation time: {np.mean(rs_times):.2f}s\")\n",
        "    print(f\"Speed improvement: {np.mean(ar_times)/np.mean(rs_times):.2f}x\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xKIwu3LXe7K"
      },
      "outputs": [],
      "source": [
        "results = evaluate_on_unique_smiles(model, test_loader, device, output_file=\"sigma_gpt_comparison_results.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLASSIFIER"
      ],
      "metadata": {
        "id": "rbTqEt7k-dEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer, EsmModel, EsmTokenizer\n",
        "import pandas as pd\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "class HyperbolicProjector(nn.Module):\n",
        "    def __init__(self, input_dim, hyper_dim=512, curvature=3.0):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(input_dim, hyper_dim)\n",
        "        self.curvature = curvature\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = torch.tanh(x) * (1 - 1e-5)\n",
        "        return x / (1 + self.curvature * (x**2).sum(dim=-1, keepdim=True)).sqrt()\n",
        "\n",
        "class HyperGraphBuilder(nn.Module):\n",
        "    def __init__(self, dim, k=25, heads=4):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.dim = dim\n",
        "        self.attn = nn.MultiheadAttention(dim, heads)\n",
        "        self.hyperedge_net = nn.Sequential(\n",
        "            nn.Linear(dim * 3, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, smiles_emb, prot_emb):\n",
        "        batch_size = smiles_emb.size(0)\n",
        "        smiles_prot = torch.cat([smiles_emb, prot_emb], dim=0)\n",
        "        attn_out, _ = self.attn(smiles_prot, smiles_prot, smiles_prot)\n",
        "        smiles_refined = attn_out[:batch_size]\n",
        "        prot_refined = attn_out[batch_size:]\n",
        "\n",
        "        smiles_exp = smiles_refined.unsqueeze(1)\n",
        "        prot_exp = prot_refined.unsqueeze(0)\n",
        "        affinities = torch.sum(smiles_exp * prot_exp, dim=-1)\n",
        "        k = min(self.k, batch_size)  # Dynamic k\n",
        "        _, topk_indices = affinities.topk(self.k, dim=1)\n",
        "\n",
        "        hyperedges = []\n",
        "        for i in range(batch_size):\n",
        "            for j in topk_indices[i]:\n",
        "                for k in topk_indices[i]:\n",
        "                    if j != k:\n",
        "                        score = self.hyperedge_net(torch.cat([smiles_refined[i],\n",
        "                                                              prot_refined[j],\n",
        "                                                              prot_refined[k]], dim=-1))\n",
        "                        if score > 0.5:\n",
        "                            hyperedges.append([i, j.item(), k.item()])\n",
        "\n",
        "        return torch.tensor(hyperedges, device=smiles_emb.device) if hyperedges else topk_indices\n",
        "\n",
        "class HyperSpectral(nn.Module):\n",
        "    def __init__(self, dim, out_dim=256, k=25):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.out_dim = out_dim\n",
        "        self.k = k\n",
        "        self.proj = nn.Linear(dim, out_dim)\n",
        "\n",
        "    def forward(self, x, hyperedge_indices):\n",
        "        batch_size = x.size(0) // 2\n",
        "        num_nodes = x.size(0)\n",
        "\n",
        "        if hyperedge_indices.dim() == 2:\n",
        "            H = torch.zeros(num_nodes, batch_size * self.k, device=x.device)\n",
        "            for i in range(batch_size):\n",
        "                for j, idx in enumerate(hyperedge_indices[i]):\n",
        "                    H[i, i*self.k + j] = 1\n",
        "                    H[batch_size + idx, i*self.k + j] = 1\n",
        "        else:\n",
        "            H = torch.zeros(num_nodes, hyperedge_indices.size(0), device=x.device)\n",
        "            for i, edge in enumerate(hyperedge_indices):\n",
        "                for node in edge:\n",
        "                    H[node, i] = 1\n",
        "\n",
        "        D_v = torch.diag(H.sum(dim=1))\n",
        "        D_e = torch.diag(H.sum(dim=0))\n",
        "        L = D_v - H @ torch.inverse(D_e + 1e-6 * torch.eye(D_e.size(0), device=x.device)) @ H.T\n",
        "\n",
        "        eigvec = x.detach().clone()  # Detach to break graph dependency\n",
        "        for _ in range(5):\n",
        "            eigvec = L @ eigvec\n",
        "            eigvec = eigvec / (eigvec.norm(dim=-1, keepdim=True) + 1e-6)\n",
        "\n",
        "        return self.proj(eigvec)\n",
        "\n",
        "class GeometricRelationalFusion(nn.Module):\n",
        "    def __init__(self, dim=256, heads=8):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(dim, heads)\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, smiles_aligned, prot_aligned):\n",
        "        batch_size = smiles_aligned.size(0)\n",
        "        fused = torch.stack([smiles_aligned, prot_aligned], dim=0)\n",
        "        attn_out, _ = self.attn(fused, fused, fused)\n",
        "        fused_out = self.norm(attn_out)\n",
        "        return fused_out[0], fused_out[1]\n",
        "\n",
        "class HGSAC(nn.Module):\n",
        "    def __init__(self, polybert_dim=256, esm_dim=1280, hyper_dim=512, k=25):\n",
        "        super().__init__()\n",
        "        self.smiles_proj = HyperbolicProjector(polybert_dim, hyper_dim)\n",
        "        self.prot_proj = HyperbolicProjector(esm_dim, hyper_dim)\n",
        "        self.hypergraph = HyperGraphBuilder(hyper_dim, k)\n",
        "        self.spectral = HyperSpectral(hyper_dim, hyper_dim // 2, k)\n",
        "        self.fusion = GeometricRelationalFusion(hyper_dim // 2)\n",
        "\n",
        "    def forward(self, smiles_emb, prot_emb):\n",
        "        smiles_h = self.smiles_proj(smiles_emb)\n",
        "        prot_h = self.prot_proj(prot_emb)\n",
        "        hyperedge_indices = self.hypergraph(smiles_h, prot_h)\n",
        "        smiles_aligned = self.spectral(torch.cat([smiles_h, prot_h], dim=0), hyperedge_indices)\n",
        "        prot_aligned = self.spectral(torch.cat([prot_h, smiles_h], dim=0), hyperedge_indices)\n",
        "        smiles_final, prot_final = self.fusion(smiles_aligned[:smiles_emb.size(0)], prot_aligned[:prot_emb.size(0)])\n",
        "        return smiles_final, prot_final\n",
        "\n",
        "def hyperbolic_distance(x, y, curvature=3.0):\n",
        "    x_sq = (x**2).sum(dim=-1, keepdim=True)\n",
        "    y_sq = (y**2).sum(dim=-1, keepdim=True)\n",
        "    num = (x - y)**2\n",
        "    den = (1 - curvature * x_sq.clamp(max=0.99)) * (1 - curvature * y_sq.clamp(max=0.99))\n",
        "    arg = 1 + 2 * num.sum(dim=-1) / den.squeeze(-1).clamp(min=1e-7)\n",
        "    dist = torch.acosh(torch.clamp(arg, min=1.0 + 1e-7))\n",
        "    return dist\n",
        "\n",
        "class PolyBERTEncoder(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "        self.polybert = AutoModel.from_pretrained('kuelumbus/polyBERT')\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('kuelumbus/polyBERT')\n",
        "        self.output_dim = output_dim\n",
        "        self.projection = nn.Linear(self.polybert.config.hidden_size, output_dim)\n",
        "\n",
        "    def forward(self, smiles_strings):\n",
        "        encoded_input = self.tokenizer(smiles_strings,\n",
        "                                     padding=True,\n",
        "                                     truncation=True,\n",
        "                                     return_tensors='pt').to(next(self.polybert.parameters()).device)\n",
        "        with torch.no_grad():\n",
        "            model_output = self.polybert(**encoded_input)\n",
        "        sequence_embeddings = model_output.last_hidden_state\n",
        "        projected_output = self.projection(sequence_embeddings)\n",
        "        return projected_output"
      ],
      "metadata": {
        "id": "xQWlZGIu_f0y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LJrIZcq_BLxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "train_df = pd.read_csv('train_data.csv')\n",
        "val_df = pd.read_csv('val_data.csv')\n"
      ],
      "metadata": {
        "id": "4wlNqJzE_mRg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "polybert_encoder = PolyBERTEncoder(output_dim=256).eval().to(device)\n",
        "esm_model = EsmModel.from_pretrained('facebook/esm2_t33_650M_UR50D').to(device)\n",
        "esm_tokenizer = EsmTokenizer.from_pretrained('facebook/esm2_t33_650M_UR50D')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7EpSKe-t4dX",
        "outputId": "a9112346-1343-43a8-ec02-4c1e369f1f8b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(df, batch_size=32):\n",
        "    smiles_list = df['smiles'].tolist()\n",
        "    protein_list = df['protein_sequence'].tolist()\n",
        "\n",
        "    polybert_embeds = []\n",
        "    esm_embeds = []\n",
        "\n",
        "    for i in range(0, len(smiles_list), batch_size):\n",
        "        batch_smiles = smiles_list[i:i+batch_size]\n",
        "        batch_proteins = protein_list[i:i+batch_size]\n",
        "\n",
        "        smiles_emb = polybert_encoder(batch_smiles).mean(dim=1)\n",
        "        polybert_embeds.append(smiles_emb)\n",
        "\n",
        "        esm_inputs = esm_tokenizer(batch_proteins, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "        with torch.no_grad():\n",
        "            esm_out = esm_model(**esm_inputs).last_hidden_state.mean(dim=1)\n",
        "        esm_embeds.append(esm_out)\n",
        "\n",
        "    return torch.cat(polybert_embeds), torch.cat(esm_embeds)\n",
        "\n"
      ],
      "metadata": {
        "id": "joYcGW3stbL_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_smiles_emb, train_esm_emb = get_embeddings(train_df)\n",
        "val_smiles_emb, val_esm_emb = get_embeddings(val_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmEltmc_tvNx",
        "outputId": "b5552531-c09c-4dea-eeb7-4fa611cc0bbd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# a. Fully Random Negative Pairs (Perturbation)\n",
        "def perturb_embeddings(embeddings, perturbation_level=1.0):\n",
        "    noise = torch.randn_like(embeddings) * perturbation_level  # Full perturbation\n",
        "    perturbed = embeddings + noise\n",
        "    return perturbed / perturbed.norm(dim=-1, keepdim=True).clamp(min=1e-7)  # Normalize\n",
        "\n",
        "# Keep SMILES the same, perturb only proteins\n",
        "train_smiles_random = train_smiles_emb  # Unchanged\n",
        "train_esm_random = perturb_embeddings(train_esm_emb, perturbation_level=1.0)  # Random proteins\n",
        "val_smiles_random = val_smiles_emb  # Unchanged\n",
        "val_esm_random = perturb_embeddings(val_esm_emb, perturbation_level=1.0)  # Random proteins"
      ],
      "metadata": {
        "id": "LAIJJMx5tIM2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b. Distant Cluster Negative Pairs (Based on SMILES)\n",
        "def get_distant_cluster_pairs(smiles_emb, df, num_samples):\n",
        "    clusters = df['cluster'].values\n",
        "    unique_clusters = np.unique(clusters)\n",
        "\n",
        "    # Compute SMILES cluster centroids\n",
        "    cluster_centroids = {}\n",
        "    for cluster in unique_clusters:\n",
        "        cluster_indices = np.where(clusters == cluster)[0]\n",
        "        cluster_emb = smiles_emb[cluster_indices].mean(dim=0).cpu().detach().numpy()\n",
        "        cluster_centroids[cluster] = cluster_emb\n",
        "\n",
        "    # Compute pairwise cluster distances (cosine similarity)\n",
        "    centroid_matrix = np.stack(list(cluster_centroids.values()))\n",
        "    sim_matrix = cosine_similarity(centroid_matrix)\n",
        "\n",
        "    # For each SMILES, find most distant cluster\n",
        "    distant_indices = []\n",
        "    for i in range(num_samples):\n",
        "        orig_cluster = clusters[i]\n",
        "        cluster_idx = list(unique_clusters).index(orig_cluster)\n",
        "        sim_scores = sim_matrix[cluster_idx]\n",
        "        most_distant_cluster_idx = np.argmin(sim_scores)  # Lowest similarity = most distant\n",
        "        most_distant_cluster = unique_clusters[most_distant_cluster_idx]\n",
        "\n",
        "        # Pick a random protein from the most distant cluster\n",
        "        distant_cluster_indices = np.where(clusters == most_distant_cluster)[0]\n",
        "        distant_idx = np.random.choice(distant_cluster_indices)\n",
        "        distant_indices.append(distant_idx)\n",
        "\n",
        "    return torch.tensor(distant_indices, device=smiles_emb.device)\n",
        "\n"
      ],
      "metadata": {
        "id": "dnQT8iYRtN0e"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_distant_indices = get_distant_cluster_pairs(train_smiles_emb, train_df, len(train_smiles_emb))\n",
        "val_distant_indices = get_distant_cluster_pairs(val_smiles_emb, val_df, len(val_smiles_emb))\n",
        "\n",
        "train_smiles_distant = train_smiles_emb  # SMILES stay the same\n",
        "train_esm_distant = train_esm_emb[train_distant_indices]  # Proteins from distant clusters\n",
        "val_smiles_distant = val_smiles_emb\n",
        "val_esm_distant = val_esm_emb[val_distant_indices]"
      ],
      "metadata": {
        "id": "Grlp6veOtP05"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "device = train_smiles_emb.device\n",
        "\n",
        "print(\"Train Smiles Mean:\", train_smiles_emb.mean(dim=-1).detach().cpu().numpy().mean())\n",
        "print(\"Train ESM Mean:\", train_esm_emb.mean(dim=-1).detach().cpu().numpy().mean())\n",
        "print(\"Train ESM Distant Mean:\", train_esm_distant.mean(dim=-1).detach().cpu().numpy().mean())\n",
        "print(\"Train ESM Random Mean:\", train_esm_random.mean(dim=-1).detach().cpu().numpy().mean())\n",
        "\n",
        "train_smiles_sim = cosine_similarity(train_smiles_emb[:100].detach().cpu().numpy())\n",
        "train_esm_sim = cosine_similarity(train_esm_emb[:100].detach().cpu().numpy())\n",
        "train_esm_distant_sim = cosine_similarity(train_esm_distant[:100].detach().cpu().numpy())\n",
        "\n",
        "print(\"Train Smiles Avg Cos Sim:\", train_smiles_sim.mean())\n",
        "print(\"Train ESM Avg Cos Sim:\", train_esm_sim.mean())\n",
        "print(\"Train ESM Distant Avg Cos Sim:\", train_esm_distant_sim.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abyWS0ui1ia7",
        "outputId": "1155e14d-0f27-4d1f-cc05-843e47d5d1b4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Smiles Mean: 0.024824483\n",
            "Train ESM Mean: -0.0008452543\n",
            "Train ESM Distant Mean: -0.0007593286\n",
            "Train ESM Random Mean: -2.9582228e-05\n",
            "Train Smiles Avg Cos Sim: 0.9999998\n",
            "Train ESM Avg Cos Sim: 0.95623195\n",
            "Train ESM Distant Avg Cos Sim: 0.95475096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = HGSAC(polybert_dim=256, esm_dim=1280, k=10).to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=10000)\n",
        "\n"
      ],
      "metadata": {
        "id": "bO9EOh_YDuqw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize all embeddings\n",
        "train_smiles_emb = train_smiles_emb / train_smiles_emb.norm(dim=-1, keepdim=True).clamp(min=1e-7)\n",
        "train_esm_emb = train_esm_emb / train_esm_emb.norm(dim=-1, keepdim=True).clamp(min=1e-7)\n",
        "val_smiles_emb = val_smiles_emb / val_smiles_emb.norm(dim=-1, keepdim=True).clamp(min=1e-7)\n",
        "val_esm_emb = val_esm_emb / val_esm_emb.norm(dim=-1, keepdim=True).clamp(min=1e-7)\n",
        "\n",
        "# Fully random negatives (SMILES unchanged, proteins perturbed)\n",
        "train_smiles_random = train_smiles_emb  # Already normalized\n",
        "train_esm_random = train_esm_random / train_esm_random.norm(dim=-1, keepdim=True).clamp(min=1e-7)\n",
        "val_smiles_random = val_smiles_emb  # Already normalized\n",
        "val_esm_random = val_esm_random / val_esm_random.norm(dim=-1, keepdim=True).clamp(min=1e-7)\n",
        "\n",
        "# Distant cluster negatives (SMILES unchanged, proteins from distant clusters)\n",
        "train_smiles_distant = train_smiles_emb  # Already normalized\n",
        "train_esm_distant = train_esm_distant / train_esm_distant.norm(dim=-1, keepdim=True).clamp(min=1e-7)\n",
        "val_smiles_distant = val_smiles_emb  # Already normalized\n",
        "val_esm_distant = val_esm_distant / val_esm_distant.norm(dim=-1, keepdim=True).clamp(min=1e-7)"
      ],
      "metadata": {
        "id": "WROP-4unPr1L"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Positive pairs\n",
        "print(\"Train Smiles NaN:\", torch.isnan(train_smiles_emb).any())\n",
        "print(\"Train ESM NaN:\", torch.isnan(train_esm_emb).any())\n",
        "print(\"Train Smiles Inf:\", torch.isinf(train_smiles_emb).any())\n",
        "print(\"Train ESM Inf:\", torch.isinf(train_esm_emb).any())\n",
        "\n",
        "print(\"Val Smiles NaN:\", torch.isnan(val_smiles_emb).any())\n",
        "print(\"Val ESM NaN:\", torch.isnan(val_esm_emb).any())\n",
        "print(\"Val Smiles Inf:\", torch.isinf(val_smiles_emb).any())\n",
        "print(\"Val ESM Inf:\", torch.isinf(val_esm_emb).any())\n",
        "\n",
        "# Fully random negatives\n",
        "print(\"Train Smiles Random NaN:\", torch.isnan(train_smiles_random).any())\n",
        "print(\"Train ESM Random NaN:\", torch.isnan(train_esm_random).any())\n",
        "print(\"Train Smiles Random Inf:\", torch.isinf(train_smiles_random).any())\n",
        "print(\"Train ESM Random Inf:\", torch.isinf(train_esm_random).any())\n",
        "\n",
        "print(\"Val Smiles Random NaN:\", torch.isnan(val_smiles_random).any())\n",
        "print(\"Val ESM Random NaN:\", torch.isnan(val_esm_random).any())\n",
        "print(\"Val Smiles Random Inf:\", torch.isinf(val_smiles_random).any())\n",
        "print(\"Val ESM Random Inf:\", torch.isinf(val_esm_random).any())\n",
        "\n",
        "# Distant cluster negatives\n",
        "print(\"Train Smiles Distant NaN:\", torch.isnan(train_smiles_distant).any())\n",
        "print(\"Train ESM Distant NaN:\", torch.isnan(train_esm_distant).any())\n",
        "print(\"Train Smiles Distant Inf:\", torch.isinf(train_smiles_distant).any())\n",
        "print(\"Train ESM Distant Inf:\", torch.isinf(train_esm_distant).any())\n",
        "\n",
        "print(\"Val Smiles Distant NaN:\", torch.isnan(val_smiles_distant).any())\n",
        "print(\"Val ESM Distant NaN:\", torch.isnan(val_esm_distant).any())\n",
        "print(\"Val Smiles Distant Inf:\", torch.isinf(val_smiles_distant).any())\n",
        "print(\"Val ESM Distant Inf:\", torch.isinf(val_esm_distant).any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPomc8HrN22R",
        "outputId": "f9c7a6c0-67ea-4f6b-8297-0d77b6a0262b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Smiles NaN: tensor(False, device='cuda:0')\n",
            "Train ESM NaN: tensor(False, device='cuda:0')\n",
            "Train Smiles Inf: tensor(False, device='cuda:0')\n",
            "Train ESM Inf: tensor(False, device='cuda:0')\n",
            "Val Smiles NaN: tensor(False, device='cuda:0')\n",
            "Val ESM NaN: tensor(False, device='cuda:0')\n",
            "Val Smiles Inf: tensor(False, device='cuda:0')\n",
            "Val ESM Inf: tensor(False, device='cuda:0')\n",
            "Train Smiles Random NaN: tensor(False, device='cuda:0')\n",
            "Train ESM Random NaN: tensor(False, device='cuda:0')\n",
            "Train Smiles Random Inf: tensor(False, device='cuda:0')\n",
            "Train ESM Random Inf: tensor(False, device='cuda:0')\n",
            "Val Smiles Random NaN: tensor(False, device='cuda:0')\n",
            "Val ESM Random NaN: tensor(False, device='cuda:0')\n",
            "Val Smiles Random Inf: tensor(False, device='cuda:0')\n",
            "Val ESM Random Inf: tensor(False, device='cuda:0')\n",
            "Train Smiles Distant NaN: tensor(False, device='cuda:0')\n",
            "Train ESM Distant NaN: tensor(False, device='cuda:0')\n",
            "Train Smiles Distant Inf: tensor(False, device='cuda:0')\n",
            "Train ESM Distant Inf: tensor(False, device='cuda:0')\n",
            "Val Smiles Distant NaN: tensor(False, device='cuda:0')\n",
            "Val ESM Distant NaN: tensor(False, device='cuda:0')\n",
            "Val Smiles Distant Inf: tensor(False, device='cuda:0')\n",
            "Val ESM Distant Inf: tensor(False, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def contrastive_loss(pos_dist, neg_dist, margin=1.0):\n",
        "    return torch.relu(pos_dist - neg_dist + margin).mean()\n",
        "\n",
        "def train_epoch(model, smiles_emb, esm_emb, smiles_random, esm_random, smiles_distant, esm_distant, optimizer, batch_size=32):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_pos_dist = 0\n",
        "    total_neg_dist = 0\n",
        "    num_batches = 0\n",
        "    with tqdm(range(0, len(smiles_emb), batch_size), desc=f\"Epoch {epoch+1} Training\") as pbar:\n",
        "        for i in pbar:\n",
        "            if i + batch_size > len(smiles_emb):\n",
        "                continue\n",
        "            batch_smiles = smiles_emb[i:i+batch_size]\n",
        "            batch_esm = esm_emb[i:i+batch_size]\n",
        "            batch_smiles_distant = smiles_distant[i:i+batch_size]  # Same SMILES\n",
        "            batch_esm_distant = esm_distant[i:i+batch_size]        # Distant proteins\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            # Positive pairs\n",
        "            smiles_aligned, prot_aligned = model(batch_smiles, batch_esm)\n",
        "            pos_dist = hyperbolic_distance(smiles_aligned, prot_aligned)\n",
        "            # Negative pairs (distant clusters)\n",
        "            smiles_distant_aligned, prot_distant_aligned = model(batch_smiles_distant, batch_esm_distant)\n",
        "            neg_dist = hyperbolic_distance(smiles_distant_aligned, prot_distant_aligned)\n",
        "\n",
        "            loss = contrastive_loss(pos_dist, neg_dist, margin=1.0)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_pos_dist += pos_dist.mean().item()\n",
        "            total_neg_dist += neg_dist.mean().item()\n",
        "            num_batches += 1\n",
        "            pbar.set_postfix({\n",
        "                'loss': loss.item(),\n",
        "                'pos_dist': pos_dist.mean().item(),\n",
        "                'neg_dist': neg_dist.mean().item()\n",
        "            })\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_pos_dist = total_pos_dist / num_batches\n",
        "    avg_neg_dist = total_neg_dist / num_batches\n",
        "    print(f\"Epoch {epoch+1} Train Loss: {avg_loss:.4f}, Avg Pos Dist: {avg_pos_dist:.4f}, Avg Neg Dist: {avg_neg_dist:.4f}\")\n",
        "    return avg_loss\n",
        "\n",
        "def validate(model, smiles_emb, esm_emb, smiles_random, esm_random, smiles_distant, esm_distant, batch_size=32):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_pos_dist = 0\n",
        "    total_neg_dist = 0\n",
        "    num_batches = 0\n",
        "    with tqdm(range(0, len(smiles_emb), batch_size), desc=f\"Epoch {epoch+1} Validation\") as pbar:\n",
        "        for i in pbar:\n",
        "            if i + batch_size > len(smiles_emb):\n",
        "                continue\n",
        "            batch_smiles = smiles_emb[i:i+batch_size]\n",
        "            batch_esm = esm_emb[i:i+batch_size]\n",
        "            batch_smiles_distant = smiles_distant[i:i+batch_size]\n",
        "            batch_esm_distant = esm_distant[i:i+batch_size]\n",
        "\n",
        "            smiles_aligned, prot_aligned = model(batch_smiles, batch_esm)\n",
        "            pos_dist = hyperbolic_distance(smiles_aligned, prot_aligned)\n",
        "            smiles_distant_aligned, prot_distant_aligned = model(batch_smiles_distant, batch_esm_distant)\n",
        "            neg_dist = hyperbolic_distance(smiles_distant_aligned, prot_distant_aligned)\n",
        "\n",
        "            loss = contrastive_loss(pos_dist, neg_dist, margin=1.0)\n",
        "            total_loss += loss.item()\n",
        "            total_pos_dist += pos_dist.mean().item()\n",
        "            total_neg_dist += neg_dist.mean().item()\n",
        "            num_batches += 1\n",
        "            pbar.set_postfix({\n",
        "                'loss': loss.item(),\n",
        "                'pos_dist': pos_dist.mean().item(),\n",
        "                'neg_dist': neg_dist.mean().item()\n",
        "            })\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_pos_dist = total_pos_dist / num_batches\n",
        "    avg_neg_dist = total_neg_dist / num_batches\n",
        "    print(f\"Epoch {epoch+1} Val Loss: {avg_loss:.4f}, Avg Pos Dist: {avg_pos_dist:.4f}, Avg Neg Dist: {avg_neg_dist:.4f}\")\n",
        "    return avg_loss\n",
        "\n",
        "# Training loop (using distant clusters here)\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_epoch(model, train_smiles_emb, train_esm_emb,\n",
        "                            train_smiles_random, train_esm_random,\n",
        "                            train_smiles_distant, train_esm_distant, optimizer)\n",
        "    val_loss = validate(model, val_smiles_emb, val_esm_emb,\n",
        "                        val_smiles_random, val_esm_random,\n",
        "                        val_smiles_distant, val_esm_distant)\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "AhyQjlesCEBA",
        "outputId": "50c5b1fe-a726-40fb-f825-97cd32e7d558"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Training:  62%|██████▏   | 68/109 [02:33<01:32,  2.25s/it, loss=0.918, pos_dist=0.486, neg_dist=0.567]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f109ea74390b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     train_loss = train_epoch(model, train_smiles_emb, train_esm_emb, \n\u001b[0m\u001b[1;32m     89\u001b[0m                             \u001b[0mtrain_smiles_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_esm_random\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                             train_smiles_distant, train_esm_distant, optimizer)\n",
            "\u001b[0;32m<ipython-input-29-f109ea74390b>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, smiles_emb, esm_emb, smiles_random, esm_random, smiles_distant, esm_distant, optimizer, batch_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Positive pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0msmiles_aligned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_aligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_smiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_esm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mpos_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperbolic_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_aligned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_aligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Negative pairs (distant clusters)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-100b9b5135a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, smiles_emb, prot_emb)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0msmiles_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mprot_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprot_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprot_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mhyperedge_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypergraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0msmiles_aligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msmiles_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_h\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperedge_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mprot_aligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprot_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmiles_h\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperedge_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-100b9b5135a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, smiles_emb, prot_emb)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopk_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                         score = self.hyperedge_net(torch.cat([smiles_refined[i],\n\u001b[0m\u001b[1;32m     51\u001b[0m                                                               \u001b[0mprot_refined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                                                               prot_refined[k]], dim=-1))\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Clusters:\", train_df['cluster'].value_counts())\n",
        "print(\"Val Clusters:\", val_df['cluster'].value_counts())\n",
        "\n",
        "# Check if distant indices differ from original\n",
        "\n",
        "device = train_distant_indices.device  # Get the device of train_distant_indices\n",
        "original_indices = torch.arange(10, device=device)\n",
        "\n",
        "print(\"Train Distant Indices Sample:\", train_distant_indices[:10])\n",
        "print(\"Train Original Indices Sample:\", original_indices)\n",
        "print(\"Any overlap in first 10?:\", any(train_distant_indices[:10] ==original_indices))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQRl3V6NzN0s",
        "outputId": "6aad1090-79f0-4aa3-ce09-cdf6e0780c3e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Clusters: cluster\n",
            "1     1556\n",
            "5      459\n",
            "2      382\n",
            "4      332\n",
            "0      230\n",
            "10     178\n",
            "8      128\n",
            "7      102\n",
            "9      102\n",
            "Name: count, dtype: int64\n",
            "Val Clusters: cluster\n",
            "3     892\n",
            "6     102\n",
            "11     51\n",
            "Name: count, dtype: int64\n",
            "Train Distant Indices Sample: tensor([2952, 2926, 2892, 2836, 2849, 2921, 2923, 2875, 2905, 2880],\n",
            "       device='cuda:0')\n",
            "Train Original Indices Sample: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0')\n",
            "Any overlap in first 10?: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "device = train_smiles_emb.device\n",
        "\n",
        "print(\"Train Smiles Mean:\", train_smiles_emb.mean(dim=-1).detach().cpu().numpy().mean())\n",
        "print(\"Train ESM Mean:\", train_esm_emb.mean(dim=-1).detach().cpu().numpy().mean())\n",
        "print(\"Train ESM Distant Mean:\", train_esm_distant.mean(dim=-1).detach().cpu().numpy().mean())\n",
        "print(\"Train ESM Random Mean:\", train_esm_random.mean(dim=-1).detach().cpu().numpy().mean())\n",
        "\n",
        "train_smiles_sim = cosine_similarity(train_smiles_emb[:100].detach().cpu().numpy())\n",
        "train_esm_sim = cosine_similarity(train_esm_emb[:100].detach().cpu().numpy())\n",
        "train_esm_distant_sim = cosine_similarity(train_esm_distant[:100].detach().cpu().numpy())\n",
        "\n",
        "print(\"Train Smiles Avg Cos Sim:\", train_smiles_sim.mean())\n",
        "print(\"Train ESM Avg Cos Sim:\", train_esm_sim.mean())\n",
        "print(\"Train ESM Distant Avg Cos Sim:\", train_esm_distant_sim.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKqAP9T6z5V7",
        "outputId": "a7e2f738-cc7b-47b7-c307-24bbab47faea"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Smiles Mean: -0.000391361\n",
            "Train ESM Mean: -0.00011110737\n",
            "Train ESM Distant Mean: -0.000101636746\n",
            "Train ESM Random Mean: -4.2555697e-05\n",
            "Train Smiles Avg Cos Sim: 1.0000001\n",
            "Train ESM Avg Cos Sim: 0.956232\n",
            "Train ESM Distant Avg Cos Sim: 0.95709044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'hgsac_model.pth')\n",
        "\n"
      ],
      "metadata": {
        "id": "DrUbXAl0CGG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "FxerSnl3arqV",
        "outputId": "08859e84-4d36-48a0-f0f6-972d7da7ccc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          Plastic Type       Enzyme Name  \\\n",
              "0                              PCL_PET     PET-hydrolase   \n",
              "1                              PCL_PET            PETase   \n",
              "2                              PCL_PET          Cutinase   \n",
              "3                              PCL_PET          Cutinase   \n",
              "4                              PCL_PET          Cutinase   \n",
              "..                                 ...               ...   \n",
              "888              PBAT_PBS_PBSA_PCL_PES         Hydrolase   \n",
              "889       PLA_PBS_PBSA_PCL_PES_PHB_PHA  PLA_depolymerase   \n",
              "890  PBAT_PBS_PBSA_PCL_PET_PHB_PLA_PHA          Cutinase   \n",
              "891       PBS_PBSA_PCL_PES_PHB_PLA_PHA  PLA_depolymerase   \n",
              "892                        PES_PCL_PET          Cutinase   \n",
              "\n",
              "                                      protein_sequence  \\\n",
              "0    MINVLTKCKLALGIIAIFFSLPSFAVKCSSCSNGFERGPDPSVDQL...   \n",
              "1    MPLLLSLPRALAAAALLAAATLVPLSAAAQTNPYQRGPDPTTRSLE...   \n",
              "2    MINRTLPNRLLSVLCAGALLLSTSAMAARPPVDTRFDPAAAYARGP...   \n",
              "3    MLLAGADAAALEARQLGGSNTRNDLANGHSGSCPGVIFIYARGSTE...   \n",
              "4    MLPQIQDAAALEARQLGGSSTRNDLANGNSGACPSVIFIYARGSTE...   \n",
              "..                                                 ...   \n",
              "888  MKRRLIAGSVAALALSATAVALPTGVASAASCSDVDVVFARGTGEL...   \n",
              "889  MRKRKGVKLAIAALLFLLVLPGNARASEKQHPLVLVHGLGNWDLWS...   \n",
              "890  MRIRRQFGTGARASTGRAIGVMTTALAVLVGLVGGPAGAESSGADD...   \n",
              "891  MRLKKRALIFISFLLAFTLLIPTAASAYEKEYKPNIALEPIETSEG...   \n",
              "892  MVRVFGLTLLAALAPALAAPVVEDLEARQSACADVTVVVARGTTQD...   \n",
              "\n",
              "                                                smiles  protein_length  \\\n",
              "0     [*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             298   \n",
              "1     [*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             298   \n",
              "2     [*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             302   \n",
              "3     [*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             226   \n",
              "4     [*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]             226   \n",
              "..                                                 ...             ...   \n",
              "888  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             216   \n",
              "889  [*]OC(C)C(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]O...             283   \n",
              "890  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             304   \n",
              "891  [*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...             431   \n",
              "892  [*]OCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCC...             203   \n",
              "\n",
              "    synthetic  cluster  \n",
              "0        True        5  \n",
              "1        True        5  \n",
              "2        True        5  \n",
              "3        True        5  \n",
              "4        True        5  \n",
              "..        ...      ...  \n",
              "888      True        3  \n",
              "889      True        3  \n",
              "890      True        3  \n",
              "891      True        3  \n",
              "892      True        3  \n",
              "\n",
              "[893 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee703aed-c1ad-46dd-83c5-a27f939aa613\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plastic Type</th>\n",
              "      <th>Enzyme Name</th>\n",
              "      <th>protein_sequence</th>\n",
              "      <th>smiles</th>\n",
              "      <th>protein_length</th>\n",
              "      <th>synthetic</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PCL_PET</td>\n",
              "      <td>PET-hydrolase</td>\n",
              "      <td>MINVLTKCKLALGIIAIFFSLPSFAVKCSSCSNGFERGPDPSVDQL...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>298</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PCL_PET</td>\n",
              "      <td>PETase</td>\n",
              "      <td>MPLLLSLPRALAAAALLAAATLVPLSAAAQTNPYQRGPDPTTRSLE...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>298</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PCL_PET</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MINRTLPNRLLSVLCAGALLLSTSAMAARPPVDTRFDPAAAYARGP...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>302</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PCL_PET</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MLLAGADAAALEARQLGGSNTRNDLANGHSGSCPGVIFIYARGSTE...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>226</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PCL_PET</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MLPQIQDAAALEARQLGGSSTRNDLANGNSGACPSVIFIYARGSTE...</td>\n",
              "      <td>[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]</td>\n",
              "      <td>226</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>PBAT_PBS_PBSA_PCL_PES</td>\n",
              "      <td>Hydrolase</td>\n",
              "      <td>MKRRLIAGSVAALALSATAVALPTGVASAASCSDVDVVFARGTGEL...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>216</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>PLA_PBS_PBSA_PCL_PES_PHB_PHA</td>\n",
              "      <td>PLA_depolymerase</td>\n",
              "      <td>MRKRKGVKLAIAALLFLLVLPGNARASEKQHPLVLVHGLGNWDLWS...</td>\n",
              "      <td>[*]OC(C)C(=O)[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]O...</td>\n",
              "      <td>283</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>PBAT_PBS_PBSA_PCL_PET_PHB_PLA_PHA</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MRIRRQFGTGARASTGRAIGVMTTALAVLVGLVGGPAGAESSGADD...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>304</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>891</th>\n",
              "      <td>PBS_PBSA_PCL_PES_PHB_PLA_PHA</td>\n",
              "      <td>PLA_depolymerase</td>\n",
              "      <td>MRLKKRALIFISFLLAFTLLIPTAASAYEKEYKPNIALEPIETSEG...</td>\n",
              "      <td>[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O...</td>\n",
              "      <td>431</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>892</th>\n",
              "      <td>PES_PCL_PET</td>\n",
              "      <td>Cutinase</td>\n",
              "      <td>MVRVFGLTLLAALAPALAAPVVEDLEARQSACADVTVVVARGTTQD...</td>\n",
              "      <td>[*]OCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCC...</td>\n",
              "      <td>203</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>893 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee703aed-c1ad-46dd-83c5-a27f939aa613')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee703aed-c1ad-46dd-83c5-a27f939aa613 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee703aed-c1ad-46dd-83c5-a27f939aa613');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-25934d58-7036-4d4e-9ba4-c4fb6dd779a7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25934d58-7036-4d4e-9ba4-c4fb6dd779a7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-25934d58-7036-4d4e-9ba4-c4fb6dd779a7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d1d9013b-47bb-4302-9342-e961710adf17\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('val_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d1d9013b-47bb-4302-9342-e961710adf17 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('val_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "val_df",
              "summary": "{\n  \"name\": \"val_df\",\n  \"rows\": 893,\n  \"fields\": [\n    {\n      \"column\": \"Plastic Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"PCL_PET\",\n          \"PET_PEF\",\n          \"PE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Enzyme Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Alkane_hydroxylase\",\n          \"Laccase\",\n          \"PET-hydrolase\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 893,\n        \"samples\": [\n          \"MRLRRHAGTGARAGMARAIGVMTTALAVTVGAVGGVAGAEVSTAQDNPYERGPDPTEQSIAAGRGPFTVATKRVSSLASGFGGGTIYYPTETDEGTFGAVAVAPGYTASQGSMSWYGPRVASHGFIVITIDTNTRLDQPGARGRQLLAALDYLTGRSDRKVRERLDPNRLAVMGHSMGGGGTLEATVDRPSLKAAIPLTPWNLDKTWGQVQVPTLIIGAENDTIASVRTHAKPFYESLPSSLDKAYMELNGATHFAPARPNTTIAKYVISWLKRFVDEDTRYEQFLCPNPTDRAIVEYRSTCPY\",\n          \"MNARSTEQHPARYPGAAAGEPTLDSWQEAPHNRWAFSRLGELLPTAAVSRADPATPAEPVTGLDALAERLPDLEQRLEETGTDAFLVLRGSEVLAEHYRNGLRPDTRHLLMSVSKSLLGLVVGALIDEGRIDPARPVTEYVPELAGSGYDGPSVLQVLDMQIGTDYSEDYVDPASEVQLLIRVAGWRTRRDGLPAGTYEFLTTLRGDGGTGEFRYCSANTDVLGWIVERVTGLRYVEALSEYLWANVGAARDATITVDPSGVGMAGGGVSATARDLARVGRMALDGGVAPGGRVVSAGWVESALAGGSREAFAGAGFTGAFPGGSYTRQWWATGNERGAVSGIGIHGQNLWVDPRTDSVIVKLSSWPDPLTTHTHGLLHSVLADVGRALDAV\",\n          \"MNARSTGQHPARPPGAAAGEPTLDSWQEAPHNRWAFARLGELLPTATVSRRDPAAPTEQVVDLDALAERLPDLEQRLEETHTDALLVLRGDEVLAEYYRAGFTPDDRHLLMSVSKSLVGLVVGALIDEGRIDPAQPVTEYVPELAASVYDGASVLQVLDMQISIDYSEDYVDPASEVQLLERAMGWRPRRDGRPADTYEFLTTLRGAGGTGEFQYRSANTDVLAWIVERVTGLRYVDALSRYLWAPLDAERDATITVDPTGFGVAGGGVSCTARDLARVGRMMLDGGVAPGGRVVSEGWVESVLAGGSREAFQAAGFTSAFPGGSYHRQWWATGGERGNVLGIGIHGQNLWLDPRSDTVIVKLSSWPDPDTRRDHELTSGVLLDVSRALDAA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smiles\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)CC(=O)O[*].[*]OC(C)C(=O)[*].[*]OC(C)CC(=O)[*]\",\n          \"[*]OCCOC(=O)CC(=O)O[*].[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]\",\n          \"[*]OCCCCC(=O)[*].[*]OCCOC(=O)c1ccc(cc1)C(=O)O[*]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 92,\n        \"min\": 108,\n        \"max\": 541,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          304,\n          203,\n          240\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synthetic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 7,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Load validation data to access clusters\n",
        "val_df = pd.read_csv('val_data.csv')\n",
        "val_clusters = val_df['cluster']  # First 32 samples’ clusters\n",
        "\n",
        "# Inference example\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # 1. Aligned pairs (first 32 from validation set, assumed related)\n",
        "    smiles_aligned, prot_aligned = model(val_smiles_emb[:32], val_esm_emb[:32])\n",
        "    distances_aligned = hyperbolic_distance(smiles_aligned, prot_aligned)\n",
        "    print(\"Aligned Pair Distances (Related):\", distances_aligned)\n",
        "    print(\"Mean Aligned Distance:\", distances_aligned.mean().item())\n",
        "\n",
        "    # # 2. Shuffled pairs (ensure different clusters)\n",
        "    # cluster_dict = {}\n",
        "    # for i, cluster in enumerate(val_clusters):\n",
        "    #     if cluster not in cluster_dict:\n",
        "    #         cluster_dict[cluster] = []\n",
        "    #     cluster_dict[cluster].append(i)  # Group indices by cluster\n",
        "\n",
        "    # # Create shuffled pairs from different clusters\n",
        "    # shuffled_indices = []\n",
        "    # used_clusters = set()\n",
        "    # for i in range(32):\n",
        "    #     orig_cluster = val_clusters[i]\n",
        "    #     # Pick a SMILES from a different cluster\n",
        "    #     available_clusters = [c for c in cluster_dict.keys() if c != orig_cluster and c not in used_clusters]\n",
        "    #     print('available clusters', available_clusters)\n",
        "    #     if not available_clusters:  # Fallback if no different clusters left\n",
        "    #         available_clusters = [c for c in cluster_dict.keys() if c != orig_cluster]\n",
        "    #     if available_clusters:\n",
        "    #         diff_cluster = random.choice(available_clusters)\n",
        "    #         shuffled_idx = random.choice(cluster_dict[diff_cluster])\n",
        "    #         shuffled_indices.append(shuffled_idx)\n",
        "    #         used_clusters.add(diff_cluster)\n",
        "    #     else:\n",
        "    #         shuffled_indices.append(i)  # Fallback to same if no options\n",
        "\n",
        "    # shuffled_smiles_emb = val_smiles_emb[:32][shuffled_indices]  # Shuffled SMILES from different clusters\n",
        "    # shuffled_prot_emb = val_esm_emb[:32]  # Original protein order\n",
        "    # smiles_shuffled, prot_shuffled = model(shuffled_smiles_emb, shuffled_prot_emb)\n",
        "    # distances_shuffled = hyperbolic_distance(smiles_shuffled, prot_shuffled)\n",
        "    # print(\"\\nShuffled Pair Distances (Different Clusters):\", distances_shuffled)\n",
        "    # print(\"Mean Shuffled Distance:\", distances_shuffled.mean().item())\n",
        "\n",
        "    # 3. Completely random pairs (unchanged)\n",
        "    random_smiles_emb = torch.randn(32, 256).to(device)\n",
        "    random_smiles_emb = random_smiles_emb / random_smiles_emb.norm(dim=-1, keepdim=True).clamp(min=1e-7)\n",
        "    random_prot_emb = torch.randn(32, 1280).to(device)\n",
        "    random_prot_emb = random_prot_emb / random_prot_emb.norm(dim=-1, keepdim=True).clamp(min=1e-7)\n",
        "    smiles_random, prot_random = model(random_smiles_emb, random_prot_emb)\n",
        "    distances_random = hyperbolic_distance(smiles_random, prot_random)\n",
        "    print(\"\\nRandom Pair Distances (Completely Random):\", distances_random)\n",
        "    print(\"Mean Random Distance:\", distances_random.mean().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "rYRD-dQqCHoh",
        "outputId": "1738b8f6-05c6-4390-b2b7-e23501a354b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling cublasLtMatmul with transpose_mat1 1 transpose_mat2 0 m 512 n 32 k 256 mat1_ld 256 mat2_ld 256 result_ld 512 abcType 0 computeType 68 scaleType 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-ac807099f6c6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# 1. Aligned pairs (first 32 from validation set, assumed related)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msmiles_aligned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_aligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_smiles_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_esm_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdistances_aligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperbolic_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_aligned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_aligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Aligned Pair Distances (Related):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances_aligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-97-3bce6213c285>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, smiles_emb, prot_emb)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmiles_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0msmiles_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mprot_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprot_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprot_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mhyperedge_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypergraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-97-3bce6213c285>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurvature\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling cublasLtMatmul with transpose_mat1 1 transpose_mat2 0 m 512 n 32 k 256 mat1_ld 256 mat2_ld 256 result_ld 512 abcType 0 computeType 68 scaleType 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    random_smiles_emb = torch.randn(32, 256).to(device)  # Unnormalized\n",
        "    random_prot_emb = torch.randn(32, 1280).to(device)   # Unnormalized\n",
        "    smiles_random, prot_random = model(random_smiles_emb, random_prot_emb)\n",
        "    distances_random = hyperbolic_distance(smiles_random, prot_random)\n",
        "    print(\"Random Pair Distances (Unnormalized):\", distances_random)\n",
        "    print(\"Mean Random Distance:\", distances_random.mean().item())"
      ],
      "metadata": {
        "id": "3nmtGh4vbVhN",
        "outputId": "7617f727-c07f-4a3d-eb9d-b71b6421f0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-0f0c29bd4724>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrandom_smiles_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Unnormalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mrandom_prot_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Unnormalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msmiles_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_smiles_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_prot_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdistances_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperbolic_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "CsZYuP9onEl1",
        "B--CLs46QMLR",
        "Y84XLPeXQIEv",
        "daZm9aPyRUAM",
        "BRJt_Mhb-6FZ",
        "0Pe8VJFxQSS7",
        "6o91I0EXQaF4",
        "xWlqqd7_tO8_",
        "EqmrJpgOtnBW",
        "Wmqg3zrXtsP-",
        "KPoO9a6Xt3FL"
      ],
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}